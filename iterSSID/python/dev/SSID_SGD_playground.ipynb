{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# alternating blocked descent\n",
    "\n",
    "- using SGD on $C$\n",
    "- after each pass over the observed parts of the covariance matrix, use analyic solution for $A$, $\\Pi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.optimize import fmin_bfgs, check_grad\n",
    "import glob, os\n",
    "\n",
    "os.chdir('../core')\n",
    "from utility import get_subpop_stats, draw_sys\n",
    "import SSID_Hankel_loss\n",
    "from SSID_Hankel_loss import run_bad, plot_outputs_l2_gradient_test, l2_sis_setup\n",
    "from SSID_Hankel_loss import yy_Hankel_cov_mat, l2_sis_draw, adam_zip_bad_stable, id_A, id_Pi\n",
    "os.chdir('../dev')\n",
    "\n",
    "# load ancient code for drawing from LDS ...\n",
    "os.chdir('../../../../pyRRHDLDS/core')\n",
    "import ssm_scripts\n",
    "import ssm_fit\n",
    "os.chdir('../../code_le_stitch/iterSSID/python/dev')\n",
    "\n",
    "\n",
    "p,n,nr = 500, 20, 10\n",
    "k,l = 5,5\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.8, 0.99, 0.8, 0.99\n",
    "\n",
    "batch_size = p # batch_size = 1 (size-1 mini-batches), p (column mini-batches), None (full gradients)\n",
    "\n",
    "a, b1, b2, e = 0.001, 0.9, 0.99, 1e-8\n",
    "max_iter_nl =  100\n",
    "max_iter_lin = 0\n",
    "reps = 1\n",
    "\n",
    "verbose=True\n",
    "\n",
    "# create subpopulations\n",
    "\n",
    "#sub_pops = (np.arange(0,200), np.arange(100,300), np.arange(200,400), np.arange(300,p))\n",
    "#sub_pops = (np.arange(0,2*p//10), np.arange(p//10,3*p//10), np.arange(2*p//10,4*p//10), np.arange(3*p//10,5*p//10),\n",
    "#            np.arange(4*p//10,6*p//10), np.arange(5*p//10,7*p//10), np.arange(6*p//10,8*p//10), \n",
    "#            np.arange(7*p//10,9*p//10), np.arange(8*p//10,p))\n",
    "\n",
    "sub_pops = (np.arange(0,p//2+1), np.arange(p//2-1,p))\n",
    "#sub_pops = (np.arange(10,p), np.arange(0,p-10))\n",
    "#sub_pops = (np.arange(0,p), np.arange(0,p))\n",
    "\n",
    "obs_idx, idx_grp, co_obs, overlaps, overlap_grp, idx_overlap, Om, Ovw, Ovc = \\\n",
    "    get_subpop_stats(sub_pops=sub_pops, p=p, verbose=False)\n",
    "\n",
    "# draw system matrices    \n",
    "ev_r = np.linspace(eig_m_r, eig_M_r, nr)\n",
    "ev_c = np.exp(2 * 1j * np.pi * np.random.uniform(size= (n - nr)//2))\n",
    "ev_c = np.linspace(eig_m_c, eig_M_c, (n - nr)//2) * ev_c\n",
    "\n",
    "pars_true, Qs, Qs_full = draw_sys(p=p,n=n,k=k,l=l,Om=Om, nr=nr, ev_r=ev_r,ev_c=ev_c)\n",
    "pars_true['d'], pars_true['mu0'], pars_true['V0'] = np.zeros(p), np.zeros(n), pars_true['Pi'].copy()\n",
    "\n",
    "x,y,_ = ssm_scripts.sim_data(pars=pars_true, t_tot= p)\n",
    "x,y = x[:,:,0], y[:,:,0]\n",
    "for m in range(k+l):\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(Qs_full[m], interpolation='none')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(np.cov(y[:,m:m-(k+l)], y[:,:-(k+l)])[:p,p:], interpolation='none')    \n",
    "    Qs_full[m] = np.cov(y[:,m:m-(k+l)], y[:,:-(k+l)])[:p,p:]\n",
    "    Qs[m] = np.cov(y[:,m:m-(k+l)], y[:,:-(k+l)])[:p,p:]\n",
    "    plt.show()\n",
    "\n",
    "for rep in range(reps):        \n",
    "    \n",
    "    linearity = 'False'\n",
    "    stable = True\n",
    "    pars_init, pars_est, traces = run_bad(k=k,l=l,n=n,Qs=Qs,Om=Om,\n",
    "                                          sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                                          linearity=linearity,stable=stable,init='default',\n",
    "                                          a=a,b1=b1,b2=b2,e=e,max_iter=max_iter_nl,batch_size=batch_size,\n",
    "                                          verbose=verbose)\n",
    "    f_i = l2_sis_setup(k,l,n,Qs,Om,idx_grp,obs_idx)[0] # get f to compute final errors\n",
    "    plot_outputs_l2_gradient_test(pars_true, pars_init, pars_est, k, l, Qs, \n",
    "                                       Qs_full, Om, Ovc, Ovw, f_i, None, traces = traces,\n",
    "                                       linearity=linearity, idx_grp = idx_grp, co_obs = co_obs, \n",
    "                                       if_flip = True, m = 1)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    linearity = 'first_order'\n",
    "    stable = False\n",
    "    _, pars_est, traces = run_bad(k=k,l=l,n=n,Qs=Qs,Om=Om,\n",
    "                                          sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                                          linearity=linearity,stable=stable,init=pars_est,\n",
    "                                          a=a,b1=b1,b2=b2,e=e,max_iter=max_iter_nl,batch_size=batch_size)\n",
    "    f_i = l2_sis_setup(k,l,n,Qs,Om,idx_grp,obs_idx)[0] # get f to compute final errors\n",
    "    plot_outputs_l2_gradient_test(pars_true, pars_init_ssid, pars_est, k, l, Qs, \n",
    "                                       Qs_full, Om, Ovc, Ovw, f_i, None, traces = traces,\n",
    "                                       linear=False, idx_grp = idx_grp, co_obs = co_obs, \n",
    "                                       if_flip = True, m = 1)    \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    linearity = 'True'\n",
    "    stable = False\n",
    "    pars_init_linear = pars_est.copy()\n",
    "    pars_init_linear['A'], pars_init_linear['Pi'] = None, None \n",
    "    pars_init_linear, pars_est, traces = run_bad(k=k,l=l,n=n,Qs=Qs,Om=Om,\n",
    "                                          sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                                          linearity=linearity,stable=stable,init=pars_init_linear,\n",
    "                                          a=a,b1=b1,b2=b2,e=e,max_iter=max_iter_lin,batch_size=batch_size,\n",
    "                                          verbose=verbose)\n",
    "    plot_outputs_l2_gradient_test(pars_true, pars_init, pars_est, k, l, Qs, \n",
    "                                       Qs_full, Om, Ovc, Ovw, f_i, None, traces = traces,\n",
    "                                       linearity=linearity, idx_grp = idx_grp, co_obs = co_obs, \n",
    "                                       if_flip = True, m = 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.plot(range(0, 110, 10), traces[1].T)\n",
    "    plt.title('corrs as function of steps (10% max_iter increments)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pars_true['R'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(Om, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# just one more turn..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_iter = 200\n",
    "\n",
    "linearity = 'True'\n",
    "stable = False\n",
    "_, pars_est, traces = run_bad(k=k,l=l,n=n,Qs=Qs_full,Om=Om,\n",
    "                              sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                              linearity=linearity,stable=stable,init=pars_est,\n",
    "                              a=a,b1=b1,b2=b2,e=e,max_iter=max_iter,batch_size=batch_size)\n",
    "f_i = l2_sis_setup(k,l,n,Qs,Om,idx_grp,obs_idx)[0] # get f to compute final errors\n",
    "plot_outputs_l2_gradient_test(pars_true, pars_init, pars_est, k, l, Qs, \n",
    "                                   Qs_full, Om, Ovc, Ovw, f_i, None, traces = traces,\n",
    "                                   linearity=linearity,  idx_grp = idx_grp, co_obs = co_obs, \n",
    "                                   if_flip = True, m = 1)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_iter = 500\n",
    "\n",
    "linearity = 'False'\n",
    "stable = False\n",
    "_, pars_est, traces = run_bad(k=k,l=l,n=n,Qs=Qs_full,Om=Om,\n",
    "                              sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                              linearity=linearity,stable=stable,init=pars_est,\n",
    "                              a=a,b1=b1,b2=b2,e=e,max_iter=max_iter,batch_size=batch_size)\n",
    "f_i = l2_sis_setup(k,l,n,Qs,Om,idx_grp,obs_idx)[0] # get f to compute final errors\n",
    "plot_outputs_l2_gradient_test(pars_true, pars_init, pars_est, k, l, Qs, \n",
    "                                   Qs_full, Om, Ovc, Ovw, f_i, None, traces = traces,\n",
    "                                   linearity=linearity, idx_grp = idx_grp, co_obs = co_obs, \n",
    "                                   if_flip = True, m = 1)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(range(0, 110, 10), traces[1].T)\n",
    "plt.title('corrs as function of steps (10% max_iter increments)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.corrcoef(Qs_full[1].reshape(-1,), (pars_true['C'].dot(pars_true['A'].dot(pars_true['Pi'])).dot(pars_true['C'].T)).reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(pars_true['C'].dot(pars_true['A'].dot(pars_true['Pi'])).dot(pars_true['C'].T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check linearity of extracted latent covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import SDLS\n",
    "\n",
    "pars = pars_est\n",
    "A, X = SSID_Hankel_loss.s_A_l2_Hankel_bad_sis(pars['C'],k,l,Qs,idx_grp,co_obs, linear=True,stable=False,A_old=None)\n",
    "\n",
    "print('checking MSE solution for A')\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(A, interpolation='none')\n",
    "plt.title('MSE solution for A')\n",
    "plt.subplot(1,2,2)\n",
    "try:\n",
    "    plt.imshow(pars['A'], interpolation='none')\n",
    "except:\n",
    "    pass\n",
    "plt.title('pars[A]')\n",
    "plt.show()\n",
    "\n",
    "try:\n",
    "    print('eig(pars[A])', np.sort(np.linalg.eigvals(pars['A'])))\n",
    "except:\n",
    "    pass\n",
    "print('eig(A_rec)', np.sort(np.linalg.eigvals(A)))\n",
    "print('MSE A: ', np.mean((pars['A'] - A)**2))\n",
    "\n",
    "\n",
    "X1,X2 = np.zeros((n, n*(k+l-2))), np.zeros((n, n*(k+l-2)))\n",
    "for m in range(k+l-2):\n",
    "    X1[:,m*n:(m+1)*n] = X[:,m].reshape(n,n)\n",
    "    X2[:,m*n:(m+1)*n] = X[:,m+1].reshape(n,n)\n",
    "\n",
    "m = 3\n",
    "print('checking MSE solution for X, m = ', m)\n",
    "AmPi = np.linalg.matrix_power(pars['A'],m ).dot(pars['Pi'])\n",
    "X_m  = X[:,m-1].reshape(n,n)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow( AmPi, interpolation='none')\n",
    "plt.title('pars cov(x_{t+m), x_t) = A^m Pi')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow( X_m, interpolation='none')\n",
    "plt.title('est. cov(x_{t+m), x_t) = C^d Qs[m] C^d.T')\n",
    "#print( 'A^m Pi - X_m' , np.mean((AmPi - X_m)**2) )\n",
    "#print( 'A^m Pi - X_m^T' , np.mean((AmPi - X_m.T)**2) )\n",
    "\n",
    "\n",
    "AX1     = np.zeros((n*(k+l-1),n))\n",
    "As = np.empty((n*(k+l-1),n))\n",
    "XT = np.empty((n*(k+l-1),n))\n",
    "for m_ in range(k+l-1):\n",
    "    XT[m_*n:(m_+1)*n,:] = X[:,m_].reshape(n,n)\n",
    "    As[m_*n:(m_+1)*n,:] = np.linalg.matrix_power(A,m_+1)\n",
    "for m_ in range(1,k+l-1):\n",
    "    AX1[(m_)*n:(m_+1)*n,:] = A.dot(XT[(m_-1)*n:m_*n,:])\n",
    "    \n",
    "Pie,_,norm_res,muv,r,fail = SDLS.sdls(A=As,B=XT, X0=0.5*pars['Pi'],Y0=None,tol=1e-3,verbose=True)\n",
    "#Pie = SSID_Hankel_loss.s_Pi_l2_Hankel_bad_sis(X,A,k,l,Qs,Pi=None,verbose=True)\n",
    "\n",
    "print('MSE Pi: ', np.mean((pars['Pi'] - Pie)**2))\n",
    "\n",
    "print('MSE for As Pi - Xms' , np.mean((As.dot(Pie) - XT)**2) )\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow( np.linalg.matrix_power(A,m ).dot(Pie), interpolation='none')\n",
    "plt.title('reconstr. cov(x_{t+m), x_t) = A_hat^m Pi_hat')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.subplot(4,1,1)\n",
    "plt.imshow(XT.T, interpolation='none')\n",
    "plt.title('data est. for latent covs')\n",
    "plt.subplot(4,1,2)\n",
    "plt.imshow( AX1.T, interpolation='none')\n",
    "plt.title('A * [X1, X2, ...]')\n",
    "plt.subplot(4,1,3)\n",
    "plt.imshow((As.dot(pars['Pi'])).T, interpolation='none')\n",
    "plt.title('param est. for latent covs, using pars[Pi]')\n",
    "plt.subplot(4,1,4)\n",
    "plt.imshow((As.dot(Pie)).T, interpolation='none')\n",
    "plt.title('param est. for latent covs, using MSE Pi')\n",
    "plt.show()\n",
    "print( 'A^m Pi - X_m' , np.mean((np.linalg.matrix_power(A,m).dot(Pie) - X[:,m-1].reshape(n,n))**2) )\n",
    "print( 'A X_{m-1} - X_m' , np.mean((A.dot(X1) - X2)**2) )\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.subplot(1,4,1)\n",
    "plt.plot(XT.reshape(-1,), XT.reshape(-1,), 'k.')\n",
    "plt.title('recov. cov vs. recov. cov (for scales)')\n",
    "plt.subplot(1,4,2)\n",
    "plt.plot(XT[n:,:].reshape(-1,), AX1[n:,:].reshape(-1,),'k.')\n",
    "plt.title('recov. cov vs. first-order reconstruction')\n",
    "plt.subplot(1,4,3)\n",
    "plt.plot(XT.reshape(-1,), (As.dot(pars['Pi'])).reshape(-1,), 'k.')\n",
    "plt.title('recov. cov vs. full reconstruction with pars[Pi]')\n",
    "plt.subplot(1,4,4)\n",
    "plt.plot(XT.reshape(-1,), (As.dot(Pie)).reshape(-1,), 'k.')\n",
    "plt.title('recov. cov vs. full reconstruction with least-squares Pi')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting $\\\\Pi$ from latent covariances given $A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "os.chdir('../core')\n",
    "import SDLS\n",
    "os.chdir('../dev')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sig, tol = 1, 10e-2\n",
    "n = 30\n",
    "V = np.random.normal(size=(n,n))\n",
    "V = V / np.sum(V**2,0).reshape(1,-1)\n",
    "Adyn = V.dot(np.diag(np.linspace(0.8, 0.99,n))).dot(np.linalg.inv(V))\n",
    "Pi = np.outer(np.linspace(0.5,1.0,n), np.linspace(0.5,1.0,n))\n",
    "\n",
    "A = np.zeros((4*n,n))\n",
    "B = np.zeros((4*n,n))\n",
    "for i in range(4):\n",
    "    B[i*n:(i+1)*n,:] = np.linalg.matrix_power(Adyn,i+1).dot(Pi)\n",
    "    A[i*n:(i+1)*n,:] = np.linalg.matrix_power(Adyn,i+1)\n",
    "    \n",
    "B += sig * np.random.normal(size=B.shape)\n",
    "    \n",
    "Pie,Y,norm_res,muv,r,fail = SDLS.sdls(A,B,X0=None,Y0=None,tol=tol,verbose=False)\n",
    "\n",
    "print('maximal absolute single-entry deviation of AX and B: ', np.max(np.abs(A.dot(Pie) - B)))\n",
    "print('maximal absolute single-entry deviation of Pi and Pi_est: ', np.max(np.abs(Pie - Pi)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(Pie,interpolation='none')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(Pi,interpolation='none')\n",
    "plt.show()\n",
    "\n",
    "for i in range(5):\n",
    "    V = np.random.normal(size=(n,n))\n",
    "    V = V / np.sum(V**2,0).reshape(1,-1)\n",
    "    Adyn = V.dot(np.diag(np.linspace(0.8, 0.99,n))).dot(np.linalg.inv(V))\n",
    "    Pi = stats.wishart.rvs(df=n, scale=np.eye(n))\n",
    "\n",
    "    A = np.zeros((4*n,n))\n",
    "    B = np.zeros((4*n,n))\n",
    "    for i in range(4):\n",
    "        B[i*n:(i+1)*n,:] = np.linalg.matrix_power(Adyn,i+1).dot(Pi)\n",
    "        A[i*n:(i+1)*n,:] = np.linalg.matrix_power(Adyn,i+1)        \n",
    "    B += sig * np.random.normal(size=B.shape)\n",
    "    \n",
    "    Pie,Y,norm_res,muv,r,fail = SDLS.sdls(A,B,X0=None,Y0=None,tol=tol,verbose=False)\n",
    "    print('maximal absolute single-entry deviation of AX and B: ', np.max(np.abs(A.dot(Pie) - B)))\n",
    "    print('maximal absolute single-entry deviation of Pi and Pi_est: ', np.max(np.abs(Pie - Pi)))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(Pie,interpolation='none')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(Pi,interpolation='none')\n",
    "    plt.show()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    if not traces is None:\n",
    "        if isinstance(traces, np.ndarray):\n",
    "            fs, len_traces = traces, 1\n",
    "        elif isinstance(traces, tuple):\n",
    "            fs, len_traces = traces[0], len(traces)  \n",
    "    fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(pars['Pi'], interpolation='none')\n",
    "plt.show()\n",
    "plt.imshow(Pie, interpolation='none')\n",
    "plt.show()\n",
    "plt.plot(pars['Pi'].reshape(-1,), Pie.reshape(-1,), '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.io import savemat # store results for comparison with Matlab code   \n",
    "\n",
    "os.chdir('../fits/')\n",
    "\n",
    "save_file = 'nousbad_p50n20r2'\n",
    "\n",
    "save_file_m = {'A_true':pars_true['A'],\n",
    "               #'B_true':pars_true['B'],\n",
    "               'Pi_true' : pars_true['Pi'], \n",
    "               'C_true' : pars_true['C'],\n",
    "               'A_0': pars_init_ssid['A'],\n",
    "               #'B_0': pars_init['B'],\n",
    "               'Pi_0': pars_init_ssid['Pi'],\n",
    "               'C_0': pars_init_ssid['C'],\n",
    "               'A_est': pars_est['A'],\n",
    "               #'B_est':  pars_est['B'],\n",
    "               'Pi_est' :  pars_est['Pi'], \n",
    "               'C_est' :  pars_est['C']}\n",
    "\n",
    "savemat(save_file,save_file_m) # does the actual saving\n",
    "\n",
    "pars_true_vec = np.hstack((pars_true['A'].reshape(n*n,),\n",
    "                    pars_true['Pi'].reshape(n*n,),\n",
    "                    pars_true['C'].reshape(p*n,)))\n",
    "pars_init_vec = np.hstack((pars_init_ssid['A'].reshape(n*n,),\n",
    "                    pars_init_ssid['Pi'].reshape(n*n,),\n",
    "                    pars_init_ssid['C'].reshape(p*n,)))\n",
    "pars_est_vec  = np.hstack((pars_est['A'].reshape(n*n,),\n",
    "                    pars_est['Pi'].reshape(n*n,),\n",
    "                    pars_est['C'].reshape(p*n,)))\n",
    "\n",
    "np.savez(save_file, \n",
    "         pars_0_vec=pars_init_vec,\n",
    "         pars_true_vec=pars_true_vec, \n",
    "         pars_est_vec=pars_est_vec)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic gradient descent\n",
    "- three variants\n",
    "    - size-1 mini-batches (batch_size = 1), zips through all observed entries of $\\mbox{cov}(y_{t+m},y_t)$ and computes gradients from one at time\n",
    "    - column mini-batches (batch_size = p), zips through all columns of $\\mbox{cov}(y_{t+m},y_t)$ and computes gradients from observed entries \n",
    "    - batch-gradients (batch_size = None), computes a full gradient using all observed entries $\\mbox{cov}(y_{t+m},y_t)$ at the same time\n",
    "    \n",
    "- mini-batch gradients use Adam for following the gradients with momentum and with re-normalising of gradients along each dimension. Full gradients use plain gradient descent.\n",
    "- max_iter is defined as the number of 'zips' through the data set. Thus for different batch sizes, max_iter fixes the amount of information visited within the data covariance matrices, *not* the number of gradient steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.optimize import fmin_bfgs, check_grad\n",
    "import glob, os\n",
    "\n",
    "os.chdir('../core')\n",
    "from utility import get_subpop_stats, draw_sys\n",
    "from SSID_Hankel_loss import f_l2_Hankel, l2_sis_setup, g_l2_Hankel_sis, plot_outputs_l2_gradient_test\n",
    "from SSID_Hankel_loss import yy_Hankel_cov_mat, l2_sis_draw, adam_zip, adam_zip_stable\n",
    "import SDLS\n",
    "os.chdir('../dev')\n",
    "\n",
    "p,n = 10,3\n",
    "k,l = 3,3\n",
    "\n",
    "nr = 3\n",
    "\n",
    "batch_size = p # batch_size = 1 (size-1 mini-batches), p (column mini-batches), None (full gradients)\n",
    "\n",
    "a, a_A, b1, b2, e = 0.0001, 0.0000001, 0.9, 0.99, 1e-8\n",
    "max_iter = 1000\n",
    "\n",
    "gammas = np.array([10e-8])\n",
    "tau = 0.5\n",
    "\n",
    "# create subpopulations\n",
    "sub_pops = (np.arange(0,p//2+1), np.arange(p//2-1,p))\n",
    "\n",
    "# draw system matrices    \n",
    "ev_r = np.linspace(0.8, 0.999, nr)\n",
    "ev_c = np.exp(2 * 1j * np.pi * np.random.uniform(size= (n - nr)//2))\n",
    "ev_c = np.linspace(0.8, 0.999, (n - nr)//2) * ev_c\n",
    "\n",
    "if p < 200:\n",
    "    print('sub_pops', sub_pops)\n",
    "obs_idx, idx_grp, co_obs, overlaps, overlap_grp, idx_overlap, Om, Ovw, Ovc = \\\n",
    "    get_subpop_stats(sub_pops, p, verbose=False)\n",
    "pars_true, Qs, Qs_full = draw_sys(p,n,k,l,Om, nr, ev_r,ev_c)\n",
    "f_base, _ = l2_sis_setup(k,l,n,Qs,Om,idx_grp,obs_idx)\n",
    "\n",
    "\n",
    "\n",
    "def s(A):\n",
    "    s = np.linalg.svd(A)[1]\n",
    "    return np.isfinite( np.log( 1 - s**2 ).sum() )\n",
    "\n",
    "err_est  = np.zeros((gammas.size, 4))\n",
    "eigA_est = np.zeros((gammas.size, n))  \n",
    "for rep in range(gammas.size):\n",
    "    \n",
    "    gamma = gammas[rep]\n",
    "\n",
    "    def f_i(theta):\n",
    "\n",
    "        A = theta[:n*n].reshape(n,n)        \n",
    "        f_log_bar = - np.log( np.linalg.det(np.eye(n)-A.dot(A.T)) )\n",
    "\n",
    "        if gamma == 0 and not np.isfinite(f_log_bar):\n",
    "            f_log_bar = 0\n",
    "\n",
    "        return f_base(theta) + gamma * f_log_bar\n",
    "    \n",
    "    def g_i(theta, idx_use, idx_co):\n",
    "\n",
    "        A = theta[:n*n].reshape(n,n)        \n",
    "        inv = np.linalg.solve(np.eye(n)-A.dot(A.T), np.eye(n))\n",
    "        g_log_bar = np.zeros(theta.size)                                 \n",
    "        g_log_bar[:n*n] = 2 * inv.dot(A).reshape(-1,)\n",
    "\n",
    "        gamma_g_log_bar = gamma * g_log_bar\n",
    "        if gamma == 0:\n",
    "            gamma_g_log_bar[np.invert(np.isfinite(gamma_g_log_bar))] = 0\n",
    "        return g_l2_Hankel_sis(theta,k,l,n,Qs,idx_use,idx_co) + gamma_g_log_bar\n",
    "\n",
    "    A_0  = np.diag(np.random.uniform(low=0.7, high=0.8, size=n))\n",
    "    B_0  = np.eye(n) #np.random.normal(size=(n,n))\n",
    "    C_0  = np.random.normal(size=(p,n))\n",
    "    Pi_0 = B_0.dot(B_0.T)\n",
    "    \n",
    "    pars_0 = np.hstack((A_0.reshape(n*n,),\n",
    "                        B_0.reshape(n*n,),\n",
    "                        C_0.reshape(p*n,)))\n",
    "\n",
    "    def converged(theta_old, theta, e, t):\n",
    "        if t >= max_iter:\n",
    "            return True\n",
    "        return False\n",
    "        #return np.abs(f_i(theta_old) - f_i(theta)) < e\n",
    "    \n",
    "    print('starting descent')\n",
    "    \n",
    "    pars_est_vec, traces = adam_zip_stable(f_i,g_i,s,tau,pars_0.copy(),a,a_A,b1,b2,e,max_iter,converged,Om,idx_grp,co_obs,batch_size)\n",
    "    fs, sig = traces\n",
    "    \n",
    "    A_est = pars_est_vec[:n*n].reshape(n,n)\n",
    "    B_est = pars_est_vec[n*n:2*n*n].reshape(n,n)\n",
    "    Pi_est = B_est.dot(B_est.T)\n",
    "    C_est = pars_est_vec[-p*n:].reshape(p,n)\n",
    "\n",
    "    print('gamma =', gamma)\n",
    "\n",
    "    eigA_est[rep,:] = np.abs(np.sort(np.linalg.eigvals(A_est)))\n",
    "    print('|eig(A_est)|', eigA_est[rep,:])\n",
    "    print('|eig(A_true)|', np.abs(np.sort(np.linalg.eigvals(pars_true['A']))))\n",
    "\n",
    "\n",
    "    err_est[rep,0] = f_l2_Hankel(pars_est_vec,k,l,n,Qs, Om)\n",
    "    err_est[rep,1] = f_l2_Hankel(pars_est_vec,k,l,n,Qs,Ovw)\n",
    "    err_est[rep,2] = f_l2_Hankel(pars_est_vec,k,l,n,Qs,Ovc)\n",
    "    err_est[rep,3] = f_l2_Hankel(pars_est_vec,k,l,n,Qs_full,~Om)\n",
    "\n",
    "    print('final squared error on observed parts:', \n",
    "          err_est[rep,0])\n",
    "    print('final squared error on overlapping parts:', \n",
    "          err_est[rep,1])\n",
    "    print('final squared error on cross-overlapping parts:',\n",
    "          err_est[rep,2])\n",
    "    print('final squared error on stitched parts:',\n",
    "          err_est[rep,3])\n",
    "\n",
    "    pars_init = {'A': A_0, 'C': C_0, 'Pi': Pi_0, 'B': B_0}\n",
    "    pars_est  = {'A': A_est, 'C': C_est, 'Pi': Pi_est, 'B': B_est}\n",
    "    #plot_outputs_l2_gradient_test(pars_true, pars_init, pars_est, k, l, Qs, \n",
    "    #                                   Qs_full, Om, Ovc, Ovw, f_i, g_i, if_flip = True)\n",
    "\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(fs[:max_iter])\n",
    "    plt.ylabel('f')\n",
    "    plt.title('target function error')\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(sig[:max_iter])\n",
    "    plt.ylabel('max sig(A)')\n",
    "    plt.title('maximum singular value of A')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# visualise overall results\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.hsv()\n",
    "plt.plot(err_est)\n",
    "plt.hsv()\n",
    "plt.xticks( np.arange(gammas.size), gammas)\n",
    "plt.xlabel('\\gamma')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend(['obs.', 'overlap', 'cross-overl.', 'stitched'])\n",
    "plt.title('Squared errors as function of log-barrier height')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "clrs = np.zeros((gammas.size, 3))\n",
    "clrs[:,2] = np.linspace(0.05, 0.99, gammas.size)\n",
    "clrs[:,0] = np.linspace(0.05, 0.99, gammas.size)[::-1]\n",
    "for i in range(gammas.size):    \n",
    "    plt.plot(eigA_est[i,:], color=clrs[i,:])\n",
    "    plt.hold(True)\n",
    "plt.plot(np.sort(np.abs(np.linalg.eigvals(pars_true['A']))), 'k')\n",
    "plt.plot([0, 1.1*n], [1, 1], 'r--')\n",
    "plt.hot()\n",
    "plt.xticks( np.arange(n), np.arange(n)+1)\n",
    "plt.xlabel('# eigenvalue')\n",
    "plt.ylabel('EV')\n",
    "lgnd = [np.ceil(gammas[i]*100)/100 for i in range(gammas.size)]\n",
    "lgnd.append('true')\n",
    "lgnd.append('stability')\n",
    "plt.legend(lgnd)\n",
    "plt.axis([0, 1.1*n, plt.ylim()[0], plt.ylim()[1]])\n",
    "plt.title('Eigenvalues as function of log-barrier height')\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# just one more turn..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gamma /= 1000\n",
    "def f_i(theta):\n",
    "\n",
    "    A = theta[:n*n].reshape(n,n)        \n",
    "    f_log_bar = - np.log( np.linalg.det(np.eye(n)-A.dot(A.T)) )\n",
    "\n",
    "    if gamma == 0 and not np.isfinite(f_log_bar):\n",
    "        f_log_bar = 0\n",
    "\n",
    "    return f_base(theta) + gamma * f_log_bar\n",
    "def g_i(theta, idx_use, idx_co):\n",
    "\n",
    "    A = theta[:n*n].reshape(n,n)        \n",
    "    inv = np.linalg.solve(np.eye(n)-A.dot(A.T), np.eye(n))\n",
    "    g_log_bar = np.zeros(theta.size)                                 \n",
    "    g_log_bar[:n*n] = 2 * inv.dot(A).reshape(-1,)\n",
    "\n",
    "    gamma_g_log_bar = gamma * g_log_bar\n",
    "    if gamma == 0:\n",
    "        gamma_g_log_bar[np.invert(np.isfinite(gamma_g_log_bar))] = 0\n",
    "    return g_l2_Hankel_sis(theta,k,l,n,Qs,idx_use,idx_co) + gamma_g_log_bar\n",
    "\n",
    "max_iter = 1000\n",
    "def converged(theta_old, theta, e, t):\n",
    "    if t >= max_iter:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "pars_est_vec, fs = adam_zip_stable(f_i,g_i,s,tau,pars_est_vec.copy(),a,a_A,b1,b2,e,max_iter,converged,Om,idx_grp,co_obs,batch_size)\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(fs[:max_iter])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "A_est = pars_est_vec[:n*n].reshape(n,n)\n",
    "B_est = pars_est_vec[n*n:2*n*n].reshape(n,n)\n",
    "Pi_est = B_est.dot(B_est.T)\n",
    "C_est = pars_est_vec[-p*n:].reshape(p,n)\n",
    "\n",
    "pars_init = {'A': A_0, 'C': C_0, 'Pi': Pi_0, 'B': B_0}\n",
    "pars_est  = {'A': A_est, 'C': C_est, 'Pi': Pi_est, 'B': B_est}\n",
    "plot_outputs_l2_gradient_test(pars_true, pars_init, pars_est, k, l, Qs, \n",
    "                                   Qs_full, Om, Ovc, Ovw, f_i, None, if_flip = True)\n",
    "\n",
    "print('gamma', gamma)\n",
    "print('eigvals[A]', np.linalg.eigvals(pars_est['A']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
