{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# alternating blocked descent\n",
    "\n",
    "- using SGD on $C$\n",
    "- after each pass over the observed parts of the covariance matrix, use analyic solution for $A$, $\\Pi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing time-lagged covariance for lag m = 0\n",
      "computing time-lagged covariance for lag m = 1\n",
      "computing time-lagged covariance for lag m = 2\n",
      "computing time-lagged covariance for lag m = 3\n",
      "computing time-lagged covariance for lag m = 4\n",
      "computing time-lagged covariance for lag m = 5\n",
      "\n",
      "\n",
      "svmem(total=67504091136, available=65053278208, percent=3.6, used=9099210752, free=58404880384, active=2796527616, inactive=5323120640, buffers=541085696, cached=6107312128)\n",
      "sswap(total=68659703808, used=0, free=68659703808, percent=0.0, sin=0, sout=0)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os\n",
    "\n",
    "os.chdir('../core')\n",
    "import SSID_Hankel_loss \n",
    "from utility import get_subpop_stats, draw_sys, gen_data\n",
    "from SSID_Hankel_loss import run_bad, plot_outputs_l2_gradient_test, l2_bad_sis_setup\n",
    "os.chdir('../dev')\n",
    "\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "# load ancient code for drawing from LDS ...\n",
    "os.chdir('../../../../pyRRHDLDS/core')\n",
    "import ssm_scripts\n",
    "import ssm_fit\n",
    "os.chdir('../../code_le_stitch/iterSSID/python/dev')\n",
    "\n",
    "#np.random.seed(0)\n",
    "\n",
    "p,n,nr = 10000, 100, 50\n",
    "k,l = 3,3\n",
    "\n",
    "T = np.inf\n",
    "mmap = True\n",
    "chunksize = np.min((p//2,5000))\n",
    "max_i = p//chunksize\n",
    "max_zip_size = p\n",
    "\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.8, 0.99, 0.8, 0.99\n",
    "\n",
    "batch_size = p # batch_size = 1 (size-1 mini-batches), p (column mini-batches), None (full gradients)\n",
    "lag_range  = 1\n",
    "a, b1, b2, e = 0.001, 0.9, 0.99, 1e-8\n",
    "max_iter_nl  = 10\n",
    "max_iter_lin = 0\n",
    "reps = 1\n",
    "\n",
    "verbose=True\n",
    "\n",
    "# create subpopulations\n",
    "sub_pops = (np.arange(0,p), np.arange(0,p))\n",
    "#sub_pops = (np.arange(p//2), np.arange(p//2,p))\n",
    "\n",
    "\"\"\"\n",
    "len_sub_pops = 9                                            #\n",
    "pop_size = p//5                                             # stochastic turn-over ('funky' observation scheme)\n",
    "sub_pops = [np.arange(pop_size)]                            # \n",
    "for i in range(1,len_sub_pops):\n",
    "    old = np.atleast_1d(np.random.choice(sub_pops[i-1],pop_size//2,replace=False))\n",
    "    assert old.size == pop_size//2\n",
    "    assert np.all([old[j] in sub_pops[i-1] for j in range(old.size)])\n",
    "    new = np.arange((1/2+i/2)*pop_size,((i+1)/2+1/2)*pop_size,dtype=np.int)\n",
    "    sub_pops.append(np.hstack((old,new)))\n",
    "    assert len(sub_pops[-1]) == pop_size\n",
    "\"\"\"\n",
    "#sub_pops = (np.arange(0,200), np.arange(100,300), np.arange(200,400), np.arange(300,p))\n",
    "#sub_pops = (np.arange(0,2*p//10), np.arange(p//10,3*p//10), np.arange(2*p//10,4*p//10), np.arange(3*p//10,5*p//10),\n",
    "#            np.arange(4*p//10,6*p//10), np.arange(5*p//10,7*p//10), np.arange(6*p//10,8*p//10), \n",
    "#            np.arange(7*p//10,9*p//10), np.arange(8*p//10,p))\n",
    "#sub_pops = (np.arange(0,p//2+1), np.arange(p//2-1,p))\n",
    "#sub_pops = (np.arange(10,p), np.arange(0,p-10))\n",
    "\n",
    "obs_idx, idx_grp, co_obs, _, _, _, Om, _, _ = \\\n",
    "    get_subpop_stats(sub_pops=sub_pops, p=p, verbose=False)\n",
    "\n",
    "# draw system matrices    \n",
    "ev_r = np.linspace(eig_m_r, eig_M_r, nr)\n",
    "ev_c = np.exp(2 * 1j * np.pi * np.random.uniform(size= (n - nr)//2))\n",
    "ev_c = np.linspace(eig_m_c, eig_M_c, (n - nr)//2) * ev_c\n",
    "\n",
    "calc_stats = True if T == np.inf else False\n",
    "pars_true, Qs, Qs_full = draw_sys(p=p,n=n,k=k,l=l, nr=nr, ev_r=ev_r,ev_c=ev_c,calc_stats=calc_stats,\n",
    "                                 return_masked=False, mmap=mmap, chunksize = chunksize)\n",
    "pars_true['d'], pars_true['mu0'], pars_true['V0'] = np.zeros(p), np.zeros(n), pars_true['Pi'].copy()\n",
    "\n",
    "#pars_true['R'] = 10e-5 * np.ones(p)\n",
    "#pars_true['Q'] = 10e-10 * np.eye(n)\n",
    "\n",
    "if calc_stats:\n",
    "    x,y = np.zeros((n,0)), np.zeros((p,0))\n",
    "else:\n",
    "    print('computing empirical covariances')\n",
    "    x,y = gen_data(pars=pars_true, T = T ) \n",
    "    for m in range(k+l):\n",
    "        print('computing time-lagged covariance for lag ', str(m))\n",
    "        if mmap:\n",
    "            Q = np.memmap('../fits/Qs_'+str(m), dtype=np.float, mode='w+', shape=(p,p))\n",
    "        for i in range(max_i):\n",
    "            idx_i  = range(i*chunksize, (i+1)*chunksize)\n",
    "            for j in range(max_i):\n",
    "                idx_j = range(j*chunksize, (j+1)*chunksize)\n",
    "                Q[np.ix_(idx_i,idx_j)] = np.cov(y[idx_i,m:m-(k+l)], y[idx_j,:-(k+l)])[:chunksize,chunksize:]     \n",
    "        if mmap:\n",
    "            del Q\n",
    "            Qs_full[m] = np.memmap('../fits/Qs_'+str(m), dtype=np.float, mode='r', shape=(p,p))\n",
    "        Qs[m] = Qs_full[m]\n",
    "        \n",
    "        \n",
    "print('\\n')\n",
    "print(psutil.virtual_memory())\n",
    "print(psutil.swap_memory())\n",
    "\n",
    "#Qs[0] = None     \n",
    "#Qs_full[0] = None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting descent\n",
      "lag_range 1\n",
      "starting extraction of A\n",
      "extracting latent cov. matrix for time-lag m= 1\n",
      "extracting latent cov. matrix for time-lag m= 2\n",
      "extracting latent cov. matrix for time-lag m= 3\n",
      "extracting latent cov. matrix for time-lag m= 4\n",
      "extracting latent cov. matrix for time-lag m= 5\n",
      "using size-p mini-batches (coviarance columms)\n",
      "....................................................................................................  [   100/10000,    0.03sec avg, ETA 05:46 ]\n",
      "....................................................................................................  [   200/10000,    0.03sec avg, ETA 05:41 ]\n",
      "....................................................................................................  [   300/10000,    0.03sec avg, ETA 05:39 ]\n",
      "....................................................................................................  [   400/10000,    0.03sec avg, ETA 05:34 ]\n",
      "....................................................................................................  [   500/10000,    0.03sec avg, ETA 05:29 ]\n",
      "....................................................................................................  [   600/10000,    0.03sec avg, ETA 05:25 ]\n",
      "....................................................................................................  [   700/10000,    0.03sec avg, ETA 05:20 ]\n",
      "....................................................................................................  [   800/10000,    0.03sec avg, ETA 05:16 ]\n",
      "....................................................................................................  [   900/10000,    0.03sec avg, ETA 05:13 ]\n",
      "....................................................................................................  [  1000/10000,    0.03sec avg, ETA 05:09 ]\n",
      "....................................................................................................  [  1100/10000,    0.03sec avg, ETA 05:06 ]\n",
      "....................................................................................................  [  1200/10000,    0.03sec avg, ETA 05:02 ]\n",
      "....................................................................................................  [  1300/10000,    0.03sec avg, ETA 04:58 ]\n",
      "....................................................................................................  [  1400/10000,    0.03sec avg, ETA 04:55 ]\n",
      "....................................................................................................  [  1500/10000,    0.03sec avg, ETA 04:51 ]\n",
      "..................................................................................................."
     ]
    }
   ],
   "source": [
    "for rep in range(reps):        \n",
    "    \n",
    "    t = time.time()\n",
    "    \n",
    "    linearity = 'False'\n",
    "    stable = False\n",
    "    sym_psd = False\n",
    "    pars_init, pars_est, traces = run_bad(k=k,l=l,n=n,Qs=Qs,Om=Om,Qs_full=Qs_full,\n",
    "                                          sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                                          linearity=linearity,stable=stable,init='default',\n",
    "                                          alpha=a,b1=b1,b2=b2,e=e,max_iter=max_iter_nl,batch_size=batch_size,\n",
    "                                          verbose=verbose, sym_psd=sym_psd, lag_range = lag_range, max_zip_size=max_zip_size)\n",
    "    #f_i = l2_sis_setup(k,l,n,Qs,Om,idx_grp,obs_idx)[0] # get f to compute final errors\n",
    "    #plot_outputs_l2_gradient_test(pars_true, pars_init, pars_est, k, l, Qs, \n",
    "    #                                   Qs_full, Om, Ovc, Ovw, f_i, None, traces = traces,\n",
    "    #                                   linearity=linearity, idx_grp = idx_grp, co_obs = co_obs, \n",
    "    #                                   if_flip = True, m = 1)\n",
    "\n",
    "    \n",
    "    print('fitting time was ', time.time() - t)\n",
    "\n",
    "print('\\n')\n",
    "print(psutil.virtual_memory())\n",
    "print(psutil.swap_memory())\n",
    "\n",
    "f_i = l2_bad_sis_setup(k,l,n,Qs,Om,idx_grp,obs_idx,Qs_full,linearity, stable, sym_psd, \n",
    "                            verbose=False, batch_size=batch_size, W=None)[0]\n",
    "plot_outputs_l2_gradient_test(pars_true, pars_init, pars_est, k, l, Qs, \n",
    "                                   Qs_full, Om, Om, Om, f_i, None, traces = traces,\n",
    "                                   linearity=linearity, idx_grp = idx_grp, co_obs = co_obs, \n",
    "                                   if_flip = True, m = 0)\n",
    "\n",
    "pars = pars_est\n",
    "idx1 = np.arange(p) #np.random.choice(p, np.min((p,1000)), replace=False)\n",
    "idx2 = np.arange(p) #np.random.choice(p, np.min((p,1000)), replace=False)\n",
    "for m in range(1,k+l-1):\n",
    "    Qrec = pars['C'][idx1,:].dot(pars['X'][:,m].reshape(n,n)).dot(pars['C'][idx2,:].T) \n",
    "    Qrec = Qrec + np.diag(pars['R'])[np.ix_(idx1,idx2)] if m==0 else Qrec\n",
    "    print('m',m,', corr', \n",
    "    np.corrcoef( Qrec.reshape(-1), (Qs[m][np.ix_(idx1,idx2)]).reshape(-1) )[0,1],', MSE', \n",
    "        np.mean( (Qrec - Qs[m][np.ix_(idx1,idx2)])**2 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "X = SSID_Hankel_loss.s_X_l2_Hankel_fully_obs(pars_true['C'], pars_true['R'], \n",
    "                                                    Qs, k, l, idx_grp, co_obs, \n",
    "                                                    max_i, chunksize)\n",
    "print('took ', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "X = SSID_Hankel_loss.s_X_l2_Hankel_vec(pars_true['C'], pars_true['R'], \n",
    "                                                    Qs, k, l, idx_grp, co_obs)\n",
    "print('took ', time.time() - t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# just one more turn..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_iter_nl = 20000\n",
    "batch_size = None # batch_size = 1 (size-1 mini-batches), p (column mini-batches), None (full gradients)\n",
    "lag_range  = None\n",
    "a = 0.000001\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "pars_init, pars_est, traces = run_bad(k=k,l=l,n=n,Qs=Qs,Om=Om,Qs_full=Qs_full,\n",
    "                                      sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                                      linearity=linearity,stable=stable,init=pars_est,\n",
    "                                      alpha=a,b1=b1,b2=b2,e=e,max_iter=max_iter_nl,batch_size=batch_size,\n",
    "                                      verbose=verbose, sym_psd=sym_psd, lag_range = lag_range, max_zip_size=max_zip_size)\n",
    "\n",
    "\n",
    "print('fitting time was ', time.time() - t)\n",
    "\n",
    "print('\\n')\n",
    "print(psutil.virtual_memory())\n",
    "print(psutil.swap_memory())\n",
    "\n",
    "f_i = l2_bad_sis_setup(k,l,n,Qs,Om,idx_grp,obs_idx,Qs_full,linearity, stable, sym_psd, \n",
    "                            verbose=False, batch_size=batch_size, W=None)[0]\n",
    "plot_outputs_l2_gradient_test(pars_true, pars_init, pars_est, k, l, Qs, \n",
    "                                   Qs_full, Om, Om, Om, f_i, None, traces = traces,\n",
    "                                   linearity=linearity, idx_grp = idx_grp, co_obs = co_obs, \n",
    "                                   if_flip = True, m = 0)\n",
    "pars = pars_est\n",
    "idx1 = np.arange(p) #np.random.choice(p, np.min((p,1000)), replace=False)\n",
    "idx2 = np.arange(p) #np.random.choice(p, np.min((p,1000)), replace=False)\n",
    "for m in range(1,k+l-1):\n",
    "    Qrec = pars['C'][idx1,:].dot(pars['X'][:,m].reshape(n,n)).dot(pars['C'][idx2,:].T) \n",
    "    Qrec = Qrec + np.diag(pars['R'])[np.ix_(idx1,idx2)] if m==0 else Qrec\n",
    "    print('m',m,', corr', \n",
    "    np.corrcoef( Qrec.reshape(-1), (Qs[m][np.ix_(idx1,idx2)]).reshape(-1) )[0,1],', MSE', \n",
    "        np.mean( (Qrec - Qs[m][np.ix_(idx1,idx2)])**2 ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_iter_nl = 200000\n",
    "batch_size = None # batch_size = 1 (size-1 mini-batches), p (column mini-batches), None (full gradients)\n",
    "lag_range  = None\n",
    "a = 0.0000001\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "pars_init, pars_est, traces = run_bad(k=k,l=l,n=n,Qs=Qs,Om=Om,Qs_full=Qs_full,\n",
    "                                      sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                                      linearity=linearity,stable=stable,init=pars_est,\n",
    "                                      alpha=a,b1=b1,b2=b2,e=e,max_iter=max_iter_nl,batch_size=batch_size,\n",
    "                                      verbose=verbose, sym_psd=sym_psd, lag_range = lag_range, max_zip_size=max_zip_size)\n",
    "\n",
    "\n",
    "print('fitting time was ', time.time() - t)\n",
    "\n",
    "print('\\n')\n",
    "print(psutil.virtual_memory())\n",
    "print(psutil.swap_memory())\n",
    "\n",
    "f_i = l2_bad_sis_setup(k,l,n,Qs,Om,idx_grp,obs_idx,Qs_full,linearity, stable, sym_psd, \n",
    "                            verbose=False, batch_size=batch_size, W=None)[0]\n",
    "plot_outputs_l2_gradient_test(pars_true, pars_init, pars_est, k, l, Qs, \n",
    "                                   Qs_full, Om, Om, Om, f_i, None, traces = traces,\n",
    "                                   linearity=linearity, idx_grp = idx_grp, co_obs = co_obs, \n",
    "                                   if_flip = True, m = 0)\n",
    "pars = pars_est\n",
    "idx1 = np.arange(p) #np.random.choice(p, np.min((p,1000)), replace=False)\n",
    "idx2 = np.arange(p) #np.random.choice(p, np.min((p,1000)), replace=False)\n",
    "for m in range(1,k+l-1):\n",
    "    Qrec = pars['C'][idx1,:].dot(pars['X'][:,m].reshape(n,n)).dot(pars['C'][idx2,:].T) \n",
    "    Qrec = Qrec + np.diag(pars['R'])[np.ix_(idx1,idx2)] if m==0 else Qrec\n",
    "    print('m',m,', corr', \n",
    "    np.corrcoef( Qrec.reshape(-1), (Qs[m][np.ix_(idx1,idx2)]).reshape(-1) )[0,1],', MSE', \n",
    "        np.mean( (Qrec - Qs[m][np.ix_(idx1,idx2)])**2 ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_iter_nl = 200000\n",
    "batch_size = None # batch_size = 1 (size-1 mini-batches), p (column mini-batches), None (full gradients)\n",
    "lag_range  = None\n",
    "a = 0.0000001\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "pars_init, pars_est, traces = run_bad(k=k,l=l,n=n,Qs=Qs,Om=Om,Qs_full=Qs_full,\n",
    "                                      sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                                      linearity=linearity,stable=stable,init=pars_est,\n",
    "                                      alpha=a,b1=b1,b2=b2,e=e,max_iter=max_iter_nl,batch_size=batch_size,\n",
    "                                      verbose=verbose, sym_psd=sym_psd, lag_range = lag_range, max_zip_size=max_zip_size)\n",
    "\n",
    "\n",
    "print('fitting time was ', time.time() - t)\n",
    "\n",
    "print('\\n')\n",
    "print(psutil.virtual_memory())\n",
    "print(psutil.swap_memory())\n",
    "\n",
    "f_i = l2_bad_sis_setup(k,l,n,Qs,Om,idx_grp,obs_idx,Qs_full,linearity, stable, sym_psd, \n",
    "                            verbose=False, batch_size=batch_size, W=None)[0]\n",
    "plot_outputs_l2_gradient_test(pars_true, pars_init, pars_est, k, l, Qs, \n",
    "                                   Qs_full, Om, Om, Om, f_i, None, traces = traces,\n",
    "                                   linearity=linearity, idx_grp = idx_grp, co_obs = co_obs, \n",
    "                                   if_flip = True, m = 0)\n",
    "pars = pars_est\n",
    "idx1 = np.arange(p) #np.random.choice(p, np.min((p,1000)), replace=False)\n",
    "idx2 = np.arange(p) #np.random.choice(p, np.min((p,1000)), replace=False)\n",
    "for m in range(1,k+l-1):\n",
    "    Qrec = pars['C'][idx1,:].dot(pars['X'][:,m].reshape(n,n)).dot(pars['C'][idx2,:].T) \n",
    "    Qrec = Qrec + np.diag(pars['R'])[np.ix_(idx1,idx2)] if m==0 else Qrec\n",
    "    print('m',m,', corr', \n",
    "    np.corrcoef( Qrec.reshape(-1), (Qs[m][np.ix_(idx1,idx2)]).reshape(-1) )[0,1],', MSE', \n",
    "        np.mean( (Qrec - Qs[m][np.ix_(idx1,idx2)])**2 ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Qs[0] = None\n",
    "Qs_full[0] = None\n",
    "\n",
    "max_iter_nl = 1000\n",
    "batch_size = p # batch_size = 1 (size-1 mini-batches), p (column mini-batches), None (full gradients)\n",
    "lag_range  = None\n",
    "a = 0.001\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "pars_init, pars_est, traces = run_bad(k=k,l=l,n=n,Qs=Qs,Om=Om,Qs_full=Qs_full,\n",
    "                                      sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                                      linearity=linearity,stable=stable,init=pars_est,\n",
    "                                      alpha=a,b1=b1,b2=b2,e=e,max_iter=max_iter_nl,batch_size=batch_size,\n",
    "                                      verbose=verbose, sym_psd=sym_psd, lag_range = lag_range, max_zip_size=max_zip_size)\n",
    "\n",
    "\n",
    "print('fitting time was ', time.time() - t)\n",
    "\n",
    "print('\\n')\n",
    "print(psutil.virtual_memory())\n",
    "print(psutil.swap_memory())\n",
    "\n",
    "f_i = l2_bad_sis_setup(k,l,n,Qs,Om,idx_grp,obs_idx,Qs_full,linearity, stable, sym_psd, \n",
    "                            verbose=False, batch_size=batch_size, W=None)[0]\n",
    "plot_outputs_l2_gradient_test(pars_true, pars_init, pars_est, k, l, Qs, \n",
    "                                   Qs_full, Om, Om, Om, f_i, None, traces = traces,\n",
    "                                   linearity=linearity, idx_grp = idx_grp, co_obs = co_obs, \n",
    "                                   if_flip = True, m = 0)\n",
    "pars = pars_est\n",
    "idx1 = np.arange(p) #np.random.choice(p, np.min((p,1000)), replace=False)\n",
    "idx2 = np.arange(p) #np.random.choice(p, np.min((p,1000)), replace=False)\n",
    "for m in range(1,k+l-1):\n",
    "    Qrec = pars['C'][idx1,:].dot(pars['X'][:,m].reshape(n,n)).dot(pars['C'][idx2,:].T) \n",
    "    Qrec = Qrec + np.diag(pars['R'])[np.ix_(idx1,idx2)] if m==0 else Qrec\n",
    "    print('m',m,', corr', \n",
    "    np.corrcoef( Qrec.reshape(-1), (Qs[m][np.ix_(idx1,idx2)]).reshape(-1) )[0,1],', MSE', \n",
    "        np.mean( (Qrec - Qs[m][np.ix_(idx1,idx2)])**2 ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = 5\n",
    "pars = pars_est\n",
    "idx1 = np.arange(0, p//2)\n",
    "idx2 = np.arange(p//2, p)\n",
    "\n",
    "Qrec = pars['C'][idx1,:].dot(pars['X'][:,m].reshape(n,n)).dot(pars['C'][idx2,:].T) \n",
    "Qrec = Qrec + np.diag(pars['R'])[np.ix_(idx1,idx2)] if m==0 else Qrec\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(Qs_full[m][np.ix_(idx1,idx2)], interpolation='none')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(Qrec, interpolation='none')\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(Qrec.reshape(-1,), Qs[m][np.ix_(idx1,idx2)].reshape(-1,), '.')\n",
    "\n",
    "print('corr', np.corrcoef(Qrec.reshape(-1,), Qs[m][np.ix_(idx1,idx2)].reshape(-1,))[0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oops... (recovering broken run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.optimize import fmin_bfgs, check_grad\n",
    "import glob, os\n",
    "\n",
    "os.chdir('../core')\n",
    "import SSID_Hankel_loss \n",
    "from utility import get_subpop_stats, draw_sys, gen_data\n",
    "from SSID_Hankel_loss import run_bad, plot_outputs_l2_gradient_test, l2_bad_sis_setup\n",
    "os.chdir('../dev')\n",
    "\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "# load ancient code for drawing from LDS ...\n",
    "os.chdir('../../../../pyRRHDLDS/core')\n",
    "import ssm_scripts\n",
    "import ssm_fit\n",
    "os.chdir('../../code_le_stitch/iterSSID/python/dev')\n",
    "\n",
    "\n",
    "from scipy.io import savemat # store results for comparison with Matlab code   \n",
    "\n",
    "os.chdir('../fits/')\n",
    "\n",
    "save_file = np.load('test_global_opt__Tinf_p100n10r2.npz')\n",
    "p,n,T,k,l = save_file['p'], save_file['n'], save_file['T'], save_file['k'], save_file['l']\n",
    "pars_true, batch_size = save_file['pars_true'], save_file['batch_size']\n",
    "pars_est, pars_init = save_file['pars_est'], save_file['pars_init']\n",
    "\n",
    "del save_file\n",
    "\n",
    "Qs_full, Qs = [], []\n",
    "for m in range(k+l):\n",
    "    print('loading time-lagged covariance for lag ', str(m))\n",
    "    Qs_full.append(np.memmap('Qs_'+str(m), dtype=np.float, mode='r', shape=(p,p)))\n",
    "    Qs.append(Qs_full[m])\n",
    "\n",
    "\n",
    "sub_pops = (np.arange(p//2), np.arange(p//2,p))\n",
    "obs_idx, idx_grp, co_obs, _, _, _, Om, _, _ = \\\n",
    "    get_subpop_stats(sub_pops=sub_pops, p=p, verbose=False)\n",
    "chunksize = 5000\n",
    "max_i = p//chunksize\n",
    "max_zip_size = 5000\n",
    "\n",
    "batch_size = p # batch_size = 1 (size-1 mini-batches), p (column mini-batches), None (full gradients)\n",
    "\n",
    "a, b1, b2, e = 0.001, 0.9, 0.99, 1e-8\n",
    "max_iter_nl  = 1\n",
    "max_iter_lin = 0\n",
    "reps = 1    \n",
    "\n",
    "verbose=True\n",
    "    \n",
    "        \n",
    "print('\\n')\n",
    "print(psutil.virtual_memory())\n",
    "print(psutil.swap_memory())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyse results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAAJKCAYAAAC7yVWMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDicaDS1PAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0ce03b2550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_,X,_ = SSID_Hankel_loss.s_A_l2_Hankel_bad_sis(pars_true['C'],pars_true['R'],k,l,Qs_full,idx_grp,co_obs, \n",
    "                            linear=False, linearise_X=False, stable=False,\n",
    "                            A_old=None,verbose=False)\n",
    "\n",
    "m = 0\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(X[:,m].reshape(n,n),interpolation='none')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(np.linalg.matrix_power(pars_true['A'],m).dot(pars_true['Pi']),interpolation='none')\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(X[:,m].reshape(n,n).reshape(-1,), \n",
    "         np.linalg.matrix_power(pars_true['A'],m).dot(pars_true['Pi']).reshape(-1,),'k.')\n",
    "plt.hold(True)\n",
    "ml = np.min(X[:,1].reshape(n,n).reshape(-1,))\n",
    "Ml = np.max(X[:,1].reshape(n,n).reshape(-1,))\n",
    "plt.plot([ml,Ml], [ml,Ml], 'r')\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pars = pars_est\n",
    "idx = np.random.choice(p, np.min((p,1000)), replace=False)\n",
    "for m in range(0,k+l-1):\n",
    "    print('m',m,', corr', \n",
    "          np.corrcoef( (pars['C'][idx,:].dot(pars['X'][:,m].reshape(n,n)).dot(pars['C'][idx,:].T)).reshape(-1), \n",
    "                       (Qs[m+1][np.ix_(idx,idx)]).reshape(-1) )[0,1],', MSE', \n",
    "          np.mean( (pars['C'][idx,:].dot(pars['X'][:,m].reshape(n,n)).dot(pars['C'][idx,:].T) - Qs[m+1][np.ix_(idx,idx)])**2 ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pars = pars_true\n",
    "idx = np.random.choice(p, np.min((p,1000)), replace=False)\n",
    "for m in range(0,k+l-1):\n",
    "    AmPi = np.linalg.matrix_power(pars['A'],m+1).dot(pars['Pi'])\n",
    "    print('m',m,', corr', \n",
    "          np.corrcoef( (pars['C'][idx,:].dot(AmPi).dot(pars['C'][idx,:].T)).reshape(-1), \n",
    "                       (Qs[m+1][np.ix_(idx,idx)]).reshape(-1) )[0,1],', MSE', \n",
    "          np.mean( (pars['C'][idx,:].dot(AmPi).dot(pars['C'][idx,:].T) - Qs[m+1][np.ix_(idx,idx)])**2 ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_i = l2_sis_setup(k,l,n,Qs,Om,idx_grp,obs_idx)[0] # get f to compute final errors\n",
    "plot_outputs_l2_gradient_test(pars_true, pars_init, pars_est, k, l, Qs, \n",
    "                                   Qs, Om, Om, Om, f_i, None, traces = traces,\n",
    "                                   linearity=linearity, idx_grp = idx_grp, co_obs = co_obs, \n",
    "                                   if_flip = True, m = 0)\n",
    "pars = pars_est\n",
    "idx = np.random.choice(p, np.min((p,1000)), replace=False)\n",
    "for m in range(0,k+l-1):\n",
    "    print('m',m,', corr', \n",
    "          np.corrcoef( (pars['C'][idx,:].dot(pars['X'][:,m].reshape(n,n)).dot(pars['C'][idx,:].T)).reshape(-1), \n",
    "                       (Qs[m+1][np.ix_(idx,idx)]).reshape(-1) )[0,1],', MSE', \n",
    "          np.mean( (pars['C'][idx,:].dot(pars['X'][:,m].reshape(n,n)).dot(pars['C'][idx,:].T) - Qs[m+1][idx,idx])**2 ))\n",
    "\n",
    "plt.plot(pars_true['R'], pars_est['R'], 'k.')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = 0\n",
    "plt.figure(figsize=(20,10))\n",
    "idx1 = range(p//2)\n",
    "idx2 = range(p//2,p)\n",
    "\n",
    "pars = pars_true\n",
    "X = np.linalg.matrix_power(pars['A'], m).dot(pars['Pi'])\n",
    "plt.subplot(1,3,1)\n",
    "cov_true = pars['C'][idx1,:].dot(X).dot(pars['C'][idx2,:].T)\n",
    "if m == 0:\n",
    "    cov_true += np.diag(pars['R'])[np.ix_(idx1,idx2)]\n",
    "plt.imshow( cov_true, interpolation='none')\n",
    "\n",
    "pars = pars_est\n",
    "X = pars['X'][:,m].reshape(n,n)\n",
    "plt.subplot(1,3,2)\n",
    "cov_est = pars['C'][idx1,:].dot(X).dot(pars['C'][idx2,:].T)\n",
    "if m == 0:\n",
    "    cov_est += np.diag(pars['R'])[np.ix_(idx1,idx2)]\n",
    "plt.imshow( cov_est, interpolation='none')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(cov_true.reshape(-1,), cov_est.reshape(-1,), 'k.')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "np.random.randint(k+l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_iter_ln = 200\n",
    "\n",
    "linearity = 'True'\n",
    "stable = False\n",
    "_, pars_est, traces = run_bad(k=k,l=l,n=n,Qs=Qs_full,Om=Om,\n",
    "                              sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                              linearity=linearity,stable=stable,init=pars_est,\n",
    "                              a=a,b1=b1,b2=b2,e=e,max_iter=max_iter_ln,batch_size=batch_size)\n",
    "f_i = l2_sis_setup(k,l,n,Qs,Om,idx_grp,obs_idx)[0] # get f to compute final errors\n",
    "plot_outputs_l2_gradient_test(pars_true, pars_init, pars_est, k, l, Qs, \n",
    "                                   Qs_full, Om, Ovc, Ovw, f_i, None, traces = traces,\n",
    "                                   linearity=linearity,  idx_grp = idx_grp, co_obs = co_obs, \n",
    "                                   if_flip = True, m = 1)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.io import savemat # store results for comparison with Matlab code   \n",
    "\n",
    "os.chdir('../fits/')\n",
    "\n",
    "save_file = 'test_global_opt__Tinf_p100n10r2_4'\n",
    "\n",
    "\n",
    "np.savez(save_file, \n",
    "         pars_init=pars_init,\n",
    "         pars_true=pars_true, \n",
    "         pars_est=pars_est,\n",
    "         p=p,\n",
    "         n=n,\n",
    "         T=T,\n",
    "         k=k,\n",
    "         l=l,\n",
    "         batch_size=batch_size,\n",
    "         linearity=linearity)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len_record = 15\n",
    "len_sub_pops = 4\n",
    "sub_pops = []\n",
    "for i in range(len_sub_pops):\n",
    "    sub_pops.append(np.arange(i*p//len_sub_pops,(i+1)*p//len_sub_pops))\n",
    "len_sub_pops = len(sub_pops)\n",
    "plt.figure(figsize=(10,10))\n",
    "fig, ax = plt.subplots()\n",
    "Om = np.ones((p,len_record))\n",
    "for i in range(len_record):\n",
    "    Om[sub_pops[np.mod(i,len_sub_pops)],i] = 0\n",
    "\n",
    "#for i in range(len_record//2):\n",
    "#    Om[sub_pops[0],i] = 0\n",
    "#for i in range(len_record//2,len_record):\n",
    "#    Om[sub_pops[1],i] = 0\n",
    "\n",
    "ax.imshow(np.flipud(Om), aspect=0.01, interpolation='none')\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(10) \n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "                #tick.label.set_fontsize(10) \n",
    "                tick.label.set_label('')\n",
    "plt.xlabel('frames', fontsize=14)\n",
    "plt.title('temporal profile of units recorded', fontsize=14)\n",
    "plt.ylabel('# unit', fontsize=14)\n",
    "plt.gray()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_pops = (np.arange(p//2), np.arange(p//2,p))\n",
    "len_sub_pops = len(sub_pops)\n",
    "Om = np.zeros((p,p))\n",
    "for i in range(len_sub_pops):\n",
    "    Om[np.ix_(sub_pops[i],sub_pops[i])] = 1\n",
    "Om[0,999]=0    \n",
    "plt.figure(figsize=(10,10))\n",
    "_,ax = plt.subplots()\n",
    "plt.imshow(Om, interpolation='none')\n",
    "sub_pops = tuple(sub_pops)\n",
    "print(np.mean(Om))\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(10) \n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(10) \n",
    "plt.xlabel('# units', fontsize=15)\n",
    "plt.ylabel('# units', fontsize=15)\n",
    "plt.title('pair-wise observation mask', fontsize=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sub_pops = (np.arange(0,2*p//10), np.arange(p//10,3*p//10), np.arange(2*p//10,4*p//10), np.arange(3*p//10,5*p//10),\n",
    "#            np.arange(4*p//10,6*p//10), np.arange(5*p//10,7*p//10), np.arange(6*p//10,8*p//10), \n",
    "#            np.arange(7*p//10,9*p//10), np.arange(8*p//10,p))\n",
    "plt.figure(figsize=(10,10))\n",
    "fig, ax = plt.subplots()\n",
    "Om = np.ones((p,len_sub_pops))\n",
    "for i in range(len_sub_pops):\n",
    "    Om[sub_pops[i],i] = 0\n",
    "ax.imshow(np.flipud(Om), aspect=0.001, interpolation='none')\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(10) \n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(10) \n",
    "plt.xlabel('days', fontsize=14)\n",
    "plt.title('temporal profile of units recorded', fontsize=14)\n",
    "plt.ylabel('# unit', fontsize=14)\n",
    "plt.gray()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "ax=plt.subplot(3,1,1)\n",
    "plt.plot(np.arange(max_iter_nl), np.log(traces[0]), 'b', linewidth=2.5)\n",
    "plt.title('log squared Hankel reconstruction error vs. iterations', fontsize=30)\n",
    "plt.ylabel('log(SE)', fontsize=30)\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(20) \n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(20) \n",
    "\n",
    "ax=plt.subplot(3,1,2)\n",
    "plt.title('correlations of covariances vs. iterations', fontsize=30)\n",
    "plt.plot(np.linspace(0,100,11), (traces[1][0,:]), 'g', linewidth=2.5)\n",
    "plt.hold(True)\n",
    "plt.plot(np.linspace(0,100,11), (traces[1][1,:]), 'b--', linewidth=2.5)\n",
    "plt.legend(('observed covs', 'non-observed covs'), fontsize=20)\n",
    "plt.axis([0,100,0.0,1.05])\n",
    "plt.ylabel('corrs', fontsize=30)\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(20) \n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(20) \n",
    "\n",
    "ax=plt.subplot(3,1,3)\n",
    "plt.title('zoom-in on high correlations', fontsize=30)\n",
    "plt.plot(np.linspace(0,100,11), (traces[1][0,:]), 'g', linewidth=2.5)\n",
    "plt.hold(True)\n",
    "plt.plot(np.linspace(0,100,11), (traces[1][1,:]), 'b--', linewidth=2.5)\n",
    "plt.plot([0,100],[1.,1.], 'r--')\n",
    "plt.axis([0,100,0.98,1.001])\n",
    "plt.ylabel('corrs', fontsize=30)\n",
    "plt.xlabel('iterations', fontsize=30)\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(20) \n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(20) \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check linearity of extracted latent covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import SDLS\n",
    "import cvxopt\n",
    "\n",
    "apply_transform = False\n",
    "sym_psd = False\n",
    "\n",
    "# pick which parameter set to use \n",
    "pars = pars_init\n",
    "\n",
    "\n",
    "# pick observation scheme\n",
    "\n",
    "#sub_pops = (np.arange(p//2), np.arange(p//2,p))            # two sub-pops, no overlap (50 % observed)\n",
    "sub_pops = (np.arange(p), np.arange(p))                    # fully observed\n",
    "\"\"\"\n",
    "len_sub_pops = 9                                            #\n",
    "pop_size = p//5                                             # stochastic turn-over ('funky' observation scheme)\n",
    "sub_pops = [np.arange(pop_size)]                            # \n",
    "for i in range(1,len_sub_pops):\n",
    "    old = np.atleast_1d(np.random.choice(sub_pops[i-1],pop_size//2,replace=False))\n",
    "    assert old.size == pop_size//2\n",
    "    assert np.all([old[j] in sub_pops[i-1] for j in range(old.size)])\n",
    "    new = np.arange((1/2+i/2)*pop_size,((i+1)/2+1/2)*pop_size,dtype=np.int)\n",
    "    sub_pops.append(np.hstack((old,new)))\n",
    "    assert len(sub_pops[-1]) == pop_size\n",
    "\"\"\"\n",
    "\n",
    "# get relevant subpopulation stats (indices, co-observation patterns)\n",
    "obs_idx, idx_grp, co_obs, overlaps, overlap_grp, idx_overlap, Om, Ovw, Ovc = \\\n",
    "    get_subpop_stats(sub_pops=sub_pops, p=p, verbose=False)\n",
    "\n",
    "# get latent covariance matrices (using same function as is part of the main code)\n",
    "_, X = SSID_Hankel_loss.s_A_l2_Hankel_bad_sis(pars['C'],k,l,Qs,idx_grp,co_obs, linear=True,stable=False,A_old=None)\n",
    "\n",
    "# compute linear transformation of latent covariance represenation\n",
    "C = pars['C']\n",
    "Ct = pars_true['C']\n",
    "M1 = np.zeros((n**2, n**2))\n",
    "M2 = np.zeros((n**2, n**2))\n",
    "for i in range(len(idx_grp)):\n",
    "    a,b = idx_grp[i], co_obs[i]\n",
    "    M1 += np.kron(C[b,:].T.dot(C[b,:]), C[a,:].T.dot(C[a,:]))\n",
    "    M2 += np.kron(C[b,:].T.dot(Ct[b,:]), C[a,:].T.dot(Ct[a,:]))        \n",
    "M = np.linalg.inv(M2).dot(M1)\n",
    "\n",
    "# apply transform (or not)\n",
    "if apply_transform:\n",
    "    for m in range(k+l-1): # python X.reshape(-1) does vec(X.T), need to 'un-transpose'\n",
    "        X[:,m] = (X[:,m].reshape(n,n).T).reshape(-1,)\n",
    "    X = M.dot(X)\n",
    "    for m in range(k+l-1):\n",
    "        X[:,m] = (X[:,m].reshape(n,n).T).reshape(-1,)  # 're-un-transposing'     \n",
    "\n",
    "# now get A given the (potentially transformed) latent covariances\n",
    "cvxopt.solvers.options['show_progress'] = False\n",
    "X1,X2 = np.zeros((n, n*(k+l-2))), np.zeros((n, n*(k+l-2)))\n",
    "for m in range(k+l-2):\n",
    "    X1[:,m*n:(m+1)*n] = X[:,m].reshape(n,n)\n",
    "    X2[:,m*n:(m+1)*n] = X[:,m+1].reshape(n,n)\n",
    "P = cvxopt.matrix( np.kron(np.eye(n), X1.dot(X1.T)), tc='d')\n",
    "q = cvxopt.matrix( - (X2.dot(X1.T)).reshape(n**2,), tc='d')\n",
    "#r = np.trace(X2.T.dot(X2))/2\n",
    "sol = cvxopt.solvers.qp(P=P,q=q)\n",
    "assert sol['status'] == 'optimal'\n",
    "A = np.asarray(sol['x']).reshape(n,n)\n",
    "    \n",
    "    \n",
    "    \n",
    "print( np.mean((pars['C'].dot(X[:,0].reshape(n,n).dot(pars['C'].T)) - Qs[1])**2) )\n",
    "\n",
    "print('checking MSE solution for A')\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(A, interpolation='none')\n",
    "plt.title('MSE solution for A')\n",
    "plt.subplot(1,2,2)\n",
    "try:\n",
    "    plt.imshow(pars['A'], interpolation='none')\n",
    "except:\n",
    "    pass\n",
    "plt.title('pars[A]')\n",
    "plt.show()\n",
    "\n",
    "try:\n",
    "    print('eig(pars[A])', np.sort(np.linalg.eigvals(pars['A'])))\n",
    "except:\n",
    "    pass\n",
    "print('eig(A_rec)', np.sort(np.linalg.eigvals(A)))\n",
    "print('MSE A: ', np.mean((pars['A'] - A)**2))\n",
    "\n",
    "\n",
    "X1,X2 = np.zeros((n, n*(k+l-2))), np.zeros((n, n*(k+l-2)))\n",
    "for m in range(k+l-2):\n",
    "    X1[:,m*n:(m+1)*n] = X[:,m].reshape(n,n)\n",
    "    X2[:,m*n:(m+1)*n] = X[:,m+1].reshape(n,n)\n",
    "\n",
    "AX1     = np.zeros((n*(k+l-1),n))\n",
    "As = np.empty((n*(k+l-1),n))\n",
    "XT = np.empty((n*(k+l-1),n))\n",
    "for m_ in range(k+l-1):\n",
    "    XT[m_*n:(m_+1)*n,:] = X[:,m_].reshape(n,n)\n",
    "    As[m_*n:(m_+1)*n,:] = np.linalg.matrix_power(A,m_+1)\n",
    "for m_ in range(1,k+l-1):\n",
    "    AX1[(m_)*n:(m_+1)*n,:] = A.dot(XT[(m_-1)*n:m_*n,:])\n",
    "    \n",
    "Pie = SSID_Hankel_loss.s_Pi_l2_Hankel_bad_sis(X,A,k,l,Qs,Pi=None,verbose=True, sym_psd=sym_psd)\n",
    "\n",
    "print('MSE Pi: ', np.mean((pars['Pi'] - Pie)**2))\n",
    "\n",
    "print('MSE for As Pi - Xms' , np.mean((As.dot(Pie) - XT)**2) )\n",
    "\n",
    "\n",
    "for m in range(1,k+l):\n",
    "    print('checking MSE solution for X, m = ', m)\n",
    "    AmPi = np.linalg.matrix_power(A,m ).dot(Pie)\n",
    "    X_m  = X[:,m-1].reshape(n,n)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow( AmPi, interpolation='none')\n",
    "    plt.title('pars cov(x_{t+m), x_t) = A^m Pi')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow( X_m, interpolation='none')\n",
    "    plt.title('est. cov(x_{t+m), x_t) = C^d Qs[m] C^d.T')\n",
    "    #print( 'A^m Pi - X_m' , np.mean((AmPi - X_m)**2) )\n",
    "    #print( 'A^m Pi - X_m^T' , np.mean((AmPi - X_m.T)**2) )\n",
    "\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow( np.linalg.matrix_power(A,m ).dot(Pie), interpolation='none')\n",
    "plt.title('reconstr. cov(x_{t+m), x_t) = A_hat^m Pi_hat')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(XT.T, interpolation='none')\n",
    "plt.title('data est. for latent covs')\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow( AX1.T, interpolation='none')\n",
    "plt.title('A * [X1, X2, ...]')\n",
    "#plt.subplot(4,1,3)\n",
    "#plt.imshow((As.dot(pars['Pi'])).T, interpolation='none')\n",
    "#plt.title('param est. for latent covs, using pars[Pi]')\n",
    "plt.subplot(3,1,3)\n",
    "plt.imshow((As.dot(Pie)).T, interpolation='none')\n",
    "plt.title('param est. for latent covs, using MSE Pi')\n",
    "plt.show()\n",
    "print( 'A^m Pi - X_m' , np.mean((np.linalg.matrix_power(A,m).dot(Pie) - X[:,m-1].reshape(n,n))**2) )\n",
    "print( 'A X_{m-1} - X_m' , np.mean((AX1[n:,:] - XT[n:,:])**2) )\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(XT.reshape(-1,), XT.reshape(-1,), 'k.')\n",
    "plt.title('recov. cov vs. recov. cov (for scales)')\n",
    "print('corrcoef: ', np.corrcoef(XT.reshape(-1,), XT.reshape(-1,))[0,1], \n",
    "      'SE, ', np.sum( (XT.reshape(-1,) - XT.reshape(-1,))**2))\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(XT[n:,:].reshape(-1,), AX1[n:,:].reshape(-1,),'k.')\n",
    "plt.title('recov. cov vs. first-order reconstruction')\n",
    "print('corrcoef: ', np.corrcoef(XT[n:,:].reshape(-1,), AX1[n:,:].reshape(-1,))[0,1], \n",
    "      'SE, ', np.sum( (XT[n:,:].reshape(-1,) - AX1[n:,:].reshape(-1,))**2))\n",
    "#plt.subplot(1,4,3)\n",
    "#plt.plot(XT.reshape(-1,), (As.dot(pars['Pi'])).reshape(-1,), 'k.')\n",
    "#plt.title('recov. cov vs. full reconstruction with pars[Pi]')\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(XT.reshape(-1,), (As.dot(Pie)).reshape(-1,), 'k.')\n",
    "plt.title('recov. cov vs. full reconstruction with least-squares Pi')\n",
    "print('corrcoef: ', np.corrcoef(XT.reshape(-1,), (As.dot(Pie)).reshape(-1,))[0,1], \n",
    "      'SE, ', np.sum( (XT.reshape(-1,) - (As.dot(Pie)).reshape(-1,))**2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f0():\n",
    "    \n",
    "    pass\n",
    "\n",
    "def F(x=None,z=None):\n",
    "    \n",
    "    if x is None and z is None:\n",
    "        return 0, cvxopt.matrix(np.eye(n).reshape(-1), tc='d')\n",
    "    elif z is None:\n",
    "        return f0(x), \n",
    "    else:\n",
    "\n",
    "\n",
    "Pie = cvxopt.sdls(A=As,B=XT, X0=0.5*pars['Pi'],Y0=None,tol=1e-3,verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Pi_ = np.linalg.lstsq(a=As,b=XT)[0]\n",
    "#plt.imshow(Pi_, interpolation='none')\n",
    "#plt.show()\n",
    "print(Pi_)\n",
    "\n",
    "np.linalg.lstsq?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(pars_init['C'].T, interpolation='none')\n",
    "plt.show()\n",
    "plt.imshow(pars_true['C'].T, interpolation='none')\n",
    "plt.show()\n",
    "plt.plot(pars_true['C'].reshape(-1), pars_init['C'].reshape(-1), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import SDLS\n",
    "import cvxopt\n",
    "\n",
    "# pick observation scheme\n",
    "\n",
    "sub_pops = (np.arange(p//2), np.arange(p//2,p))            # two sub-pops, no overlap (50 % observed)\n",
    "#sub_pops = (np.arange(p), np.arange(p))                    # fully observed\n",
    "\"\"\"\n",
    "len_sub_pops = 9                                            #\n",
    "pop_size = p//5                                             # stochastic turn-over ('funky' observation scheme)\n",
    "sub_pops = [np.arange(pop_size)]                            # \n",
    "for i in range(1,len_sub_pops):\n",
    "    old = np.atleast_1d(np.random.choice(sub_pops[i-1],pop_size//2,replace=False))\n",
    "    assert old.size == pop_size//2\n",
    "    assert np.all([old[j] in sub_pops[i-1] for j in range(old.size)])\n",
    "    new = np.arange((1/2+i/2)*pop_size,((i+1)/2+1/2)*pop_size,dtype=np.int)\n",
    "    sub_pops.append(np.hstack((old,new)))\n",
    "    assert len(sub_pops[-1]) == pop_size\n",
    "\"\"\"\n",
    "\n",
    "# get relevant subpopulation stats (indices, co-observation patterns)\n",
    "obs_idx, idx_grp, co_obs, overlaps, overlap_grp, idx_overlap, Om, Ovw, Ovc = \\\n",
    "    get_subpop_stats(sub_pops=sub_pops, p=p, verbose=False)\n",
    "\n",
    "# pick which parameter set to use \n",
    "pars = pars_init\n",
    "\n",
    "# get latent covariance matrices (using same function as is part of the main code)\n",
    "_, X = SSID_Hankel_loss.s_A_l2_Hankel_bad_sis(pars['C'],k,l,Qs,idx_grp,co_obs, linear=True,stable=False,A_old=None)\n",
    "\n",
    "# compute linear transformation of latent covariance represenation\n",
    "C = pars['C']\n",
    "Ct = pars_true['C']\n",
    "M1 = np.zeros((n**2, n**2))\n",
    "M2 = np.zeros((n**2, n**2))\n",
    "for i in range(len(idx_grp)):\n",
    "    a,b = idx_grp[i], co_obs[i]\n",
    "    M1 += np.kron(C[b,:].T.dot(C[b,:]), C[a,:].T.dot(C[a,:]))\n",
    "    M2 += np.kron(C[b,:].T.dot(Ct[b,:]), C[a,:].T.dot(Ct[a,:]))        \n",
    "M = np.linalg.inv(M2).dot(M1)\n",
    "\n",
    "# apply transform (or not)\n",
    "apply_transform = True\n",
    "\n",
    "if apply_transform:\n",
    "    for m in range(k+l-1):\n",
    "        X[:,m] = (X[:,m].reshape(n,n).T).reshape(-1,)\n",
    "    X = M.dot(X)\n",
    "    for m in range(k+l-1):\n",
    "        X[:,m] = (X[:,m].reshape(n,n).T).reshape(-1,)\n",
    "\n",
    "# now get A given the (potentially transformed) latent covariances\n",
    "cvxopt.solvers.options['show_progress'] = False\n",
    "X1,X2 = np.zeros((n, n*(k+l-2))), np.zeros((n, n*(k+l-2)))\n",
    "for m in range(k+l-2):\n",
    "    X1[:,m*n:(m+1)*n] = X[:,m].reshape(n,n)\n",
    "    X2[:,m*n:(m+1)*n] = X[:,m+1].reshape(n,n)\n",
    "P = cvxopt.matrix( np.kron(np.eye(n), X1.dot(X1.T)), tc='d')\n",
    "q = cvxopt.matrix( - (X2.dot(X1.T)).reshape(n**2,), tc='d')\n",
    "#r = np.trace(X2.T.dot(X2))/2\n",
    "sol = cvxopt.solvers.qp(P=P,q=q)\n",
    "assert sol['status'] == 'optimal'\n",
    "A = np.asarray(sol['x']).reshape(n,n)\n",
    "    \n",
    "    \n",
    "    \n",
    "print( np.mean((pars['C'].dot(X[:,0].reshape(n,n).dot(pars['C'].T)) - Qs[1])**2) )\n",
    "\n",
    "print('checking MSE solution for A')\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(A, interpolation='none')\n",
    "plt.title('MSE solution for A')\n",
    "plt.subplot(1,2,2)\n",
    "try:\n",
    "    plt.imshow(pars['A'], interpolation='none')\n",
    "except:\n",
    "    pass\n",
    "plt.title('pars[A]')\n",
    "plt.show()\n",
    "\n",
    "try:\n",
    "    print('eig(pars[A])', np.sort(np.linalg.eigvals(pars['A'])))\n",
    "except:\n",
    "    pass\n",
    "print('eig(A_rec)', np.sort(np.linalg.eigvals(A)))\n",
    "print('MSE A: ', np.mean((pars['A'] - A)**2))\n",
    "\n",
    "\n",
    "X1,X2 = np.zeros((n, n*(k+l-2))), np.zeros((n, n*(k+l-2)))\n",
    "for m in range(k+l-2):\n",
    "    X1[:,m*n:(m+1)*n] = X[:,m].reshape(n,n)\n",
    "    X2[:,m*n:(m+1)*n] = X[:,m+1].reshape(n,n)\n",
    "\n",
    "m = 3\n",
    "print('checking MSE solution for X, m = ', m)\n",
    "AmPi = np.linalg.matrix_power(pars['A'],m ).dot(pars['Pi'])\n",
    "X_m  = X[:,m-1].reshape(n,n)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow( AmPi, interpolation='none')\n",
    "plt.title('pars cov(x_{t+m), x_t) = A^m Pi')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow( X_m, interpolation='none')\n",
    "plt.title('est. cov(x_{t+m), x_t) = C^d Qs[m] C^d.T')\n",
    "#print( 'A^m Pi - X_m' , np.mean((AmPi - X_m)**2) )\n",
    "#print( 'A^m Pi - X_m^T' , np.mean((AmPi - X_m.T)**2) )\n",
    "\n",
    "\n",
    "AX1     = np.zeros((n*(k+l-1),n))\n",
    "As = np.empty((n*(k+l-1),n))\n",
    "XT = np.empty((n*(k+l-1),n))\n",
    "for m_ in range(k+l-1):\n",
    "    XT[m_*n:(m_+1)*n,:] = X[:,m_].reshape(n,n)\n",
    "    As[m_*n:(m_+1)*n,:] = np.linalg.matrix_power(A,m_+1)\n",
    "for m_ in range(1,k+l-1):\n",
    "    AX1[(m_)*n:(m_+1)*n,:] = A.dot(XT[(m_-1)*n:m_*n,:])\n",
    "    \n",
    "Pie,_,norm_res,muv,r,fail = SDLS.sdls(A=As,B=XT, X0=0.5*pars['Pi'],Y0=None,tol=1e-3,verbose=True)\n",
    "#Pie = SSID_Hankel_loss.s_Pi_l2_Hankel_bad_sis(X,A,k,l,Qs,Pi=None,verbose=True)\n",
    "\n",
    "print('MSE Pi: ', np.mean((pars['Pi'] - Pie)**2))\n",
    "\n",
    "print('MSE for As Pi - Xms' , np.mean((As.dot(Pie) - XT)**2) )\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow( np.linalg.matrix_power(A,m ).dot(Pie), interpolation='none')\n",
    "plt.title('reconstr. cov(x_{t+m), x_t) = A_hat^m Pi_hat')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(XT.T, interpolation='none')\n",
    "plt.title('data est. for latent covs')\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow( AX1.T, interpolation='none')\n",
    "plt.title('A * [X1, X2, ...]')\n",
    "#plt.subplot(4,1,3)\n",
    "#plt.imshow((As.dot(pars['Pi'])).T, interpolation='none')\n",
    "#plt.title('param est. for latent covs, using pars[Pi]')\n",
    "plt.subplot(3,1,3)\n",
    "plt.imshow((As.dot(Pie)).T, interpolation='none')\n",
    "plt.title('param est. for latent covs, using MSE Pi')\n",
    "plt.show()\n",
    "print( 'A^m Pi - X_m' , np.mean((np.linalg.matrix_power(A,m).dot(Pie) - X[:,m-1].reshape(n,n))**2) )\n",
    "print( 'A X_{m-1} - X_m' , np.mean((AX1[n:,:] - XT[n:,:])**2) )\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(XT.reshape(-1,), XT.reshape(-1,), 'k.')\n",
    "plt.title('recov. cov vs. recov. cov (for scales)')\n",
    "print('corrcoef: ', np.corrcoef(XT.reshape(-1,), XT.reshape(-1,))[0,1], \n",
    "      'SE, ', np.sum( (XT.reshape(-1,) - XT.reshape(-1,))**2))\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(XT[n:,:].reshape(-1,), AX1[n:,:].reshape(-1,),'k.')\n",
    "plt.title('recov. cov vs. first-order reconstruction')\n",
    "print('corrcoef: ', np.corrcoef(XT[n:,:].reshape(-1,), AX1[n:,:].reshape(-1,))[0,1], \n",
    "      'SE, ', np.sum( (XT[n:,:].reshape(-1,) - AX1[n:,:].reshape(-1,))**2))\n",
    "#plt.subplot(1,4,3)\n",
    "#plt.plot(XT.reshape(-1,), (As.dot(pars['Pi'])).reshape(-1,), 'k.')\n",
    "#plt.title('recov. cov vs. full reconstruction with pars[Pi]')\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(XT.reshape(-1,), (As.dot(Pie)).reshape(-1,), 'k.')\n",
    "plt.title('recov. cov vs. full reconstruction with least-squares Pi')\n",
    "print('corrcoef: ', np.corrcoef(XT.reshape(-1,), (As.dot(Pie)).reshape(-1,))[0,1], \n",
    "      'SE, ', np.sum( (XT.reshape(-1,) - (As.dot(Pie)).reshape(-1,))**2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting $\\\\Pi$ from latent covariances given $A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "os.chdir('../core')\n",
    "import SDLS\n",
    "os.chdir('../dev')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sig, tol = 1, 10e-2\n",
    "n = 30\n",
    "V = np.random.normal(size=(n,n))\n",
    "V = V / np.sum(V**2,0).reshape(1,-1)\n",
    "Adyn = V.dot(np.diag(np.linspace(0.8, 0.99,n))).dot(np.linalg.inv(V))\n",
    "Pi = np.outer(np.linspace(0.5,1.0,n), np.linspace(0.5,1.0,n))\n",
    "\n",
    "A = np.zeros((4*n,n))\n",
    "B = np.zeros((4*n,n))\n",
    "for i in range(4):\n",
    "    B[i*n:(i+1)*n,:] = np.linalg.matrix_power(Adyn,i+1).dot(Pi)\n",
    "    A[i*n:(i+1)*n,:] = np.linalg.matrix_power(Adyn,i+1)\n",
    "    \n",
    "B += sig * np.random.normal(size=B.shape)\n",
    "    \n",
    "Pie,Y,norm_res,muv,r,fail = SDLS.sdls(A,B,X0=None,Y0=None,tol=tol,verbose=False)\n",
    "\n",
    "print('maximal absolute single-entry deviation of AX and B: ', np.max(np.abs(A.dot(Pie) - B)))\n",
    "print('maximal absolute single-entry deviation of Pi and Pi_est: ', np.max(np.abs(Pie - Pi)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(Pie,interpolation='none')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(Pi,interpolation='none')\n",
    "plt.show()\n",
    "\n",
    "for i in range(5):\n",
    "    V = np.random.normal(size=(n,n))\n",
    "    V = V / np.sum(V**2,0).reshape(1,-1)\n",
    "    Adyn = V.dot(np.diag(np.linspace(0.8, 0.99,n))).dot(np.linalg.inv(V))\n",
    "    Pi = stats.wishart.rvs(df=n, scale=np.eye(n))\n",
    "\n",
    "    A = np.zeros((4*n,n))\n",
    "    B = np.zeros((4*n,n))\n",
    "    for i in range(4):\n",
    "        B[i*n:(i+1)*n,:] = np.linalg.matrix_power(Adyn,i+1).dot(Pi)\n",
    "        A[i*n:(i+1)*n,:] = np.linalg.matrix_power(Adyn,i+1)        \n",
    "    B += sig * np.random.normal(size=B.shape)\n",
    "    \n",
    "    Pie,Y,norm_res,muv,r,fail = SDLS.sdls(A,B,X0=None,Y0=None,tol=tol,verbose=False)\n",
    "    print('maximal absolute single-entry deviation of AX and B: ', np.max(np.abs(A.dot(Pie) - B)))\n",
    "    print('maximal absolute single-entry deviation of Pi and Pi_est: ', np.max(np.abs(Pie - Pi)))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(Pie,interpolation='none')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(Pi,interpolation='none')\n",
    "    plt.show()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic gradient descent\n",
    "- three variants\n",
    "    - size-1 mini-batches (batch_size = 1), zips through all observed entries of $\\mbox{cov}(y_{t+m},y_t)$ and computes gradients from one at time\n",
    "    - column mini-batches (batch_size = p), zips through all columns of $\\mbox{cov}(y_{t+m},y_t)$ and computes gradients from observed entries \n",
    "    - batch-gradients (batch_size = None), computes a full gradient using all observed entries $\\mbox{cov}(y_{t+m},y_t)$ at the same time\n",
    "    \n",
    "- mini-batch gradients use Adam for following the gradients with momentum and with re-normalising of gradients along each dimension. Full gradients use plain gradient descent.\n",
    "- max_iter is defined as the number of 'zips' through the data set. Thus for different batch sizes, max_iter fixes the amount of information visited within the data covariance matrices, *not* the number of gradient steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.optimize import fmin_bfgs, check_grad\n",
    "import glob, os\n",
    "\n",
    "os.chdir('../core')\n",
    "from utility import get_subpop_stats, draw_sys\n",
    "from SSID_Hankel_loss import f_l2_Hankel, l2_sis_setup, g_l2_Hankel_sis, plot_outputs_l2_gradient_test\n",
    "from SSID_Hankel_loss import yy_Hankel_cov_mat, l2_sis_draw, adam_zip, adam_zip_stable\n",
    "import SDLS\n",
    "os.chdir('../dev')\n",
    "\n",
    "p,n = 10,3\n",
    "k,l = 3,3\n",
    "\n",
    "nr = 3\n",
    "\n",
    "batch_size = p # batch_size = 1 (size-1 mini-batches), p (column mini-batches), None (full gradients)\n",
    "\n",
    "a, a_A, b1, b2, e = 0.0001, 0.0000001, 0.9, 0.99, 1e-8\n",
    "max_iter = 1000\n",
    "\n",
    "gammas = np.array([10e-8])\n",
    "tau = 0.5\n",
    "\n",
    "# create subpopulations\n",
    "sub_pops = (np.arange(0,p//2+1), np.arange(p//2-1,p))\n",
    "\n",
    "# draw system matrices    \n",
    "ev_r = np.linspace(0.8, 0.999, nr)\n",
    "ev_c = np.exp(2 * 1j * np.pi * np.random.uniform(size= (n - nr)//2))\n",
    "ev_c = np.linspace(0.8, 0.999, (n - nr)//2) * ev_c\n",
    "\n",
    "if p < 200:\n",
    "    print('sub_pops', sub_pops)\n",
    "obs_idx, idx_grp, co_obs, overlaps, overlap_grp, idx_overlap, Om, Ovw, Ovc = \\\n",
    "    get_subpop_stats(sub_pops, p, verbose=False)\n",
    "pars_true, Qs, Qs_full = draw_sys(p,n,k,l,Om, nr, ev_r,ev_c)\n",
    "f_base, _ = l2_sis_setup(k,l,n,Qs,Om,idx_grp,obs_idx)\n",
    "\n",
    "\n",
    "\n",
    "def s(A):\n",
    "    s = np.linalg.svd(A)[1]\n",
    "    return np.isfinite( np.log( 1 - s**2 ).sum() )\n",
    "\n",
    "err_est  = np.zeros((gammas.size, 4))\n",
    "eigA_est = np.zeros((gammas.size, n))  \n",
    "for rep in range(gammas.size):\n",
    "    \n",
    "    gamma = gammas[rep]\n",
    "\n",
    "    def f_i(theta):\n",
    "\n",
    "        A = theta[:n*n].reshape(n,n)        \n",
    "        f_log_bar = - np.log( np.linalg.det(np.eye(n)-A.dot(A.T)) )\n",
    "\n",
    "        if gamma == 0 and not np.isfinite(f_log_bar):\n",
    "            f_log_bar = 0\n",
    "\n",
    "        return f_base(theta) + gamma * f_log_bar\n",
    "    \n",
    "    def g_i(theta, idx_use, idx_co):\n",
    "\n",
    "        A = theta[:n*n].reshape(n,n)        \n",
    "        inv = np.linalg.solve(np.eye(n)-A.dot(A.T), np.eye(n))\n",
    "        g_log_bar = np.zeros(theta.size)                                 \n",
    "        g_log_bar[:n*n] = 2 * inv.dot(A).reshape(-1,)\n",
    "\n",
    "        gamma_g_log_bar = gamma * g_log_bar\n",
    "        if gamma == 0:\n",
    "            gamma_g_log_bar[np.invert(np.isfinite(gamma_g_log_bar))] = 0\n",
    "        return g_l2_Hankel_sis(theta,k,l,n,Qs,idx_use,idx_co) + gamma_g_log_bar\n",
    "\n",
    "    A_0  = np.diag(np.random.uniform(low=0.7, high=0.8, size=n))\n",
    "    B_0  = np.eye(n) #np.random.normal(size=(n,n))\n",
    "    C_0  = np.random.normal(size=(p,n))\n",
    "    Pi_0 = B_0.dot(B_0.T)\n",
    "    \n",
    "    pars_0 = np.hstack((A_0.reshape(n*n,),\n",
    "                        B_0.reshape(n*n,),\n",
    "                        C_0.reshape(p*n,)))\n",
    "\n",
    "    def converged(theta_old, theta, e, t):\n",
    "        if t >= max_iter:\n",
    "            return True\n",
    "        return False\n",
    "        #return np.abs(f_i(theta_old) - f_i(theta)) < e\n",
    "    \n",
    "    print('starting descent')\n",
    "    \n",
    "    pars_est_vec, traces = adam_zip_stable(f_i,g_i,s,tau,pars_0.copy(),a,a_A,b1,b2,e,max_iter,converged,Om,idx_grp,co_obs,batch_size)\n",
    "    fs, sig = traces\n",
    "    \n",
    "    A_est = pars_est_vec[:n*n].reshape(n,n)\n",
    "    B_est = pars_est_vec[n*n:2*n*n].reshape(n,n)\n",
    "    Pi_est = B_est.dot(B_est.T)\n",
    "    C_est = pars_est_vec[-p*n:].reshape(p,n)\n",
    "\n",
    "    print('gamma =', gamma)\n",
    "\n",
    "    eigA_est[rep,:] = np.abs(np.sort(np.linalg.eigvals(A_est)))\n",
    "    print('|eig(A_est)|', eigA_est[rep,:])\n",
    "    print('|eig(A_true)|', np.abs(np.sort(np.linalg.eigvals(pars_true['A']))))\n",
    "\n",
    "\n",
    "    err_est[rep,0] = f_l2_Hankel(pars_est_vec,k,l,n,Qs, Om)\n",
    "    err_est[rep,1] = f_l2_Hankel(pars_est_vec,k,l,n,Qs,Ovw)\n",
    "    err_est[rep,2] = f_l2_Hankel(pars_est_vec,k,l,n,Qs,Ovc)\n",
    "    err_est[rep,3] = f_l2_Hankel(pars_est_vec,k,l,n,Qs_full,~Om)\n",
    "\n",
    "    print('final squared error on observed parts:', \n",
    "          err_est[rep,0])\n",
    "    print('final squared error on overlapping parts:', \n",
    "          err_est[rep,1])\n",
    "    print('final squared error on cross-overlapping parts:',\n",
    "          err_est[rep,2])\n",
    "    print('final squared error on stitched parts:',\n",
    "          err_est[rep,3])\n",
    "\n",
    "    pars_init = {'A': A_0, 'C': C_0, 'Pi': Pi_0, 'B': B_0}\n",
    "    pars_est  = {'A': A_est, 'C': C_est, 'Pi': Pi_est, 'B': B_est}\n",
    "    #plot_outputs_l2_gradient_test(pars_true, pars_init, pars_est, k, l, Qs, \n",
    "    #                                   Qs_full, Om, Ovc, Ovw, f_i, g_i, if_flip = True)\n",
    "\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(fs[:max_iter])\n",
    "    plt.ylabel('f')\n",
    "    plt.title('target function error')\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(sig[:max_iter])\n",
    "    plt.ylabel('max sig(A)')\n",
    "    plt.title('maximum singular value of A')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# visualise overall results\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.hsv()\n",
    "plt.plot(err_est)\n",
    "plt.hsv()\n",
    "plt.xticks( np.arange(gammas.size), gammas)\n",
    "plt.xlabel('\\gamma')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend(['obs.', 'overlap', 'cross-overl.', 'stitched'])\n",
    "plt.title('Squared errors as function of log-barrier height')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "clrs = np.zeros((gammas.size, 3))\n",
    "clrs[:,2] = np.linspace(0.05, 0.99, gammas.size)\n",
    "clrs[:,0] = np.linspace(0.05, 0.99, gammas.size)[::-1]\n",
    "for i in range(gammas.size):    \n",
    "    plt.plot(eigA_est[i,:], color=clrs[i,:])\n",
    "    plt.hold(True)\n",
    "plt.plot(np.sort(np.abs(np.linalg.eigvals(pars_true['A']))), 'k')\n",
    "plt.plot([0, 1.1*n], [1, 1], 'r--')\n",
    "plt.hot()\n",
    "plt.xticks( np.arange(n), np.arange(n)+1)\n",
    "plt.xlabel('# eigenvalue')\n",
    "plt.ylabel('EV')\n",
    "lgnd = [np.ceil(gammas[i]*100)/100 for i in range(gammas.size)]\n",
    "lgnd.append('true')\n",
    "lgnd.append('stability')\n",
    "plt.legend(lgnd)\n",
    "plt.axis([0, 1.1*n, plt.ylim()[0], plt.ylim()[1]])\n",
    "plt.title('Eigenvalues as function of log-barrier height')\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# just one more turn..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gamma /= 1000\n",
    "def f_i(theta):\n",
    "\n",
    "    A = theta[:n*n].reshape(n,n)        \n",
    "    f_log_bar = - np.log( np.linalg.det(np.eye(n)-A.dot(A.T)) )\n",
    "\n",
    "    if gamma == 0 and not np.isfinite(f_log_bar):\n",
    "        f_log_bar = 0\n",
    "\n",
    "    return f_base(theta) + gamma * f_log_bar\n",
    "def g_i(theta, idx_use, idx_co):\n",
    "\n",
    "    A = theta[:n*n].reshape(n,n)        \n",
    "    inv = np.linalg.solve(np.eye(n)-A.dot(A.T), np.eye(n))\n",
    "    g_log_bar = np.zeros(theta.size)                                 \n",
    "    g_log_bar[:n*n] = 2 * inv.dot(A).reshape(-1,)\n",
    "\n",
    "    gamma_g_log_bar = gamma * g_log_bar\n",
    "    if gamma == 0:\n",
    "        gamma_g_log_bar[np.invert(np.isfinite(gamma_g_log_bar))] = 0\n",
    "    return g_l2_Hankel_sis(theta,k,l,n,Qs,idx_use,idx_co) + gamma_g_log_bar\n",
    "\n",
    "max_iter = 1000\n",
    "def converged(theta_old, theta, e, t):\n",
    "    if t >= max_iter:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "pars_est_vec, fs = adam_zip_stable(f_i,g_i,s,tau,pars_est_vec.copy(),a,a_A,b1,b2,e,max_iter,converged,Om,idx_grp,co_obs,batch_size)\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(fs[:max_iter])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "A_est = pars_est_vec[:n*n].reshape(n,n)\n",
    "B_est = pars_est_vec[n*n:2*n*n].reshape(n,n)\n",
    "Pi_est = B_est.dot(B_est.T)\n",
    "C_est = pars_est_vec[-p*n:].reshape(p,n)\n",
    "\n",
    "pars_init = {'A': A_0, 'C': C_0, 'Pi': Pi_0, 'B': B_0}\n",
    "pars_est  = {'A': A_est, 'C': C_est, 'Pi': Pi_est, 'B': B_est}\n",
    "plot_outputs_l2_gradient_test(pars_true, pars_init, pars_est, k, l, Qs, \n",
    "                                   Qs_full, Om, Ovc, Ovw, f_i, None, if_flip = True)\n",
    "\n",
    "print('gamma', gamma)\n",
    "print('eigvals[A]', np.linalg.eigvals(pars_est['A']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
