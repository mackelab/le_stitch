{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic gradient descent\n",
    "- three variants\n",
    "    - size-1 mini-batches (batch_size = 1), zips through all observed entries of $\\mbox{cov}(y_{t+m},y_t)$ and computes gradients from one at time\n",
    "    - column mini-batches (batch_size = p), zips through all columns of $\\mbox{cov}(y_{t+m},y_t)$ and computes gradients from observed entries \n",
    "    - batch-gradients (batch_size = None), computes a full gradient using all observed entries $\\mbox{cov}(y_{t+m},y_t)$ at the same time\n",
    "    \n",
    "- mini-batch gradients use Adam for following the gradients with momentum and with re-normalising of gradients along each dimension. Full gradients use plain gradient descent.\n",
    "- max_iter is defined as the number of 'zips' through the data set. Thus for different batch sizes, max_iter fixes the amount of information visited within the data covariance matrices, *not* the number of gradient steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.optimize import fmin_bfgs, check_grad\n",
    "import glob, os\n",
    "\n",
    "os.chdir('../core')\n",
    "from utility import get_subpop_stats, draw_sys\n",
    "from SSID_Hankel_loss import f_l2_Hankel, l2_sis_setup, g_l2_Hankel_sis, plot_outputs_l2_gradient_test\n",
    "from SSID_Hankel_loss import yy_Hankel_cov_mat, l2_sis_draw, adam_zip, adam_zip_stable\n",
    "os.chdir('../dev')\n",
    "\n",
    "p,n = 30,10\n",
    "k,l = 3,3\n",
    "\n",
    "nr = 4\n",
    "\n",
    "batch_size = p # batch_size = 1 (size-1 mini-batches), p (column mini-batches), None (full gradients)\n",
    "\n",
    "a, a_A, b1, b2, e = 0.0001, 0.000001, 0.9, 0.99, 1e-8\n",
    "max_iter = 1000\n",
    "\n",
    "gammas = np.array([0.000000])\n",
    "tau = 0.5\n",
    "\n",
    "# create subpopulations\n",
    "sub_pops = (np.arange(0,p//2+1), np.arange(p//2-1,p))\n",
    "\n",
    "# draw system matrices    \n",
    "ev_r = np.linspace(0.7, 0.99, nr)\n",
    "ev_c = np.exp(2 * 1j * np.pi * np.random.uniform(size= (n - nr)//2))\n",
    "ev_c = np.linspace(0.8, 0.99, (n - nr)//2) * ev_c\n",
    "\n",
    "if p < 200:\n",
    "    print('sub_pops', sub_pops)\n",
    "obs_idx, idx_grp, co_obs, overlaps, overlap_grp, idx_overlap, Om, Ovw, Ovc = \\\n",
    "    get_subpop_stats(sub_pops, p, verbose=False)\n",
    "pars_true, Qs, Qs_full = draw_sys(p,n,k,l,Om, nr, ev_r,ev_c)\n",
    "f_base, _ = l2_sis_setup(k,l,n,Qs,Om,idx_grp,obs_idx)\n",
    "\n",
    "\n",
    "def s(A):\n",
    "    s = np.linalg.svd(A)[1]\n",
    "    return np.isfinite( np.log( 1 - s**2 ).sum() )\n",
    "\n",
    "#def s(A):\n",
    "#    return True\n",
    "\n",
    "err_est  = np.zeros((gammas.size, 4))\n",
    "eigA_est = np.zeros((gammas.size, n))  \n",
    "for rep in range(gammas.size):\n",
    "    \n",
    "    gamma = gammas[rep]\n",
    "    \n",
    "    def f_i(theta):\n",
    "\n",
    "        A = theta[:n*n].reshape(n,n)        \n",
    "        f_log_bar = - np.log( np.linalg.det(np.eye(n)-A.dot(A.T)) )\n",
    "\n",
    "        if gamma == 0 and not np.isfinite(f_log_bar):\n",
    "            f_log_bar = 0\n",
    "\n",
    "        return f_base(theta) + gamma * f_log_bar\n",
    "    \n",
    "    def g_i(theta, idx_use, idx_co):\n",
    "\n",
    "        A = theta[:n*n].reshape(n,n)        \n",
    "        inv = np.linalg.solve(np.eye(n)-A.dot(A.T), np.eye(n))\n",
    "        g_log_bar = np.zeros(theta.size)                                 \n",
    "        g_log_bar[:n*n] = 2 * inv.dot(A).reshape(-1,)\n",
    "\n",
    "        gamma_g_log_bar = gamma * g_log_bar\n",
    "        if gamma == 0:\n",
    "            gamma_g_log_bar[np.invert(np.isfinite(gamma_g_log_bar))] = 0\n",
    "        return g_l2_Hankel_sis(theta,k,l,n,Qs,idx_use,idx_co) + gamma_g_log_bar\n",
    "    \n",
    "    A_0  = np.diag(np.random.uniform(low=0.7, high=0.8, size=n))\n",
    "    B_0  = np.eye(n) #np.random.normal(size=(n,n))\n",
    "    C_0  = np.random.normal(size=(p,n))\n",
    "    Pi_0 = B_0.dot(B_0.T)\n",
    "    \n",
    "    pars_0 = np.hstack((A_0.reshape(n*n,),\n",
    "                        B_0.reshape(n*n,),\n",
    "                        C_0.reshape(p*n,)))\n",
    "\n",
    "\n",
    "    def converged(theta_old, theta, e, t):\n",
    "        if t >= max_iter:\n",
    "            return True\n",
    "        return False\n",
    "        #return np.abs(f_i(theta_old) - f_i(theta)) < e\n",
    "    \n",
    "    print('starting descent')\n",
    "    \n",
    "    pars_est_vec, fs = adam_zip_stable(f_i,g_i,s,tau,pars_0.copy(),a,a_A,b1,b2,e,max_iter,converged,Om,idx_grp,co_obs,batch_size)\n",
    "\n",
    "    A_est = pars_est_vec[:n*n].reshape(n,n)\n",
    "    B_est = pars_est_vec[n*n:2*n*n].reshape(n,n)\n",
    "    Pi_est = B_est.dot(B_est.T)\n",
    "    C_est = pars_est_vec[-p*n:].reshape(p,n)\n",
    "\n",
    "    print('gamma =', gamma)\n",
    "\n",
    "    eigA_est[rep,:] = np.abs(np.sort(np.linalg.eigvals(A_est)))\n",
    "    print('|eig(A_est)|', eigA_est[rep,:])\n",
    "    print('|eig(A_true)|', np.abs(np.sort(np.linalg.eigvals(pars_true['A']))))\n",
    "\n",
    "\n",
    "    err_est[rep,0] = f_l2_Hankel(pars_est_vec,k,l,n,Qs, Om)\n",
    "    err_est[rep,1] = f_l2_Hankel(pars_est_vec,k,l,n,Qs,Ovw)\n",
    "    err_est[rep,2] = f_l2_Hankel(pars_est_vec,k,l,n,Qs,Ovc)\n",
    "    err_est[rep,3] = f_l2_Hankel(pars_est_vec,k,l,n,Qs_full,~Om)\n",
    "\n",
    "    print('final squared error on observed parts:', \n",
    "          err_est[rep,0])\n",
    "    print('final squared error on overlapping parts:', \n",
    "          err_est[rep,1])\n",
    "    print('final squared error on cross-overlapping parts:',\n",
    "          err_est[rep,2])\n",
    "    print('final squared error on stitched parts:',\n",
    "          err_est[rep,3])\n",
    "\n",
    "    pars_init = {'A': A_0, 'C': C_0, 'Pi': Pi_0, 'B': B_0}\n",
    "    pars_est  = {'A': A_est, 'C': C_est, 'Pi': Pi_est, 'B': B_est}\n",
    "    #plot_outputs_l2_gradient_test(pars_true, pars_init, pars_est, k, l, Qs, \n",
    "    #                                   Qs_full, Om, Ovc, Ovw, f_i, g_i, if_flip = True)\n",
    "\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.plot(fs[:max_iter])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# visualise overall results\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.hsv()\n",
    "plt.plot(err_est)\n",
    "plt.hsv()\n",
    "plt.xticks( np.arange(gammas.size), gammas)\n",
    "plt.xlabel('\\gamma')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend(['obs.', 'overlap', 'cross-overl.', 'stitched'])\n",
    "plt.title('Squared errors as function of log-barrier height')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "clrs = np.zeros((gammas.size, 3))\n",
    "clrs[:,2] = np.linspace(0.05, 0.99, gammas.size)\n",
    "clrs[:,0] = np.linspace(0.05, 0.99, gammas.size)[::-1]\n",
    "for i in range(gammas.size):    \n",
    "    plt.plot(eigA_est[i,:], color=clrs[i,:])\n",
    "    plt.hold(True)\n",
    "plt.plot(np.sort(np.abs(np.linalg.eigvals(pars_true['A']))), 'k')\n",
    "plt.plot([0, 1.1*n], [1, 1], 'r--')\n",
    "plt.hot()\n",
    "plt.xticks( np.arange(n), np.arange(n)+1)\n",
    "plt.xlabel('# eigenvalue')\n",
    "plt.ylabel('EV')\n",
    "lgnd = [np.ceil(gammas[i]*100)/100 for i in range(gammas.size)]\n",
    "lgnd.append('true')\n",
    "lgnd.append('stability')\n",
    "plt.legend(lgnd)\n",
    "plt.axis([0, 1.1*n, plt.ylim()[0], plt.ylim()[1]])\n",
    "plt.title('Eigenvalues as function of log-barrier height')\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# just one more turn..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gamma /= 10\n",
    "def f_i(theta):\n",
    "\n",
    "    A = theta[:n*n].reshape(n,n)        \n",
    "    f_log_bar = - np.log( np.linalg.det(np.eye(n)-A.dot(A.T)) )\n",
    "\n",
    "    if gamma == 0 and not np.isfinite(f_log_bar):\n",
    "        f_log_bar = 0\n",
    "\n",
    "    return f_base(theta) + gamma * f_log_bar\n",
    "def g_i(theta, idx_use, idx_co):\n",
    "\n",
    "    A = theta[:n*n].reshape(n,n)        \n",
    "    inv = np.linalg.solve(np.eye(n)-A.dot(A.T), np.eye(n))\n",
    "    g_log_bar = np.zeros(theta.size)                                 \n",
    "    g_log_bar[:n*n] = 2 * inv.dot(A).reshape(-1,)\n",
    "\n",
    "    gamma_g_log_bar = gamma * g_log_bar\n",
    "    if gamma == 0:\n",
    "        gamma_g_log_bar[np.invert(np.isfinite(gamma_g_log_bar))] = 0\n",
    "    return g_l2_Hankel_sis(theta,k,l,n,Qs,idx_use,idx_co) + gamma_g_log_bar\n",
    "\n",
    "max_iter = 1000\n",
    "def converged(theta_old, theta, e, t):\n",
    "    if t >= max_iter:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "pars_est_vec, fs = adam_zip_stable(f_i,g_i,s,tau,pars_est_vec.copy(),a,a_A,b1,b2,e,max_iter,converged,Om,idx_grp,co_obs,batch_size)\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(fs[:max_iter])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "A_est = pars_est_vec[:n*n].reshape(n,n)\n",
    "B_est = pars_est_vec[n*n:2*n*n].reshape(n,n)\n",
    "Pi_est = B_est.dot(B_est.T)\n",
    "C_est = pars_est_vec[-p*n:].reshape(p,n)\n",
    "\n",
    "pars_init = {'A': A_0, 'C': C_0, 'Pi': Pi_0, 'B': B_0}\n",
    "pars_est  = {'A': A_est, 'C': C_est, 'Pi': Pi_est, 'B': B_est}\n",
    "plot_outputs_l2_gradient_test(pars_true, pars_init, pars_est, k, l, Qs, \n",
    "                                   Qs_full, Om, Ovc, Ovw, f_i, None, if_flip = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# alternating blocked descent\n",
    "\n",
    "- using SGD on $C$\n",
    "- after each pass over the observed parts of the covariance matrix, use analyic solution for $A$, $\\Pi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.optimize import fmin_bfgs, check_grad\n",
    "import glob, os\n",
    "\n",
    "os.chdir('../core')\n",
    "from utility import get_subpop_stats, draw_sys\n",
    "import SSID_Hankel_loss\n",
    "from SSID_Hankel_loss import f_l2_Hankel, plot_outputs_l2_gradient_test\n",
    "from SSID_Hankel_loss import l2_bad_sis_setup\n",
    "from SSID_Hankel_loss import yy_Hankel_cov_mat, l2_sis_draw, adam_zip_bad_stable, id_A\n",
    "from SSID_Hankel_loss import ssidSVD\n",
    "os.chdir('../dev')\n",
    "\n",
    "p,n = 1000,20\n",
    "k,l = 20,20\n",
    "k_init, l_init = 3,3\n",
    "\n",
    "nr = 20\n",
    "batch_size = p # batch_size = 1 (size-1 mini-batches), p (column mini-batches), None (full gradients)\n",
    "\n",
    "a, b1, b2, e = 0.001, 0.9, 0.99, 1e-8\n",
    "max_iter, max_iter_init = 100, 10\n",
    "\n",
    "reps = 1\n",
    "stable = False\n",
    "linear = False\n",
    "\n",
    "# create subpopulations\n",
    "sub_pops = (np.arange(0,p//2+1), np.arange(p//2-1,p))\n",
    "\n",
    "# draw system matrices    \n",
    "ev_r = np.linspace(0.7, 0.99, nr)\n",
    "ev_c = np.exp(2 * 1j * np.pi * np.random.uniform(size= (n - nr)//2))\n",
    "ev_c = np.linspace(0.8, 0.99, (n - nr)//2) * ev_c\n",
    "\n",
    "\n",
    "if p < 200:\n",
    "    print('sub_pops', sub_pops)\n",
    "obs_idx, idx_grp, co_obs, overlaps, overlap_grp, idx_overlap, Om, Ovw, Ovc = \\\n",
    "    get_subpop_stats(sub_pops=sub_pops, p=p, verbose=False)\n",
    "pars_true, Qs, Qs_full = draw_sys(p=p,n=n,k=k,l=l,Om=Om, nr=nr, ev_r=ev_r,ev_c=ev_c)\n",
    "f_i, g_C, g_A = l2_bad_sis_setup(k=k,l=l,n=n,Qs=Qs,Om=Om,idx_grp=idx_grp,obs_idx=obs_idx,linear=linear,stable=stable)\n",
    "\n",
    "print('getting initial parameter values (SSID on largest subpopulation)')\n",
    "idx = sub_pops[0]\n",
    "H_kl = yy_Hankel_cov_mat(pars_true['C'][idx,:],pars_true['A'],pars_true['Pi'],\n",
    "                         k_init,l_init,Om=None)\n",
    "pars_ssid = ssidSVD(H_kl, Qs[0][np.ix_(idx,idx)], n, pi_method='proper')\n",
    "#pars_ssid = pars_true.copy()\n",
    "U,S,_ = np.linalg.svd(pars_ssid['Pi'])\n",
    "M = np.diag(1/np.sqrt(S)).dot(U.T)\n",
    "\n",
    "for rep in range(reps):\n",
    "        \n",
    "    pars_init = {'A'  : M.dot(pars_ssid['A']).dot(np.linalg.inv(M)),\n",
    "                 'Pi' : M.dot(pars_ssid['Pi']).dot(M.T),\n",
    "                 'B'  : np.eye(n), \n",
    "                 'C'  : np.random.normal(size=(p,n))} #pars_ssid['C'].dot(np.linalg.inv(M))}\n",
    "\n",
    "    \"\"\"\n",
    "    def converged(theta_old, theta, e, t):\n",
    "        return True if t >= max_iter_init else False    \n",
    "    pars_est_vec, fs = adam_zip_bad_stable(f=f_i,g_C=g_C,g_A=id_A,pars_0=pars_init,\n",
    "                                           a=a,b1=b1,b2=b2,e=e,max_iter=max_iter_init,converged=converged,\n",
    "                                           Om=Om,idx_grp=idx_grp,co_obs=co_obs,\n",
    "                                           batch_size=batch_size,linear=linear)    \n",
    "    \"\"\"\n",
    "    print('starting descent')    \n",
    "    def converged(theta_old, theta, e, t):\n",
    "        return True if t >= max_iter else False\n",
    "    pars_est_vec, fs = adam_zip_bad_stable(f=f_i,g_C=g_C,g_A=g_A,pars_0=pars_init,\n",
    "                                           a=a,b1=b1,b2=b2,e=e,max_iter=max_iter,converged=converged,\n",
    "                                           Om=Om,idx_grp=idx_grp,co_obs=co_obs,\n",
    "                                           batch_size=batch_size,linear=linear)   \n",
    "    pars_est  = {'A': pars_est_vec[:n*n].reshape(n,n), \n",
    "                 'C': pars_est_vec[-p*n:].reshape(p,n), \n",
    "                 'B': pars_est_vec[n*n:2*n*n].reshape(n,n)}\n",
    "    pars_est['Pi'] = pars_est['B'].dot( pars_est['B'].T)\n",
    "\n",
    "    plot_outputs_l2_gradient_test(pars_true, pars_init, pars_est, k, l, Qs, \n",
    "                                       Qs_full, Om, Ovc, Ovw, f_i, None, \n",
    "                                       linear=linear, idx_grp = idx_grp, co_obs = co_obs, \n",
    "                                       if_flip = True)\n",
    "\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.plot(fs[:max_iter])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(fs[:max_iter])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "H_true = yy_Hankel_cov_mat(pars_true['C'],pars_true['A'],pars_true['Pi'],k,l,Om=None,linear=True)\n",
    "X=SSID_Hankel_loss.s_A_l2_Hankel_bad_sis(pars_est['C'],k,l,Qs,idx_grp,co_obs, linear=False)\n",
    "H_est  = yy_Hankel_cov_mat(pars_est['C'], X,None,k,l,Om=None,linear=False)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(H_true)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(H_est)\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(H_true.reshape(-1,), H_est.reshape(-1,), 'k.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# just one more turn..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_iter = 100\n",
    "def converged(theta_old, theta, e, t):\n",
    "    return True if t >= max_iter else False\n",
    "\n",
    "pars_est_vec, fs = adam_zip_bad_stable(f=f_i,g_C=g_C,g_A=g_A,pars_0=pars_est_vec.copy(),\n",
    "                                       a=a,b1=b1,b2=b2,e=e,max_iter=max_iter,converged=converged,\n",
    "                                       Om=Om,idx_grp=idx_grp,co_obs=co_obs,\n",
    "                                       batch_size=batch_size,linear=linear) \n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(fs[:max_iter])\n",
    "plt.show()\n",
    "\n",
    "A_est = pars_est_vec[:n*n].reshape(n,n)\n",
    "B_est = pars_est_vec[n*n:2*n*n].reshape(n,n)\n",
    "Pi_est = B_est.dot(B_est.T)\n",
    "C_est = pars_est_vec[-p*n:].reshape(p,n)\n",
    "pars_est  = {'A': A_est, 'C': C_est, 'Pi': Pi_est, 'B': B_est}\n",
    "plot_outputs_l2_gradient_test(pars_true, pars_init, pars_est, k, l, Qs, \n",
    "                                   Qs_full, Om, Ovc, Ovw, f_i, None, \n",
    "                                   linear=linear, idx_grp = idx_grp, co_obs = co_obs, \n",
    "                                   if_flip = True)\n",
    "\n",
    "print(np.linalg.eigvals(A_est))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_iter = 500\n",
    "def converged(theta_old, theta, e, t):\n",
    "    return True if t >= max_iter else False\n",
    "\n",
    "pars_est_vec, fs = adam_zip_bad_stable(f=f_i,g_C=g_C,g_A=g_A,pars_0=pars_est_vec.copy(),\n",
    "                                       a=a,b1=b1,b2=b2,e=e,max_iter=max_iter,converged=converged,\n",
    "                                       Om=Om,idx_grp=idx_grp,co_obs=co_obs,\n",
    "                                       batch_size=batch_size,linear=linear) \n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(fs[:max_iter])\n",
    "plt.show()\n",
    "\n",
    "A_est = pars_est_vec[:n*n].reshape(n,n)\n",
    "B_est = pars_est_vec[n*n:2*n*n].reshape(n,n)\n",
    "Pi_est = B_est.dot(B_est.T)\n",
    "C_est = pars_est_vec[-p*n:].reshape(p,n)\n",
    "pars_est  = {'A': A_est, 'C': C_est, 'Pi': Pi_est, 'B': B_est}\n",
    "plot_outputs_l2_gradient_test(pars_true, pars_init, pars_est, k, l, Qs, \n",
    "                                   Qs_full, Om, Ovc, Ovw, f_i, None, \n",
    "                                   linear=linear, idx_grp = idx_grp, co_obs = co_obs, \n",
    "                                   if_flip = True)\n",
    "\n",
    "print(np.linalg.eigvals(A_est))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.io import savemat # store results for comparison with Matlab code   \n",
    "\n",
    "os.chdir('../fits/')\n",
    "\n",
    "save_file = 'usbad_p1000n20r2'\n",
    "\n",
    "save_file_m = {'A_true':pars_true['A'],\n",
    "               'B_true':pars_true['B'],\n",
    "               'Pi_true' : pars_true['Pi'], \n",
    "               'C_true' : pars_true['C'],\n",
    "               'A_0': pars_init['A'],\n",
    "               'B_0': pars_init['B'],\n",
    "               'Pi_0': pars_init['Pi'],\n",
    "               'C_0': pars_init['C'],\n",
    "               'A_est': pars_est['A'],\n",
    "               'B_est':  pars_est['B'],\n",
    "               'Pi_est' :  pars_est['Pi'], \n",
    "               'C_est' :  pars_est['C']}\n",
    "\n",
    "savemat(save_file,save_file_m) # does the actual saving\n",
    "\n",
    "pars_true_vec = np.hstack((pars_true['A'].reshape(n*n,),\n",
    "                    pars_true['B'].reshape(n*n,),\n",
    "                    pars_true['C'].reshape(p*n,)))\n",
    "pars_init_vec = np.hstack((pars_init['A'].reshape(n*n,),\n",
    "                    pars_init['B'].reshape(n*n,),\n",
    "                    pars_init['C'].reshape(p*n,)))\n",
    "\n",
    "np.savez(save_file, \n",
    "         pars_0_vec=pars_init_vec,\n",
    "         pars_true_vec=pars_true_vec, \n",
    "         pars_est_vec=pars_est_vec)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "\n",
    "def sdls(A,B,X0=None,Y0=None,tol=1e-10,verbose=False):\n",
    "    \"\"\"\n",
    "     [X,Y,norm_res,muv,tt,iter,fail] = SDLS(A,B,X0,Y0,tol,verbose)\n",
    "\n",
    "     Uses a stanadard path-following interior-point method based on the\n",
    "     AHO search direction to solve the symmetric semidefinite constrained\n",
    "     least squares problem:\n",
    "\n",
    "       min  norm(A*X-B,’fro’)\n",
    "       s.t. X symm. pos. semidef.\n",
    "\n",
    "     where A and B are real m-by-n matrices, and X is a real n-by-n matrix.\n",
    "     X0 and Y0 are n-by-n initial strictly feasible matrices, which means\n",
    "     that X0 and Y0 are symmetric positive definite.\n",
    "     Set as [] for the default value of eye(n).\n",
    "\n",
    "     tol is the zero tolerance described below.\n",
    "     Set as [] for the default value of 1e-10.\n",
    "\n",
    "     Set verbose = 1 for screen output during algorithm execution,\n",
    "     otherwise set vebose = 0 for no output.\n",
    "\n",
    "     SDLS returns approximate optimal solutions to the above primal\n",
    "     problem and its associated dual problem so that\n",
    "\n",
    "       norm(res,’fro’)  <=  sqrt(tol)*norm(res0,’fro’)\n",
    "            trace(X*Y)  <=  tol*trace(X0*Y0)\n",
    "\n",
    "     where res = (Z+Z’)/2-Y, Z =  A’*(A*X-B), and res0 is res evaluated Appendix B.  Matlab M-files\n",
    "     at X0, Y0.\n",
    "\n",
    "     SDLS optionally returns:\n",
    "\n",
    "      norm_res : norm(res,’fro’) at the final iterate,\n",
    "      muv  : a vector of the duality gaps for each iteration\n",
    "      tt   : the total running time of the algorithm\n",
    "      iter : the number of iterations required\n",
    "      fail : fail = 1 if the algorithm failed to achieve the desired\n",
    "             tolerances within the maximum number of iterations allowed;\n",
    "             otherwise fail = 0\n",
    "     Nathan Krislock, University of British Columbia, 2003.\n",
    "\n",
    "     N. Krislock. Numerical solution of semidefinite constrained least\n",
    "     squares problems.  M.Sc. thesis, University of British Columbia,\n",
    "     Vancouver, British Columbia, Canada, 2003.\n",
    "    \"\"\"\n",
    "\n",
    "    max_iter = 1000  # max iteration\n",
    "    m,n = A.shape\n",
    "    AA, AB, I = A.T.dot(A), A.T.dot(B), np.eye(n)\n",
    "    X = np.eye(n) if X0 is None else X0.copy()\n",
    "    Y = np.eye(n) if Y0 is None else X0.copy()\n",
    "\n",
    "    XAA,XY = X.dot(AA), X.dot(Y);\n",
    "    Z = XAA.T - AB  \n",
    "    Z = (Z+Z.T)/2  \n",
    "    R = Z - Y\n",
    "    norm_res = np.linalg.norm(R)\n",
    "    mu = np.trace(XY)/n  \n",
    "    muv = np.zeros(max_iter)\n",
    "    muv[0] = mu\n",
    "    tol1 = np.sqrt(tol)*norm_res \n",
    "    tol2 = tol*mu\n",
    "    r, theta = 0, 0 \n",
    "    while ( norm_res > tol1 or mu > tol2 ) and r < max_iter : \n",
    "        # Compute sigma and tau\n",
    "        sigma = 1/n**2 if norm_res < tol1 else 1-1/n**2\n",
    "        tau = sigma*mu;\n",
    "        # Compute the AHO search direction (dX,dY)\n",
    "        E = (np.kron(I,Y)+np.kron(Y,I))/2\n",
    "        XZ = X.dot(Z)\n",
    "        M  = (np.kron(I,XAA)+np.kron(AA,X)+np.kron(X,AA)+np.kron(XAA,I))/4 + E\n",
    "        d = (tau*I - (XZ+XZ.T)/2).reshape(-1,order='F')\n",
    "        # d = F*vec(-R) + vec(tau*I-(X*Y+Y*X)/2);\n",
    "        P,L,U = la.lu(M)\n",
    "\n",
    "        #dx = U\\(L\\(P*d))        \n",
    "        dx = np.linalg.solve(U, np.linalg.solve(L, P.dot(d)))\n",
    "        \n",
    "        dX = mat(dx)\n",
    "        dX = (dX+dX.T)/2  \n",
    "        AAdX = AA.dot(dX)\n",
    "        dY = (AAdX+AAdX.T)/2 + R  \n",
    "        dY = (dY+dY.T)/2;\n",
    "        # Compute the step length theta\n",
    "        c = 0.9 + 0.09*theta\n",
    "        theta1, theta2 = max_step(X,dX), max_step(Y,dY)\n",
    "        theta_max = np.min((theta1, theta2))\n",
    "        theta = np.min((c*theta_max,1))\n",
    "        # Update\n",
    "        X += theta*dX\n",
    "        Y += theta*dY\n",
    "        XAA, XY = X.dot(AA), X.dot(Y)\n",
    "        Z = XAA.T - AB  \n",
    "        Z = (Z+Z.T)/2  \n",
    "        R = Z - Y\n",
    "        norm_res = np.linalg.norm(R)\n",
    "        mu = np.trace(XY)/n  \n",
    "        muv[r] = mu;\n",
    "        r +=1\n",
    "    fail = True if r==max_iter and ( norm_res > tol1 or mu > tol2 ) else False\n",
    "    if fail:\n",
    "        print('\\n Failed to reach desired tolerance. \\n')\n",
    "\n",
    "    return X,Y,norm_res,muv,r,fail        \n",
    "        \n",
    "def mat(v,n=None):\n",
    "    # V = mat(v,n)\n",
    "    #\n",
    "    # Given an m*n column vector v, returns the corresponding\n",
    "    # m-by-n matrix V.  If n is not given, it is assumed that\n",
    "    # v is an n^2 column vector.\n",
    "    if n is None:\n",
    "        n = int(np.sqrt(v.size))\n",
    "        m = n  \n",
    "        mn = m*n\n",
    "    else:\n",
    "        mn = v.size;\n",
    "        m = mn//n;\n",
    "    V, k = np.zeros((m,n)), 0\n",
    "    for i in range(0,mn,m):\n",
    "        V[:,k] = v[i:(i+m)]\n",
    "        k += 1\n",
    "    return V\n",
    "                  \n",
    "def max_step(X,dX):\n",
    "    # theta = MAX_STEP(X,dX)\n",
    "    #\n",
    "    # Given n-by-n symmetric matrices, X and dX, where X is positive definite,\n",
    "    # MAX_STEP returns the largest theta_max > 0 such that\n",
    "    #\n",
    "    #   X + theta*dX\n",
    "    #\n",
    "    # is positive definite for all 0 < theta < theta_max. If X + theta*dX is\n",
    "    # positive definite for all theta, then theta_max = Inf.\n",
    "\n",
    "    x = np.max(la.eig(-dX,X,right=False,left=False));\n",
    "    \n",
    "    if np.isfinite(x) and not np.allclose(x, np.real(x)):\n",
    "        print('\\n Warning: max_step returns complex argument')\n",
    "        print('max_step: ', x)\n",
    "        print('real(max_step): ', np.real(x))\n",
    "        \n",
    "    x = np.real(x)\n",
    "    return 1/x if x > 0 else np.inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "n = 100\n",
    "df = n\n",
    "A = np.random.normal(size=(n,n))\n",
    "Pi = stats.wishart.rvs(n, np.eye(n))/n\n",
    "\n",
    "X = np.zeros((4*n,n))\n",
    "As = np.zeros((4*n,n))\n",
    "for i in range(4):\n",
    "    X[i*n:(i+1)*n,:] = np.linalg.matrix_power(A,i+1).dot(Pi)\n",
    "    As[i*n:(i+1)*n,:] = np.linalg.matrix_power(A,i+1)\n",
    "    \n",
    "X,Y,norm_res,muv,r,fail = sdls(As,X,X0=None,Y0=None,tol=1e-10,verbose=False)\n",
    "\n",
    "\n",
    "X - Pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check log-barrier values and gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pypimport numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fmin_bfgs, check_grad\n",
    "n = 3\n",
    "def f_i(theta):\n",
    "\n",
    "    A = theta[:n*n].reshape(n,n)        \n",
    "    f_log_bar = - np.log( np.linalg.det(np.eye(n)-A.dot(A.T)) )\n",
    "\n",
    "    if np.linalg.det(np.eye(n)-A.dot(A.T)) < 0:\n",
    "        print('negative det!')\n",
    "        \n",
    "    return f_log_bar\n",
    "def g_i(theta):\n",
    "\n",
    "    A = theta[:n*n].reshape(n,n)        \n",
    "    inv = np.linalg.solve(np.eye(n)-A.dot(A.T), np.eye(n))\n",
    "    g_log_bar = 2 * inv.dot(A)\n",
    "                       \n",
    "    return g_log_bar.reshape(-1,)\n",
    "                       \n",
    "%matplotlib inline\n",
    "V = np.random.normal(size=(n,n))\n",
    "V /= np.sqrt(np.sum(V**2,axis=0)).reshape(1,-1)\n",
    "#theta = np.diag(2 * np.random.uniform(0,1, n) - 1)\n",
    "theta = 0.99 * np.eye(n)\n",
    "theta = V.dot(theta).dot(np.linalg.inv(V)).reshape(-1,)\n",
    "\n",
    "print('A \\n', theta.reshape(n,n))\n",
    "print('eig(A) \\n', np.sort(np.abs(np.linalg.eigvals(theta.reshape(n,n))))[::-1])\n",
    "        \n",
    "print('difference in gradient to finite-differencing value:', check_grad(f_i, g_i, theta))\n",
    "\n",
    "max_iter = 10000\n",
    "EVs = np.zeros(max_iter)\n",
    "fs  = np.zeros(max_iter)\n",
    "for i in range(max_iter):\n",
    "    \n",
    "    theta -= 0.00001 * g_i(theta)\n",
    "    \n",
    "    EVs[i] = np.mean(np.sort(np.abs(np.linalg.eigvals(theta.reshape(n,n))))[::-1])\n",
    "    fs[i]  = f_i(theta)\n",
    "    \n",
    "    if np.mod(i, max_iter//5)==0:\n",
    "        print('A \\n', theta.reshape(n,n))\n",
    "        print('eig(A) \\n', np.sort(np.abs(np.linalg.eigvals(theta.reshape(n,n))))[::-1])\n",
    "        print('\\n f(A)', f_i(theta))\n",
    "        print('\\n')\n",
    "\n",
    "plt.figure(figsize=(20,7))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(EVs)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(fs)\n",
    "plt.show()                       ot as plt\n",
    "from scipy.optimize import fmin_bfgs, check_grad\n",
    "n = 3\n",
    "def f_i(theta):\n",
    "\n",
    "    A = theta[:n*n].reshape(n,n)        \n",
    "    f_log_bar = - np.log( np.linalg.det(np.eye(n)-A.dot(A.T)) )\n",
    "\n",
    "    if np.linalg.det(np.eye(n)-A.dot(A.T)) < 0:\n",
    "        print('negative det!')\n",
    "        \n",
    "    return f_log_bar\n",
    "def g_i(theta):\n",
    "\n",
    "    A = theta[:n*n].reshape(n,n)        \n",
    "    inv = np.linalg.solve(np.eye(n)-A.dot(A.T), np.eye(n))\n",
    "    g_log_bar = 2 * inv.dot(A)\n",
    "                       \n",
    "    return g_log_bar.reshape(-1,)\n",
    "                       \n",
    "%matplotlib inline\n",
    "V = np.random.normal(size=(n,n))\n",
    "V /= np.sqrt(np.sum(V**2,axis=0)).reshape(1,-1)\n",
    "#theta = np.diag(2 * np.random.uniform(0,1, n) - 1)\n",
    "theta = 0.99 * np.eye(n)\n",
    "theta = V.dot(theta).dot(np.linalg.inv(V)).reshape(-1,)\n",
    "\n",
    "print('A \\n', theta.reshape(n,n))\n",
    "print('eig(A) \\n', np.sort(np.abs(np.linalg.eigvals(theta.reshape(n,n))))[::-1])\n",
    "        \n",
    "print('difference in gradient to finite-differencing value:', check_grad(f_i, g_i, theta))\n",
    "\n",
    "max_iter = 10000\n",
    "EVs = np.zeros(max_iter)\n",
    "fs  = np.zeros(max_iter)\n",
    "for i in range(max_iter):\n",
    "    \n",
    "    theta -= 0.00001 * g_i(theta)\n",
    "    \n",
    "    EVs[i] = np.mean(np.sort(np.abs(np.linalg.eigvals(theta.reshape(n,n))))[::-1])\n",
    "    fs[i]  = f_i(theta)\n",
    "    \n",
    "    if np.mod(i, max_iter//5)==0:\n",
    "        print('A \\n', theta.reshape(n,n))\n",
    "        print('eig(A) \\n', np.sort(np.abs(np.linalg.eigvals(theta.reshape(n,n))))[::-1])\n",
    "        print('\\n f(A)', f_i(theta))\n",
    "        print('\\n')\n",
    "\n",
    "plt.figure(figsize=(20,7))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(EVs)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(fs)\n",
    "plt.show()                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# extracting $\\Pi$ from latent covariances given $A$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.optimize import fmin_bfgs, check_grad\n",
    "import glob, os\n",
    "import cvxopt\n",
    "\n",
    "os.chdir('../core')\n",
    "from utility import get_subpop_stats, gen_pars\n",
    "from SSID_Hankel_loss import yy_Hankel_cov_mat\n",
    "os.chdir('../dev')\n",
    "\n",
    "p,n = 1000,2\n",
    "k,l = 2,2\n",
    "k_init, l_init = 10,10\n",
    "\n",
    "nr = 2\n",
    "batch_size = p # batch_size = 1 (size-1 mini-batches), p (column mini-batches), None (full gradients)\n",
    "\n",
    "a, b1, b2, e = 0.0001, 0.9, 0.99, 1e-8\n",
    "max_iter, max_iter_init = 100, 10\n",
    "\n",
    "reps = 1\n",
    "if_stable = False\n",
    "\n",
    "# create subpopulations\n",
    "sub_pops = (np.arange(0,p//2+1), np.arange(p//2-1,p))\n",
    "\n",
    "# draw system matrices    \n",
    "ev_r = np.linspace(0.7, 0.99, nr)\n",
    "ev_c = np.exp(2 * 1j * np.pi * np.random.uniform(size= (n - nr)//2))\n",
    "ev_c = np.linspace(0.8, 0.99, (n - nr)//2) * ev_c\n",
    "\n",
    "pars = gen_pars(p,n, nr , ev_r , ev_c )\n",
    "\n",
    "obs_idx, idx_grp, co_obs, overlaps, overlap_grp, idx_overlap, Om, Ovw, Ovc = \\\n",
    "    get_subpop_stats(sub_pops, p, verbose=False)\n",
    "\n",
    "Xl = [pars['Pi'].copy()]\n",
    "for m in range(1,k+l-1):\n",
    "    Xl.append(pars['A'].dot(Xl[m-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "As = np.vstack([np.linalg.matrix_power(pars['A'],m) for m in range(1,k+l-1)])\n",
    "Xs = np.vstack(Xl[1:])\n",
    "\n",
    "vX = Xs.T.reshape(-1,)\n",
    "P2 = np.kron(np.eye(n), As)\n",
    "\n",
    "def mat(X):\n",
    "    return cvxopt.matrix(X, tc='d')\n",
    "\n",
    "P,q = mat(P2.T.dot(P2)), mat(- vX.T.dot(P2))\n",
    "G,h = mat(-np.eye(n*n)), mat(np.zeros((n*n,1)))\n",
    "dims={'l': 0, 'q': [], 's': [n]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cvxopt.solvers.options['show_progress'] = False\n",
    "sol = cvxopt.solvers.coneqp(P=P, q=q, G=G, h=h, dims=dims )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.asarray(sol['x']).reshape(n,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P, q, G, h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
