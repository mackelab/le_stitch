{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implementation of non-linear (locally (bi-)linear) models\n",
    "\n",
    "Zhao et al. (2016), \"Interpretable Nonlinear Dynamic Modeling\n",
    "of Neural Trajectories\"\n",
    "\n",
    "\\begin{align}\n",
    "y_{t+1} &= (1-\\exp(-\\tau^2)) y_t + C x_t + B_t u_t + \\epsilon_t \\\\\n",
    "\\mbox{vec}\\left(B_t\\right) &= W x_t \\nonumber \\\\\n",
    "x_{i,t} &= \\Phi_i(y_t) = \\frac{1}{Z} \\exp\\left(- \\frac{||y_t - z_i ||}{2\\sigma_i^2}\\right) \\nonumber \\\\\n",
    "\\epsilon_t &\\sim \\mathcal{N}(0, R) \\nonumber\n",
    "\\end{align}\n",
    "Parameters: \n",
    "- $C \\in \\mathbb{R}^{p \\times n}$, \n",
    "- $\\mbox{diag}(R) \\in \\mathbb{R}^p$, \n",
    "- $W \\in \\mathbb{R}^{p\\cdot{}m \\times n}$, \n",
    "- $\\tau \\in \\mathbb{R}$, $\\alpha = 1- \\exp(-\\tau^2))$ is effective parameter for AR process\n",
    "- $\\forall i = 1, \\ldots,n: z_i \\in \\mathbb{R}^p, \\sigma_i^2 \\in \\mathbb{R}$\n",
    "\n",
    "Remarks:\n",
    "- $B_t u_t = \\left( u_t^\\top \\otimes \\mathcal{1}_{p}  \\right) W x_t$, i.e. the input-dependent terms are bilinear in $x_t, u_t$. \n",
    "- $x_t = \\Phi(y_t)$ is identical to 'responsibilities' in a Gaussian mixture model with n spherical mixture distributions, with $\\mu_i = z_i$, $\\Sigma_i = \\sigma_i^2 \\mathcal{1}_p$.\n",
    "- with $C,W = 0$, the model is a simple autoregressive process. To fix a certain output variance for each $y_i$, choose\n",
    "$R_{ii} = (1-\\alpha)^2 \\mbox{Var}[y_i]$\n",
    "\n",
    "Cookbook:\n",
    "- settting $z_i = -C_{:,i}$ potentially leads to interesting (albeit extreme) dynamics\n",
    "- centering the $C_{:,i}$ ensures dynamics are centered on the origin even for small $n$\n",
    "- with $\\tau =0$ (no AR part), the $\\sigma_i^2$ become the single-most important parameters to get right\n",
    "- the behavior of the model can change drastically with $\\bar{\\sigma}^2 = < \\sigma_i^2 >$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os, psutil, time\n",
    "\n",
    "p,n,m,T = 10000,5,2,1000\n",
    "k,l =  3,3\n",
    "pars = {}\n",
    "\n",
    "# I/O matter\n",
    "mmap, chunksize = True, np.min((2*T,10000))\n",
    "#data_path, save_file = '/media/marcel/636f7b46-1fd1-4600-b69e-86d2ed82002c/stitching/hankel/', 'test'\n",
    "data_path, save_file = '../fits/', 'test'\n",
    "pa, pb = np.min((p, 1000)), np.min((p, 1000))\n",
    "idx_a, idx_b = np.sort(np.random.choice(p,pa,replace=False)), np.sort(np.random.choice(p,pb,replace=False))\n",
    "verbose=True\n",
    "\n",
    "# auto-regression on observed variables\n",
    "pars['tau'] = 0 * np.sqrt(-np.log( 0.5 ))\n",
    "pars['alpha'] = 1 - np.exp(-pars['tau']**2)\n",
    "pars['R'] = (1-pars['alpha']**2) * np.ones(p)\n",
    "\n",
    "# classic LDS pars\n",
    "pars['C'] = 1 * np.random.normal(size=(p,n))\n",
    "pars['C'] -= np.mean(pars['C'], axis=1).reshape((-1,1))\n",
    "\n",
    "# fixed non-linear mapping from observed to latents\n",
    "pars['Z'] = - pars['C'].T.copy() \n",
    "#pars['Z'] = np.random.normal(size=(n,p))\n",
    "pars['sig2'] = 1/2 * p/n * np.ones(n)\n",
    "\n",
    "# input\n",
    "u_const = np.random.normal(size=m)\n",
    "u = np.zeros((2*T,m))\n",
    "for t in range(2*T):\n",
    "    u[t] = u_const.copy()\n",
    "\n",
    "# bilinear dependence on inputs & latents\n",
    "pars['W'] = 0 * np.random.normal(size=(p*m,n))/np.sqrt(n)\n",
    "pars['B'] = lambda x: np.reshape((pars['W'].dot(x)), (m,p)).T\n",
    "pars['Ceff'] = pars['C'] + np.kron(u_const.T, np.eye(p)).dot(pars['W']) \n",
    "def predict(y, u, x,pars):\n",
    "    return pars['alpha']*y + pars['C'].dot(x) + pars['B'](x).dot(u)\n",
    "\n",
    "# technical convenience parameters\n",
    "pars['e'] = 10e-30\n",
    "pars['sqR'] = np.sqrt(pars['R'])\n",
    "print('alpha = ', pars['alpha'])\n",
    "\n",
    "def condition_on(y):\n",
    "    phi = np.exp( - np.sum((y-pars['Z'])**2,1) / (2*pars['sig2']) )\n",
    "    phi /= (pars['e'] + phi.sum())\n",
    "    return phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# draw data\n",
    "x = np.zeros((2*T,n))\n",
    "eps = np.random.normal(size=(2*T,p))\n",
    "if mmap:\n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='w+', shape=(2*T,p))\n",
    "else:\n",
    "    y = np.empty(shape=(2*T,p))\n",
    "y[0] =  np.mean(pars['Z'], axis=0) # np.random.normal(size=p)   \n",
    "for t in range(1,2*T):\n",
    "    x[t-1] = condition_on(y[t-1])    \n",
    "    y[ t ] = predict(y[t-1], u[t-1], x[t-1], pars) + pars['sqR'] * eps[t-1]\n",
    "    if mmap and np.mod(t,chunksize)==0:\n",
    "        del y # releases RAM, forces flush to disk\n",
    "        y = np.memmap(data_path+'y', dtype=np.float, mode='r+', shape=(2*T,p))        \n",
    "x[2*T-1] = condition_on(y[ 2*T-1 ])\n",
    "if mmap:\n",
    "    del y # releases RAM, forces flush to disk\n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(2*T,p))\n",
    "\n",
    "Qs = []\n",
    "for m in range(k+l):\n",
    "    Qs.append(None)\n",
    "    print('computing time-lagged covariance for lag ', str(m))\n",
    "    if mmap:\n",
    "        Q = np.memmap(data_path+'Qs_'+str(m), dtype=np.float, \n",
    "                      mode='w+', shape=(pa,pb))\n",
    "    else:\n",
    "        Q = np.empty((pa,pb))\n",
    "    Q[:] = np.cov(y[m:m-(k+l),idx_a].T, y[:-(k+l),idx_b].T)[:pa,pa:]     \n",
    "    if mmap:\n",
    "        del Q\n",
    "        Qs[m] = np.memmap(data_path+'Qs_'+str(m), dtype=np.float, \n",
    "                          mode='r', shape=(pa,pb))\n",
    "    else:\n",
    "        Qs[m] = Q\n",
    "    \n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(y[T:, idx_a])\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(x[T:])\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('x')\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(3*T//2+np.arange(100,dtype=int), x[3*T//2+np.arange(100,dtype=int)])\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('x')\n",
    "plt.show()\n",
    "if mmap:\n",
    "    del y # releases RAM, forces flush to disk\n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(2*T,p))\n",
    "\n",
    "print('\\n')\n",
    "print(psutil.virtual_memory())\n",
    "print(psutil.swap_memory())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,30))\n",
    "plt.subplot(3,2,1)\n",
    "plt.plot(y[T:,0], y[T:,1], 'ko-')\n",
    "plt.hold(True)\n",
    "for n_ in range(n):\n",
    "    i = [0,1]\n",
    "    plt.plot(pars['Z'][n_][i[0]],pars['Z'][n_][i[1]], 'o', markersize=20)    \n",
    "    plt.xlabel('y_'+str(i[0]+1))\n",
    "    plt.ylabel('y_'+str(i[1]+1))\n",
    "    plt.title('projection onto 2D, traj. + n=' + str(n) + ' RBF centres')\n",
    "    \n",
    "for j in range(3):\n",
    "    plt.subplot(3,2,2+j)\n",
    "    i = np.random.choice(p,2,replace=False)\n",
    "    plt.plot(y[T:,i[0]], y[T:,i[1]], 'ko-')\n",
    "    plt.hold(True)\n",
    "    for n_ in range(n):\n",
    "        plt.plot(pars['Z'][n_][i[0]],pars['Z'][n_][i[1]], 'o', markersize=20)    \n",
    "    plt.xlabel('y_'+str(i[0]+1))\n",
    "    plt.ylabel('y_'+str(i[1]+1))\n",
    "    \n",
    "plt.subplot(3,2,5)\n",
    "if not mmap:\n",
    "    pca = PCA()\n",
    "    pca.fit(y[T:]-np.mean(y[T:],0))\n",
    "    if T >= p:\n",
    "        plt.plot(range(1,p+1), np.cumsum(pca.explained_variance_ratio_)/np.sum(pca.explained_variance_ratio_))\n",
    "    plt.hold(True)\n",
    "    plt.plot(np.linspace(0,p+1,np.min((20,p))), \n",
    "             np.cumsum(pca.explained_variance_ratio_[:np.min((20,p))])/np.sum(pca.explained_variance_ratio_), \n",
    "             'r--')\n",
    "    plt.legend(('cum. var. expl.', 'first 20, x-axis rescaled'))\n",
    "plt.xlabel('#eigvalue')\n",
    "plt.title('% explained variance of PCA (if p not too large)')\n",
    "plt.show()\n",
    "\n",
    "print('noise variance / total variance: \\n ', np.mean(pars['R']/np.var(y,axis=0)))\n",
    "\n",
    "if p < 1000:\n",
    "    L0 = np.cov(y.T)\n",
    "    L0[np.diag_indices(p)] *= 0\n",
    "    Lr = (pars['Ceff']).dot(np.cov(x.T)).dot((pars['Ceff']).T) + np.cov(np.atleast_2d((pars['sqR'])*eps).T) #np.diag(pars['R'])\n",
    "    Lr[np.diag_indices(p)] *= 0\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(L0, interpolation='None')\n",
    "    \n",
    "    plt.title('emp. cov matrix')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(Lr, interpolation='None')\n",
    "    plt.title('est. cov matrix (C*cov(x)*C.T + cov(eps))')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.plot(L0[:], Lr[:], 'b.')\n",
    "    plt.xlabel('emp.')\n",
    "    plt.xlabel('est.')\n",
    "    plt.show()\n",
    "\n",
    "    print(np.var(y), np.var(pars['sqR']*eps), \n",
    "          np.mean(np.abs(x.dot(pars['C'].T))), np.var(x.dot(pars['C'].T)))\n",
    "#print(np.var(y, axis=0), np.var(pars['sqR']*eps, axis=0), np.mean(np.abs(x.dot(pars['C'].T)), axis=0))\n",
    "\n",
    "#nonlinearity of latents\n",
    "xp = x[0:T-1]\n",
    "xf = x[1:T]\n",
    "A_ls = np.linalg.lstsq(xp, xf)[0].T\n",
    "xf_l = xp.dot(A_ls)\n",
    "plt.figure(figsize=(np.ceil(n/2)*10,20))\n",
    "for i in range(n):\n",
    "    plt.subplot(np.ceil(n/2),2,i+1)\n",
    "    plt.plot(xf_l[:,i], xf[:,i], 'k.')\n",
    "    plt.hold(True)\n",
    "    plt.plot(xf_l[:,i], xf_l[:,i], 'r.')\n",
    "    plt.xlabel('x_pred_lin')\n",
    "    plt.ylabel('x_emp')\n",
    "    plt.axis('equal')\n",
    "    mlim = np.max((np.max(np.abs(xf_l[:,i])),np.max(np.abs(xf[:,i]))))\n",
    "    #plt.axis(1.1*np.array([-mlim,mlim,-mlim,mlim]))\n",
    "    plt.title('non-linearity of x_'+str(i+1))\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('eigenvalues of A (least squares on x_t vs. x_{t-1})')\n",
    "np.sort(np.linalg.eig(A_ls)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(x,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.linalg.eigvals(L0)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.cov(x.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "for m in range(k+l):\n",
    "    plt.subplot(k+l,1,m)\n",
    "    Q = np.empty((2*n,2*n))\n",
    "    Q[:] = np.corrcoef(x[m:m-(k+l),:].T, x[:-(k+l),:].T)\n",
    "    plt.imshow(Q, interpolation='None')    \n",
    "    plt.colorbar()\n",
    "    plt.title('m' + str(m))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10*(k+l), 10))\n",
    "for m in range(k+l):\n",
    "    print('computing time-lagged covariance for lag ', str(m))\n",
    "    \n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.subplot(1,3,1)\n",
    "    Q = np.empty((pa,pb))\n",
    "    Q[:] = (pars['Ceff'].dot(np.cov(x[m:m-(k+l),:].T, x[:-(k+l),:].T)[:n,n:]).dot(pars['Ceff'].T))[np.ix_(idx_a,idx_b)]\n",
    "    Q[np.diag_indices(pa)] *= 0\n",
    "    plt.imshow(Q, interpolation='None')    \n",
    "\n",
    "    plt.subplot(1,3,2)    \n",
    "    Qf = np.empty((pa,pb))\n",
    "    Qf[:] = np.cov(y[m:m-(k+l),idx_a].T, y[:-(k+l),idx_b].T)[:pa,pa:]    \n",
    "    if mmap:\n",
    "        del y # releases RAM, forces flush to disk\n",
    "        y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(2*T,p))    \n",
    "    Qf[np.diag_indices(pa)] *= 0\n",
    "    plt.imshow(Qf, interpolation='None')    \n",
    "\n",
    "    plt.subplot(1,3,3)    \n",
    "    plt.plot(Qf[:], Q[:], 'b.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os, psutil, time\n",
    "\n",
    "os.chdir('../core')\n",
    "import ssm_scripts, ssm_fit\n",
    "from utility import get_subpop_stats, gen_data\n",
    "from SSID_Hankel_loss import run_bad, plot_slim, plot_outputs_l2_gradient_test\n",
    "os.chdir('../dev')\n",
    "\n",
    "#np.random.seed(0)\n",
    "\n",
    "#y -= np.mean(y,axis=0)\n",
    "\n",
    "# settings for fitting algorithm\n",
    "# settings for fitting algorithm\n",
    "batch_size, max_zip_size, max_iter = 1, 100, 100\n",
    "a, b1, b2, e = 0.001, 0.9, 0.99, 1e-8\n",
    "a_R = 0.001\n",
    "linearity, stable, sym_psd = 'False', False, False\n",
    "\n",
    "# create subpopulations\n",
    "sub_pops = (np.arange(0,p), np.arange(0,p))\n",
    "\n",
    "obs_idx, idx_grp, co_obs, _, _, _, Om, _, _ = \\\n",
    "    get_subpop_stats(sub_pops=sub_pops, p=p, verbose=False)\n",
    "\n",
    "pars_init='default'        \n",
    "t = time.time()\n",
    "_, pars_est, traces = run_bad(k=k,l=l,n=n,y=y, Qs=Qs,Om=Om,idx_a=idx_a, idx_b=idx_b,\n",
    "                                      sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                                      linearity=linearity,stable=stable,init=pars_init,\n",
    "                                      alpha=a,alpha_R=a_R,b1=b1,b2=b2,e=e,max_iter=max_iter,batch_size=batch_size,\n",
    "                                      verbose=verbose, sym_psd=sym_psd, max_zip_size=max_zip_size)\n",
    "\n",
    "print('fitting time was ', time.time() - t, 's')\n",
    "print('\\n')\n",
    "print(psutil.virtual_memory())\n",
    "print(psutil.swap_memory())\n",
    "\n",
    "plot_slim(Qs,k,l,pars_est,idx_a,idx_b,traces,mmap,data_path)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(Qs[1][:], Qs[5][:], 'b.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# settings for fitting algorithm\n",
    "batch_size, max_zip_size, max_iter = 1, 100, 100\n",
    "a, b1, b2, e = 0.001, 0.9, 0.99, 1e-8\n",
    "a_R = 0.001\n",
    "linearity, stable, sym_psd = 'False', False, False\n",
    "\n",
    "\n",
    "_, pars_est, traces = run_bad(k=k,l=l,n=n,y=y, Qs=Qs,Om=Om,idx_a=idx_a, idx_b=idx_b,\n",
    "                                      sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                                      linearity=linearity,stable=stable,init=pars_est,\n",
    "                                      alpha=a,alpha_R=a_R,b1=b1,b2=b2,e=e,max_iter=max_iter,batch_size=batch_size,\n",
    "                                      verbose=verbose, sym_psd=sym_psd, max_zip_size=max_zip_size)\n",
    "\n",
    "print('fitting time was ', time.time() - t, 's')\n",
    "print('\\n')\n",
    "print(psutil.virtual_memory())\n",
    "print(psutil.swap_memory())\n",
    "\n",
    "plot_slim(Qs,k,l,pars_est,idx_a,idx_b,traces,mmap,data_path)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(Qs[0], pars_est['C'].dot(pars_est['X'][:n,:]).dot(pars_est['C'].T) + np.diag(pars_est['R']), 'b.')\n",
    "plt.hold(True)\n",
    "plt.plot(np.diag(Qs[0]), np.diag(pars_est['C'].dot(pars_est['X'][:n,:]).dot(pars_est['C'].T)) + pars_est['R'], 'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Pi = np.cov(x.T)\n",
    "L0 = np.cov(y.T)\n",
    "L0[np.diag_indices(p)] *= 0\n",
    "Lr = (pars['Ceff']).dot(Pi).dot((pars['Ceff']).T) + np.diag(pars['R'])\n",
    "Lr[np.diag_indices(p)] *= 0\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(L0, interpolation='None')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(Lr, interpolation='None')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
