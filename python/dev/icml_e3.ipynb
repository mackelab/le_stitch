{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serial subset obserations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os, psutil, time\n",
    "from scipy import linalg as la\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "from ssidid.utility import get_subpop_stats, gen_data\n",
    "from ssidid import ObservationScheme\n",
    "from subtracking import Grouse, calc_subspace_proj_error\n",
    "from ssidid.icml_scripts import run_default\n",
    "\n",
    "run = '_e3'\n",
    "# define problem size\n",
    "lag_range = np.arange(10)\n",
    "kl_ = np.max(lag_range)+1\n",
    "p, n = 1000, 10\n",
    "T_full = 100000 + kl_\n",
    "T = T_full\n",
    "\n",
    "nr = 0 # number of real eigenvalues\n",
    "snr = (1., 1.)\n",
    "whiten = True\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.90, 0.99, 0.90, 0.99\n",
    "\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "\n",
    "\n",
    "# I/O matter\n",
    "mmap, chunksize = True, np.min((p,1000))\n",
    "verbose=True\n",
    "\n",
    "rnd_seeds = range(40,50)\n",
    "overlaps = (10,)\n",
    "\n",
    "\n",
    "for rnd_seed in rnd_seeds:\n",
    "    \n",
    "    data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e3/sso/seed_' + str(rnd_seed) + '/'\n",
    "\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('seed:', str(rnd_seed))\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    \n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "    idx_a, idx_b = np.arange(p), np.arange(p)\n",
    "    file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T_full)+str(run)+'_init'\n",
    "    load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()    \n",
    "    pars_true = load_file['pars_true']\n",
    "    print('angles ev(A): ', np.sort(np.angle(np.linalg.eigvals(pars_true['A'])))/np.pi)\n",
    "    \n",
    "    #np.random.seed(rnd_seed)\n",
    "    #pars_true, x, y, _, _ = gen_data(p,n,lag_range,T_full, nr,\n",
    "    #                                 eig_m_r, eig_M_r, \n",
    "    #                                 eig_m_c, eig_M_c,\n",
    "    #                                 mmap, chunksize,\n",
    "    #                                 data_path,\n",
    "    #                                 snr=snr, whiten=whiten)        \n",
    "    #pars_true['X'] = np.vstack([ np.linalg.matrix_power(pars_true['A'],m).dot(pars_true['Pi']) for m in lag_range])\n",
    "    \n",
    "    idx_a, idx_b = np.arange(p), np.arange(p)\n",
    "\n",
    "    sso = True\n",
    "\n",
    "    for overlap in overlaps:\n",
    "\n",
    "        # compute length of recordings to keep total observation count stable    \n",
    "        print('(p,n,k+l,T) = ', (p,n,len(lag_range),T), '\\n')\n",
    "\n",
    "        reps = 1\n",
    "        ns = 10\n",
    "        sub_pops = [np.arange(0,  p//ns + overlap//2)]\n",
    "        sub_pops = sub_pops + [np.arange(i*p//ns-overlap//2, (i+1)*p//ns+overlap//2) for i in range(1,ns-1)]\n",
    "        sub_pops.append(np.arange((ns-1)*p//ns-overlap//2,p))\n",
    "        obs_pops = np.concatenate([ np.arange(len(sub_pops)) for r in range(reps) ])\n",
    "        obs_time = np.linspace(0,T, len(obs_pops)+1)[1:].astype(int)\n",
    "        obs_scheme = ObservationScheme(p=p, T=T, \n",
    "                                        sub_pops=sub_pops, \n",
    "                                        obs_pops=obs_pops, \n",
    "                                        obs_time=obs_time)\n",
    "\n",
    "        W = obs_scheme.comp_coocurrence_weights(lag_range, sso=sso, idx_a=idx_a, idx_b=idx_b)\n",
    "        if overlap < p:\n",
    "            for m in range(1, len(lag_range)):\n",
    "                W[m] = W[0].copy()\n",
    "                #W[m][0,1] = 0\n",
    "                #W[m][1,0] = 0\n",
    "\n",
    "        print('computing time-lagged covariances')\n",
    "        Qs, Om = f_l2_Hankel_comp_Q_Om(n=n,y=y,lag_range=lag_range,obs_scheme=obs_scheme,\n",
    "                              idx_a=idx_a,idx_b=idx_b,W=W,sso=sso,\n",
    "                              mmap=mmap,data_path=data_path,ts=None,ms=None)    \n",
    "        if overlap < p:\n",
    "            for m in range(len(lag_range)):    \n",
    "                Om[m] = Om[0].copy()\n",
    "                #Om[m][np.ix_(obs_scheme.idx_grp[0], obs_scheme.idx_grp[1])] = False\n",
    "                #Om[m][np.ix_(obs_scheme.idx_grp[1], obs_scheme.idx_grp[0])] = False\n",
    "\n",
    "        print_slim(Qs,Om,lag_range,pars_true,idx_a,idx_b,None,False,data_path)\n",
    "        print('true param. loss: ', f_l2_Hankel_nl(C=pars_true['C'],X=pars_true['X'],R=pars_true['R'],\n",
    "                                       Qs=Qs,Om=Om,lag_range=lag_range,ms=range(len(lag_range)),idx_a=idx_a,idx_b=idx_b))        \n",
    "\n",
    "        \n",
    "        sub_pops = obs_scheme.sub_pops\n",
    "        rnd_seed = int(time.time()) #np.random.get_state()\n",
    "        np.random.seed(rnd_seed)\n",
    "        pars_est, traces, ts= run_default(\n",
    "                    alphas    = (0.1, 0.001), \n",
    "                    b1s       = (0.9 , 0.9), \n",
    "                    a_decays  = (0.95, 0.98), \n",
    "                    batch_sizes = (1, 10), \n",
    "                    max_zip_sizes =  (1000,100), \n",
    "                    max_iters = (100, 100 ),\n",
    "                    parametrizations = ('nl', 'ln'),\n",
    "                    pars_est='default', pars_true=pars_true, n=n, \n",
    "                    y=y, sso=sso, obs_scheme=obs_scheme, lag_range=lag_range, \n",
    "                    idx_a=idx_a, idx_b=idx_b,Qs=Qs,Om=Om, W=W,\n",
    "                    traces=[[], [], []], ts = [])    \n",
    "\n",
    "\n",
    "        print('per-subpops principal angles')\n",
    "        C = pars_est['C'].copy()\n",
    "        print(principal_angle(pars_true['C'][sub_pops[0],:], C[sub_pops[0],:]))\n",
    "        print(principal_angle(pars_true['C'][sub_pops[1],:], C[sub_pops[1],:]))\n",
    "\n",
    "        print('final principal angles')\n",
    "        C = pars_est['C'].copy()\n",
    "        print(principal_angle(pars_true['C'], C))\n",
    "\n",
    "        print('final principal angles (sign-flipped)')\n",
    "        C = pars_est['C'].copy()\n",
    "        C[sub_pops[0],:] *= -1\n",
    "        print(principal_angle(pars_true['C'], C))\n",
    "\n",
    "        del C\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # settings for GROUSE\n",
    "        a_grouse = 1.\n",
    "        tracker = Grouse(p, n, a_grouse )\n",
    "        max_epoch_size = 100\n",
    "        max_iter_grouse = 1000\n",
    "        get_obs = obs_scheme.gen_get_observed()\n",
    "\n",
    "        # fit GROUSE\n",
    "        print('\\n - GROUSE')\n",
    "        tracker.step = a_grouse\n",
    "        ct = 1.\n",
    "        error = np.zeros((max_iter_grouse, n+1))\n",
    "        t = time.time()\n",
    "        get_obs = obs_scheme.gen_get_observed()\n",
    "        \n",
    "        for i in range(max_iter_grouse):\n",
    "            if np.mod(i,max_iter_grouse//10) == 0:\n",
    "                print('finished % ' + str((100*i)//max_iter_grouse))\n",
    "            idx = np.random.permutation(T-np.max(lag_range)-1)\n",
    "            idx = idx[:max_epoch_size] if len(idx) > max_epoch_size else idx\n",
    "            for j in range(len(idx)):\n",
    "                obs_idx =  np.zeros((p,1), dtype=bool)\n",
    "                obs_idx[get_obs(idx[j])] = True\n",
    "                tracker.consume(y[idx[j],:].reshape(-1,1), obs_idx)\n",
    "                ct += 1     \n",
    "                tracker.step = a_grouse / ct\n",
    "        \n",
    "            error[i] = np.hstack((calc_subspace_proj_error(pars_true['C'], tracker.U), principal_angle(pars_true['C'], tracker.U)))\n",
    "        t = time.time() - t\n",
    "        pars_est_g = {'C' : tracker.U.copy()}\n",
    "\n",
    "        print('final proj. error (est.): ', str(error[-1][0]))\n",
    "\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(error[:,1:])\n",
    "        plt.title('subspace proj. error (GROUSE)')\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.loglog(error[:,1:])\n",
    "        plt.title('subspace proj. error (GROUSE)')\n",
    "        plt.show()\n",
    "\n",
    "        print('per-subpops principal angles')\n",
    "        C = pars_est_g['C'].copy()\n",
    "        print(principal_angle(pars_true['C'][sub_pops[0],:], C[sub_pops[0],:]))\n",
    "        print(principal_angle(pars_true['C'][sub_pops[1],:], C[sub_pops[1],:]))\n",
    "\n",
    "        print('final principal angles')\n",
    "        C = pars_est_g['C'].copy()\n",
    "        print(principal_angle(pars_true['C'], C))\n",
    "\n",
    "        print('final principal angles (sign-flipped)')\n",
    "        C = pars_est_g['C'].copy()\n",
    "        C[sub_pops[0],:] *= -1\n",
    "        print(principal_angle(pars_true['C'], C))\n",
    "\n",
    "        del C    \n",
    "        traces_g = [error.copy()]\n",
    "        ts_g = [t]            \n",
    "\n",
    "        print('filtering data') \n",
    "        obs_scheme.gen_mask_from_scheme()\n",
    "        tracker = Grouse(p, n, 0. )\n",
    "        tracker.U = pars_est_g['C'].copy()\n",
    "        x_g = np.zeros((T,n))\n",
    "        for t in range (T):\n",
    "            x_g[t,:] = tracker._project(y[t,:].reshape(p,1), obs_scheme.mask[t,:].reshape(p,1)).reshape(-1)\n",
    "        obs_scheme.mask = None    \n",
    "\n",
    "        lag_range_g = np.arange(20)\n",
    "        kl_ = np.max(lag_range_g) + 1\n",
    "        print('extracting dynamics parameters') \n",
    "        pars_est_g['X'] = np.vstack([np.cov(x_g[m:-(kl_+1)+m, :].T, x_g[:-(kl_+1), :].T)[:n,n:] for m in lag_range_g])\n",
    "        pars_est_g['A'] = np.linalg.lstsq(pars_est_g['X'][:(len(lag_range_g)-1)*n,:], pars_est_g['X'][n:len(lag_range_g)*n,:])[0]\n",
    "        pars_est_g['Pi'] = (pars_est_g['X'][:n,:] + pars_est_g['X'][:n,:].T)/2 \n",
    "        ev_est = np.linalg.eigvals(pars_est_g['A'])\n",
    "        del x_g                \n",
    "        \"\"\"\n",
    "        pars_est_g, traces_g, ts_g = None, None, None\n",
    "\n",
    "        save_dict = {'p' : p,'n' : n,'T' : T,'snr' : snr,'lag_range' : lag_range,\n",
    "                     'obs_scheme' : obs_scheme, 'mmap' : mmap,'y' : data_path if mmap else y,\n",
    "                     'pars_true' : pars_true, 'pars_est' : pars_est, 'pars_est_g' : pars_est_g,\n",
    "                     'idx_a' : idx_a,'idx_b' : idx_b, 'W' : None,'Qs' : None,'Om' : None,\n",
    "                     'traces' : traces, 'traces_g' : traces_g, 'ts':ts, 'ts_g':ts_g,\n",
    "                     'rnd_seed' : rnd_seed\n",
    "                    }\n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run)+'_'+str(overlap) \n",
    "        np.savez(data_path + file_name, save_dict)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FA fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os, psutil, time\n",
    "from scipy import linalg as la\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "from ssidid import ObservationScheme, progprint_xrange\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "run = '_e3'\n",
    "# define problem size\n",
    "lag_range = np.arange(10)\n",
    "kl_ = np.max(lag_range)+1\n",
    "p, n = 1000, 10\n",
    "T = 100000 + kl_\n",
    "T_full = 100030\n",
    "\n",
    "nr = 0 # number of real eigenvalues\n",
    "snr = (1., 1.)\n",
    "whiten = True\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.90, 0.99, 0.90, 0.99\n",
    "\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "\n",
    "\n",
    "# I/O matter\n",
    "mmap, chunksize = True, np.min((p,1000))\n",
    "verbose=True\n",
    "dtype=np.float\n",
    "rnd_seeds = range(30,50)\n",
    "#overlaps = (0,5,10,15,20,25,50,100,300,1000)\n",
    "overlaps = (1000, 300, 100, 50, 25, 20, 15, 10, 5, 0)\n",
    "\n",
    "overlaps = (10,)\n",
    "for rnd_seed in rnd_seeds:\n",
    "    \n",
    "    data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e3/sso/seed_' + str(rnd_seed) + '/'\n",
    "\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('seed:', str(rnd_seed))\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    \n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='c', shape=(T,p))\n",
    "    idx_a, idx_b = np.arange(p), np.arange(p)\n",
    "    file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T_full)+str(run)+'_init'\n",
    "    load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()    \n",
    "    pars_true = load_file['pars_true']        \n",
    "\n",
    "    sso = True\n",
    "\n",
    "    for overlap in overlaps:\n",
    "\n",
    "        # compute length of recordings to keep total observation count stable    \n",
    "        print('(p,n,k+l,T) = ', (p,n,len(lag_range),T), '\\n')\n",
    "\n",
    "        reps = 1\n",
    "        ns = 10\n",
    "        sub_pops = [np.arange(0,  p//ns + overlap//2)]\n",
    "        sub_pops = sub_pops + [np.arange(i*p//ns-overlap//2, (i+1)*p//ns+overlap//2) for i in range(1,ns-1)]\n",
    "        sub_pops.append(np.arange((ns-1)*p//ns-overlap//2,p))\n",
    "        obs_pops = np.concatenate([ np.arange(len(sub_pops)) for r in range(reps) ])\n",
    "        obs_time = np.linspace(0,T, len(obs_pops)+1)[1:].astype(int)\n",
    "        obs_scheme = ObservationScheme(p=p, T=T, \n",
    "                                        sub_pops=sub_pops, \n",
    "                                        obs_pops=obs_pops, \n",
    "                                        obs_time=obs_time)\n",
    "        obs_scheme.comp_subpop_stats()        \n",
    "        obs_scheme.gen_mask_from_scheme()\n",
    "        y[np.invert(obs_scheme.mask)] = 0\n",
    "        obs_scheme.mask = None\n",
    "        obs_scheme.use_mask = False\n",
    "\n",
    "        # start fitting    \n",
    "        pars_ests = []\n",
    "        traces = []\n",
    "        ts = []\n",
    "        for j in range(len(sub_pops)):\n",
    "            print('fitting subpop #' + str(j))        \n",
    "            data = y[:obs_time[0], sub_pops[0]] if j==0 else y[obs_time[j-1]:obs_time[j], sub_pops[j]]\n",
    "            print('data shape ', data.shape)\n",
    "            rnd_seed_fit = np.random.get_state()    \n",
    "            fa = FactorAnalysis(n_components=n, \n",
    "                                tol=0.01, \n",
    "                                copy=True, \n",
    "                                max_iter=1000, \n",
    "                                noise_variance_init=None, \n",
    "                                svd_method='randomized', \n",
    "                                iterated_power=3, \n",
    "                                random_state=0)\n",
    "            t = time.time()\n",
    "            fa.fit(data)\n",
    "            t = time.time() - t\n",
    "            print('fitting time: ', t)\n",
    "            print('principal angles: ', principal_angle(pars_true['C'][sub_pops[j],:], fa.components_.T))\n",
    "\n",
    "            pars_ests.append({\n",
    "                'C' : fa.components_.T.copy(),\n",
    "                'Pi' : np.eye(n).copy(),\n",
    "                'R' : fa.noise_variance_.copy()\n",
    "            })\n",
    "            traces.append(fa.loglike_.copy())\n",
    "            ts.append(t)        \n",
    "            del fa\n",
    "\n",
    "\n",
    "        save_dict = {'p' : p,'n' : n,'T' : T,'snr' : snr,'lag_range' : lag_range,\n",
    "                     'obs_scheme' : obs_scheme, 'mmap' : mmap,'y' : None,\n",
    "                     'pars_true' : pars_true, \n",
    "                     'pars_ests' : pars_ests, 'traces' : traces, 'ts': ts, \n",
    "                     'rnd_seed' : rnd_seed_fit\n",
    "                    }\n",
    "\n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run)+'_'+str(overlap) + '_FAsp'\n",
    "        np.savez(data_path + file_name, save_dict)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import linalg as la \n",
    "run = '_e3'\n",
    "\n",
    "overlaps = (10,)\n",
    "rnd_seeds = range(30,50)\n",
    "\n",
    "\n",
    "subsp_errors_FAst    = np.zeros((len(overlaps), len(rnd_seeds)))\n",
    "subsp_errors_FAst_f  = np.zeros((len(overlaps), len(rnd_seeds)))\n",
    "for rndsidx in range(len(rnd_seeds)):\n",
    "\n",
    "    rnd_seed = rnd_seeds[rndsidx]\n",
    "    #print('\\n rndseed ' + str(rnd_seed))\n",
    "    \n",
    "    for i in range(len(overlaps)):\n",
    "        \n",
    "        overlap = overlaps[i]\n",
    "        #print('\\n overlap ' + str(overlap))\n",
    "\n",
    "        data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e3/sso/seed_' + str(rnd_seed) + '/'        \n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run)+'_'+str(overlap) + '_FAsp'\n",
    "        load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "        pars_ests = load_file['pars_ests']\n",
    "        pars_true = load_file['pars_true']\n",
    "        obs_scheme = load_file['obs_scheme']\n",
    "        p,n = pars_true['C'].shape\n",
    "\n",
    "        #pars_true['C'] = pars_true['C'][np.union1d(np.union1d(sub_pops[0],sub_pops[1]), sub_pops[2]),:]\n",
    "        \n",
    "        sub_pops = obs_scheme.sub_pops\n",
    "        C12 = np.zeros_like(pars_true['C'])    \n",
    "        C12[sub_pops[0],:] = pars_ests[0]['C']\n",
    "        for j in range(1,len(sub_pops)):\n",
    "            idx_overlap = np.intersect1d(sub_pops[j-1], sub_pops[j])\n",
    "            C2 = np.nan * np.zeros((p,n))            \n",
    "            C2[sub_pops[ j ], :] = pars_ests[ j ]['C']\n",
    "\n",
    "            if overlap > 0:\n",
    "                W, sclale = la.orthogonal_procrustes(C2[idx_overlap,:], C12[idx_overlap,:])\n",
    "            else:\n",
    "                W = np.eye(n)\n",
    "            C12[sub_pops[j],:] = C2[sub_pops[j],:].dot(W)\n",
    "\n",
    "        subsp_errors_FAst[i,rndsidx]    = calc_subspace_proj_error(pars_true['C'], C12)\n",
    "        subsp_errors_FAst_f[i, rndsidx] = calc_subspace_proj_error(pars_true['C'], C12)\n",
    "    \n",
    "        C = C12.copy()\n",
    "        C[sub_pops[0],:] *= -1\n",
    "        if calc_subspace_proj_error(pars_true['C'], C) < calc_subspace_proj_error(pars_true['C'], C12):\n",
    "            C12[sub_pops[0],:] *= -1    \n",
    "            subsp_errors_FAst_f[i, rndsidx] = calc_subspace_proj_error(pars_true['C'], C12)\n",
    "                                               \n",
    "        \n",
    "        \n",
    "plt.semilogx(np.array(overlaps)+0.01, subsp_errors_FAst, 'k')\n",
    "plt.show()\n",
    "\n",
    "data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e3/sso/'\n",
    "save_dict = {\n",
    "    'run' : run, \n",
    "    'p' : p,\n",
    "    'n' : n, \n",
    "    'overlaps' : overlaps ,\n",
    "    'rnd_seeds' : rnd_seeds,\n",
    "    'subsp_errors_FAst' : subsp_errors_FAst,   \n",
    "}\n",
    "#np.save(data_path + 'fig3_B_FAst_final_data', save_dict)       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add dynamics estimates to FA fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import linalg as la\n",
    "import glob, os, psutil, time\n",
    "\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "from ssidid import ObservationScheme, progprint_xrange\n",
    "from subtracking import Grouse, calc_subspace_proj_error\n",
    "\n",
    "\n",
    "mmap, verbose = True, True\n",
    "\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "\n",
    "run = '_e3'\n",
    "\n",
    "p,T_full,n,snr = 1000, 100010, 10, (1., 1.)\n",
    "\n",
    "data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e3/sso/'\n",
    "load_file = np.load(data_path + 'p1000n10T100010_e3_FA_all.npz')['arr_0'].tolist()\n",
    "overlaps = load_file['overlaps']\n",
    "rnd_seeds = load_file['rnd_seeds']\n",
    "\n",
    "lag_range = np.arange(10)\n",
    "kl_ = np.max(lag_range) + 1\n",
    "\n",
    "for rndsidx in range(len(rnd_seeds)):\n",
    "    \n",
    "    rnd_seed = rnd_seeds[rndsidx]\n",
    "    data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e3/sso/seed_'+str(rnd_seed)+'/'\n",
    "\n",
    "    for i in range(len(overlaps)):\n",
    "\n",
    "        T = T_full\n",
    "        overlap = overlaps[i]\n",
    "\n",
    "        print('T = ', T)\n",
    "        print('overlap =', overlap)\n",
    "        y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "        \n",
    "        sub_pops = [np.arange((p+overlap)//2),np.arange((p-overlap)//2,p)]\n",
    "\n",
    "        reps = 1\n",
    "        obs_pops = np.concatenate([ np.arange(len(sub_pops)) for r in range(reps) ])\n",
    "        obs_time = np.linspace(0,T, len(obs_pops)+1)[1:].astype(int)\n",
    "        obs_scheme = ObservationScheme(p=p, T=T, \n",
    "                                        sub_pops=sub_pops, \n",
    "                                        obs_pops=obs_pops, \n",
    "                                        obs_time=obs_time)\n",
    "        obs_scheme.comp_subpop_stats()        \n",
    "        obs_scheme.gen_mask_from_scheme()        \n",
    "        \n",
    "        pars_est = load_file['pars_est_all'][rndsidx][i]\n",
    "\n",
    "\n",
    "        print('filtering data') \n",
    "        obs_scheme.gen_mask_from_scheme()\n",
    "        tracker = Grouse(p, n, 0. )\n",
    "        tracker.U = pars_est['C'].copy()\n",
    "        x_g = np.zeros((T,n))\n",
    "        for t in range (T):\n",
    "            x_g[t,:] = tracker._project(y[t,:].reshape(p,1), obs_scheme.mask[t,:].reshape(p,1)).reshape(-1)\n",
    "        obs_scheme.mask = None\n",
    "\n",
    "        print('extracting dynamics parameters') \n",
    "        pars_est['X'] = np.vstack([np.cov(x_g[m:-(kl_+1)+m, :].T, x_g[:-(kl_+1), :].T)[:n,n:] for m in lag_range])\n",
    "        pars_est['A'] = np.linalg.lstsq(pars_est['X'][:(len(lag_range)-1)*n,:], pars_est['X'][n:len(lag_range)*n,:])[0]\n",
    "        pars_est['Pi'] = (pars_est['X'][:n,:] + pars_est['X'][:n,:].T)/2 \n",
    "\n",
    "\n",
    "save_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e3/sso/'   \n",
    "file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run) + '_FA_all_addedDyns'\n",
    "np.savez(save_path + file_name, load_file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load_file['rnd_seeds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add EM fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os, psutil, time\n",
    "from scipy import linalg as la\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "\n",
    "os.chdir(\"/home/mackelab/Desktop/Projects/Stitching/code/pyRRHDLDS/core\")\n",
    "from ssm_scripts import setup_fit_lds\n",
    "\n",
    "run = '_e3'\n",
    "# define problem size\n",
    "lag_range = np.arange(10)\n",
    "kl_ = np.max(lag_range)+1\n",
    "p, n = 1000, 10\n",
    "T_full = 100000 + kl_\n",
    "T = T_full\n",
    "\n",
    "nr = 0 # number of real eigenvalues\n",
    "snr = (1., 1.)\n",
    "whiten = True\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.90, 0.99, 0.90, 0.99\n",
    "\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "\n",
    "\n",
    "# I/O matter\n",
    "mmap, chunksize = True, np.min((p,1000))\n",
    "verbose=True\n",
    "dtype=np.float\n",
    "rnd_seeds = range(40,50)\n",
    "#overlaps = (0,10,15,20,25,50,100,300,1000)\n",
    "overlaps = (1000, 300, 100, 50, 25, 20, 15, 10, 0)\n",
    "\n",
    "\n",
    "for rnd_seed in rnd_seeds:\n",
    "    \n",
    "    data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e3/sso/seed_' + str(rnd_seed) + '/'\n",
    "\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('seed:', str(rnd_seed))\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    \n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "    idx_a, idx_b = np.arange(p), np.arange(p)\n",
    "    file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T_full)+str(run)+'_init'\n",
    "    load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()    \n",
    "    pars_true = load_file['pars_true']\n",
    "    print('angles ev(A): ', np.sort(np.angle(np.linalg.eigvals(pars_true['A'])))/np.pi)\n",
    "        \n",
    "\n",
    "    sso = True\n",
    "\n",
    "    for overlap in overlaps:\n",
    "\n",
    "        # compute length of recordings to keep total observation count stable    \n",
    "        print('(p,n,k+l,T) = ', (p,n,len(lag_range),T), '\\n')\n",
    "\n",
    "        sub_pops = [np.arange((p+overlap)//2),np.arange((p-overlap)//2,p)]\n",
    "\n",
    "        reps = 1\n",
    "        obs_pops = np.concatenate([ np.arange(len(sub_pops)) for r in range(reps) ])\n",
    "        obs_time = np.linspace(0,T, len(obs_pops)+1)[1:].astype(int)\n",
    "        obs_scheme = {'sub_pops': sub_pops,\n",
    "                      'obs_pops': obs_pops,\n",
    "                      'obs_time': obs_time}\n",
    "\n",
    "        np.random.seed(int(time.time()))\n",
    "        rnd_seed_fit = np.random.get_state()    \n",
    "        pars_init={\n",
    "            'C' : np.asarray(la.orth(np.random.normal(size=(p,n))),dtype=dtype) * np.sqrt(p) / np.sqrt(n),\n",
    "            'A' : np.asarray(np.diag(np.linspace(0.89, 0.91, n)), dtype=dtype),\n",
    "            'Q' : np.asarray(np.eye(n), dtype=dtype),\n",
    "            'R' : 2*np.ones(p, dtype=dtype),\n",
    "            'd' : np.zeros(p, dtype=dtype),\n",
    "            'mu0' :  np.zeros(n ,dtype=dtype),\n",
    "            'V0' : np.eye(  n ,dtype=dtype)            \n",
    "        }    \n",
    "\n",
    "        # EM    \n",
    "        max_iter_EM = 200\n",
    "        eps_cov = 1e-5\n",
    "        epsilon = 1e-6\n",
    "        likes = np.zeros(max_iter_EM)\n",
    "        res = np.zeros((max_iter_EM, n+1))\n",
    "        fit_lds = setup_fit_lds(y=y.T.reshape(p,T,1), \n",
    "                                u=None, \n",
    "                                max_iter=max_iter_EM,\n",
    "                                epsilon=epsilon, \n",
    "                                eps_cov=eps_cov,\n",
    "                                plot_flag=False, \n",
    "                                trace_pars_flag=True, \n",
    "                                trace_stats_flag=False, \n",
    "                                diag_R_flag=True,\n",
    "                                use_A_flag=True, \n",
    "                                use_B_flag=False)        \n",
    "        \n",
    "        \n",
    "        pars_hat = pars_init    \n",
    "        t = time.time()\n",
    "        #try:\n",
    "        pars_hat['B'] = np.empty((n,0), dtype=dtype)\n",
    "        pars_hat,ll = fit_lds(x_dim=n,\n",
    "                              pars=pars_hat, \n",
    "                              obs_scheme=obs_scheme,\n",
    "                              save_file=None)\n",
    "        for i_ in range(len(pars_hat['Cs'])-1):\n",
    "            res[i_,1:] = principal_angle(pars_hat['Cs'][i_+1], pars_true['C'])\n",
    "\n",
    "        likes = np.array(ll[1:])\n",
    "        elapsed_time = time.time() - t\n",
    "        #except:\n",
    "        #    elapsed_time = np.nan \n",
    "        #    likes = np.zeros(0)\n",
    "        #    print('\\n ')\n",
    "        #    print('EM BROKE')\n",
    "        #    print('\\n ')\n",
    "        print('elapsed time for fitting is')\n",
    "        print(elapsed_time)\n",
    "        pars_hat['Pi'] = sp.linalg.solve_discrete_lyapunov(pars_hat['A'], \n",
    "                                                           pars_hat['Q'])        \n",
    "\n",
    "        t = time.time() - t    \n",
    "        print('fitting time: ', t)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(res[:,1:])\n",
    "        plt.title('final princ. angles')\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(likes)\n",
    "        plt.show()\n",
    "\n",
    "        save_dict = {'p' : p,'n' : n,'T' : T,'snr' : snr,'lag_range' : lag_range,\n",
    "                     'pars_true' : pars_true, 'pars_est_EM' : pars_hat, \n",
    "                     'idx_a' : idx_a,'idx_b' : idx_b, 'W' : None,'Qs' : None,'Om' : None,\n",
    "                     'traces_EM' : [likes, res], 'ts_EM':[t], \n",
    "                     'rnd_seed' : rnd_seed, 'eps_cov' : eps_cov, 'epsilon' : epsilon\n",
    "                    }\n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run)+'_'+str(overlap) + '_EM_r2'\n",
    "        np.savez(data_path + file_name, save_dict)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add more EM iterations to previous fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os, psutil, time\n",
    "from scipy import linalg as la\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "\n",
    "os.chdir(\"/home/mackelab/Desktop/Projects/Stitching/code/pyRRHDLDS/core\")\n",
    "from ssm_scripts import setup_fit_lds\n",
    "\n",
    "run = '_e3'\n",
    "# define problem size\n",
    "lag_range = np.arange(10)\n",
    "kl_ = np.max(lag_range)+1\n",
    "p, n = 1000, 10\n",
    "T_full = 100000 + kl_\n",
    "T = T_full\n",
    "\n",
    "nr = 0 # number of real eigenvalues\n",
    "snr = (1., 1.)\n",
    "whiten = True\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.90, 0.99, 0.90, 0.99\n",
    "\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "\n",
    "\n",
    "# I/O matter\n",
    "mmap, chunksize = True, np.min((p,1000))\n",
    "verbose=True\n",
    "dtype=np.float\n",
    "rnd_seeds = range(43,50)\n",
    "overlaps = (1000, 300, 100, 50, 25, 20, 15, 10, 0)\n",
    "#overlaps = (0, )\n",
    "\n",
    "\n",
    "for rnd_seed in rnd_seeds:\n",
    "    \n",
    "    data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e3/sso/seed_' + str(rnd_seed) + '/'\n",
    "\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('seed:', str(rnd_seed))\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    \n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "    idx_a, idx_b = np.arange(p), np.arange(p)\n",
    "    file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T_full)+str(run)+'_init'\n",
    "    load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()    \n",
    "    pars_true = load_file['pars_true']\n",
    "    print('angles ev(A): ', np.sort(np.angle(np.linalg.eigvals(pars_true['A'])))/np.pi)\n",
    "        \n",
    "\n",
    "    sso = True\n",
    "\n",
    "    for overlap in overlaps:\n",
    "\n",
    "        # compute length of recordings to keep total observation count stable    \n",
    "        print('(p,n,k+l,T) = ', (p,n,len(lag_range),T), '\\n')\n",
    "\n",
    "        sub_pops = [np.arange((p+overlap)//2),np.arange((p-overlap)//2,p)]\n",
    "\n",
    "        reps = 1\n",
    "        obs_pops = np.concatenate([ np.arange(len(sub_pops)) for r in range(reps) ])\n",
    "        obs_time = np.linspace(0,T, len(obs_pops)+1)[1:].astype(int)\n",
    "        obs_scheme = {'sub_pops': sub_pops,\n",
    "                      'obs_pops': obs_pops,\n",
    "                      'obs_time': obs_time}\n",
    "\n",
    "\n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run)+'_'+str(overlap) + '_EM'\n",
    "        load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()    \n",
    "        pars_hat = load_file['pars_est_EM']\n",
    "        traces_EM = load_file['traces_EM']\n",
    "        ts_EM = load_file['ts_EM']\n",
    "        eps_cov = load_file['eps_cov']\n",
    "\n",
    "        # EM    \n",
    "        max_iter_EM = 100\n",
    "        epsilon = 1e-6\n",
    "        likes = np.zeros(max_iter_EM)\n",
    "        res = np.zeros((max_iter_EM, n+1))\n",
    "        fit_lds = setup_fit_lds(y=y.T.reshape(p,T,1), \n",
    "                                u=None, \n",
    "                                max_iter=max_iter_EM,\n",
    "                                epsilon=epsilon, \n",
    "                                eps_cov=eps_cov,\n",
    "                                plot_flag=False, \n",
    "                                trace_pars_flag=True, \n",
    "                                trace_stats_flag=False, \n",
    "                                diag_R_flag=True,\n",
    "                                use_A_flag=True, \n",
    "                                use_B_flag=False)        \n",
    "        \n",
    "        \n",
    "        pars_hat['As'].pop()\n",
    "        pars_hat['Qs'].pop()\n",
    "        pars_hat['Bs'].pop()\n",
    "        pars_hat['mu0s'].pop()\n",
    "        pars_hat['V0s'].pop()\n",
    "        pars_hat['Cs'].pop()\n",
    "        pars_hat['Rs'].pop()\n",
    "        pars_hat['ds'].pop()\n",
    "        pars_hat['B'] = np.empty((n,0), dtype=dtype)\n",
    "        t = time.time()\n",
    "        pars_hat,ll = fit_lds(x_dim=n,\n",
    "                              pars=pars_hat, \n",
    "                              obs_scheme=obs_scheme,\n",
    "                              save_file=None)\n",
    "        for i_ in range(max_iter_EM):\n",
    "            res[i_,1:] = principal_angle(pars_hat['Cs'][len(pars_hat['Cs'])-max_iter_EM+i_], pars_true['C'])\n",
    "\n",
    "        likes = np.array(ll[1:])\n",
    "        elapsed_time = time.time() - t\n",
    "        #except:\n",
    "        #    elapsed_time = np.nan \n",
    "        #    likes = np.zeros(0)\n",
    "        #    print('\\n ')\n",
    "        #    print('EM BROKE')\n",
    "        #    print('\\n ')\n",
    "        print('elapsed time for fitting is')\n",
    "        print(elapsed_time)\n",
    "        pars_hat['Pi'] = sp.linalg.solve_discrete_lyapunov(pars_hat['A'], \n",
    "                                                           pars_hat['Q'])        \n",
    "\n",
    "        t = time.time() - t    \n",
    "        print('fitting time: ', t)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(res[:,1:])\n",
    "        plt.title('final princ. angles')\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(likes)\n",
    "        plt.show()\n",
    "        \n",
    "        ts_EM.append(t)\n",
    "        traces_EM[0] = np.hstack((traces_EM[0], likes))\n",
    "        traces_EM[1] = np.vstack((traces_EM[1], res))\n",
    "        snr, lag_range = load_file['snr'], load_file['lag_range']\n",
    "        idx_a, idx_b = load_file['idx_a'], load_file['idx_b']\n",
    "\n",
    "        save_dict = {'p' : p,'n' : n,'T' : T,'snr' : snr,'lag_range' : lag_range,\n",
    "                     'pars_true' : pars_true, 'pars_est_EM' : pars_hat, \n",
    "                     'idx_a' : idx_a,'idx_b' : idx_b, 'W' : None,'Qs' : None,'Om' : None,\n",
    "                     'traces_EM' : traces_EM, 'ts_EM':ts_EM, \n",
    "                     'rnd_seed' : rnd_seed, 'eps_cov' : eps_cov, 'epsilon' : epsilon\n",
    "                    }\n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run)+'_'+str(overlap) + '_EM'\n",
    "        np.savez(data_path + file_name, save_dict)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add SSID fits with harsh learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os, psutil, time\n",
    "from scipy import linalg as la\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "from ssidid.utility import get_subpop_stats, gen_data\n",
    "from ssidid import ObservationScheme\n",
    "from subtracking import Grouse, calc_subspace_proj_error\n",
    "from ssidid.icml_scripts import run_default\n",
    "\n",
    "run = '_e3'\n",
    "# define problem size\n",
    "lag_range = np.arange(10)\n",
    "kl_ = np.max(lag_range)+1\n",
    "p, n = 1000, 10\n",
    "T_full = 100000 + kl_\n",
    "T = T_full\n",
    "\n",
    "nr = 0 # number of real eigenvalues\n",
    "snr = (1., 1.)\n",
    "whiten = True\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.90, 0.99, 0.90, 0.99\n",
    "\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "\n",
    "\n",
    "# I/O matter\n",
    "mmap, chunksize = True, np.min((p,1000))\n",
    "verbose=True\n",
    "\n",
    "rnd_seeds = range(30,50)\n",
    "overlaps = (10,)\n",
    "\n",
    "\n",
    "for rnd_seed in rnd_seeds:\n",
    "    \n",
    "    data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e3/sso/seed_' + str(rnd_seed) + '/'\n",
    "\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('seed:', str(rnd_seed))\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    \n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "    \n",
    "    print('first data entries: ', y[:10,:10])\n",
    "        \n",
    "    file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T_full + 20)+'_e3_init'\n",
    "    load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()    \n",
    "    pars_true = load_file['pars_true']\n",
    "    sso = True\n",
    "    idx_a, idx_b = np.arange(p), np.arange(p)\n",
    "\n",
    "    for overlap in overlaps:\n",
    "\n",
    "        # compute length of recordings to keep total observation count stable    \n",
    "        print('(p,n,k+l,T) = ', (p,n,len(lag_range),T), '\\n')\n",
    "\n",
    "        sub_pops = (np.arange((p+overlap)//2),np.arange((p-overlap)//2,p))\n",
    "\n",
    "        reps = 1\n",
    "        obs_pops = np.concatenate([ np.arange(len(sub_pops)) for r in range(reps) ])\n",
    "        obs_time = np.linspace(0,T, len(obs_pops)+1)[1:].astype(int)\n",
    "        obs_scheme = ObservationScheme(p=p, T=T, \n",
    "                                        sub_pops=sub_pops, \n",
    "                                        obs_pops=obs_pops, \n",
    "                                        obs_time=obs_time)\n",
    "\n",
    "        W = obs_scheme.comp_coocurrence_weights(lag_range, sso=sso, idx_a=idx_a, idx_b=idx_b)\n",
    "        if overlap < p:\n",
    "            for m in range(len(lag_range)):\n",
    "                W[m][0,1] = 0\n",
    "                W[m][1,0] = 0\n",
    "\n",
    "        print('computing time-lagged covariances')\n",
    "        Qs, Om = f_l2_Hankel_comp_Q_Om(n=n,y=y,lag_range=lag_range,obs_scheme=obs_scheme,\n",
    "                              idx_a=idx_a,idx_b=idx_b,W=W,sso=sso,\n",
    "                              mmap=mmap,data_path=data_path,ts=None,ms=None)    \n",
    "        if overlap < p:\n",
    "            for m in range(len(lag_range)):    \n",
    "                Om[m][np.ix_(obs_scheme.idx_grp[0], obs_scheme.idx_grp[1])] = False\n",
    "                Om[m][np.ix_(obs_scheme.idx_grp[1], obs_scheme.idx_grp[0])] = False\n",
    "\n",
    "        print_slim(Qs,Om,lag_range,pars_true,idx_a,idx_b,None,False,data_path)\n",
    "        print('true param. loss: ', f_l2_Hankel_nl(C=pars_true['C'],X=pars_true['X'],R=pars_true['R'],\n",
    "                                       Qs=Qs,Om=Om,lag_range=lag_range,ms=range(len(lag_range)),idx_a=idx_a,idx_b=idx_b))        \n",
    "\n",
    "        \n",
    "        sub_pops = obs_scheme.sub_pops\n",
    "        rnd_seed = np.random.get_state()\n",
    "        #np.random.seed(rnd_seed)\n",
    "        pars_init={\n",
    "            'C' : np.asarray(la.orth(np.random.normal(size=(p,n))),dtype=dtype) * np.sqrt(p) / np.sqrt(n),\n",
    "            'A' : np.asarray(np.diag(np.linspace(0.89, 0.91, n)), dtype=dtype), \n",
    "            'Pi' : np.asarray(np.eye(n), dtype=dtype),\n",
    "            'R' : np.ones(p, dtype=dtype)    \n",
    "        }            \n",
    "        pars_init['X'] = np.vstack([ np.linalg.matrix_power(pars_init['A'],m).dot(pars_init['Pi']) for m in lag_range])\n",
    "\n",
    "        pars_est, traces, ts= run_default(\n",
    "                    alphas    = (0.05, 0.001), \n",
    "                    b1s       = (0.9, 0.95), \n",
    "                    a_decays  = (0.95, 0.98), \n",
    "                    batch_sizes = (1, 10), \n",
    "                    max_zip_sizes =  (1000, 100), \n",
    "                    max_iters = (100, 100 ),\n",
    "                    parametrizations = ('nl', 'ln'),\n",
    "                    pars_est=pars_init, pars_true=pars_true, n=n, \n",
    "                    y=y, sso=sso, obs_scheme=obs_scheme, lag_range=lag_range, \n",
    "                    idx_a=idx_a, idx_b=idx_b,Qs=Qs,Om=Om, W=W,\n",
    "                    traces=[[], [], []], ts = [])    \n",
    "        \n",
    "        print('final subsp. proj. error: ', calc_subspace_proj_error(pars_est['C'], pars_true['C']))\n",
    "\n",
    "\n",
    "        print('per-subpops principal angles')\n",
    "        C = pars_est['C'].copy()\n",
    "        print(principal_angle(pars_true['C'][sub_pops[0],:], C[sub_pops[0],:]))\n",
    "        print(principal_angle(pars_true['C'][sub_pops[1],:], C[sub_pops[1],:]))\n",
    "\n",
    "        print('final principal angles')\n",
    "        C = pars_est['C'].copy()\n",
    "        print(principal_angle(pars_true['C'], C))\n",
    "\n",
    "        print('final principal angles (sign-flipped)')\n",
    "        C = pars_est['C'].copy()\n",
    "        C[sub_pops[0],:] *= -1\n",
    "        print(principal_angle(pars_true['C'], C))\n",
    "\n",
    "        del C\n",
    "\n",
    "        save_dict = {'p' : p,'n' : n,'T' : T,'snr' : snr,'lag_range' : lag_range,\n",
    "                     'obs_scheme' : obs_scheme, 'mmap' : mmap,'y' : data_path if mmap else y,\n",
    "                     'pars_true' : pars_true, 'pars_est' : pars_est, 'pars_est_g' : None,\n",
    "                     'idx_a' : idx_a,'idx_b' : idx_b, 'W' : None,'Qs' : None,'Om' : None,\n",
    "                     'traces' : traces, 'traces_g' : None, 'ts':ts, 'ts_g':None,\n",
    "                     'rnd_seed' : rnd_seed\n",
    "                    }\n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run)+'_'+str(overlap) + '_r2'\n",
    "        np.savez(data_path + file_name, save_dict)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os, psutil, time\n",
    "from scipy import linalg as la\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "from ssidid.utility import get_subpop_stats, gen_data\n",
    "from ssidid import ObservationScheme\n",
    "from subtracking import Grouse, calc_subspace_proj_error\n",
    "from ssidid.icml_scripts import run_default\n",
    "\n",
    "run = '_e3'\n",
    "# define problem size\n",
    "lag_range = np.arange(10)\n",
    "kl_ = np.max(lag_range)+1\n",
    "p, n = 1000, 10\n",
    "T_full = 100000 + kl_\n",
    "T = T_full\n",
    "\n",
    "nr = 0 # number of real eigenvalues\n",
    "snr = (1., 1.)\n",
    "whiten = True\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.90, 0.99, 0.90, 0.99\n",
    "\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "\n",
    "\n",
    "# I/O matter\n",
    "mmap, chunksize = True, np.min((p,1000))\n",
    "verbose=True\n",
    "\n",
    "rnd_seeds = range(30,50)\n",
    "overlaps = (10,)\n",
    "\n",
    "\n",
    "subsp_errs = np.zeros((len(overlaps), len(rnd_seeds)))\n",
    "\n",
    "rndsidx = 0\n",
    "\n",
    "for rnd_seed in rnd_seeds:\n",
    "    \n",
    "    data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e3/sso/seed_' + str(rnd_seed) + '/'\n",
    "\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('seed:', str(rnd_seed))\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    \n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "    \n",
    "    print('first data entries: ', y[:10,:10])\n",
    "        \n",
    "    file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T_full + 20)+'_e3_init'\n",
    "    load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()    \n",
    "    pars_true = load_file['pars_true']\n",
    "    sso = True\n",
    "    idx_a, idx_b = np.arange(p), np.arange(p)\n",
    "\n",
    "    i = 0\n",
    "    for overlap in overlaps:\n",
    "\n",
    "        # compute length of recordings to keep total observation count stable    \n",
    "        print('(p,n,k+l,T) = ', (p,n,len(lag_range),T), '\\n')\n",
    "\n",
    "        sub_pops = (np.arange((p+overlap)//2),np.arange((p-overlap)//2,p))\n",
    "        \n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run)+'_'+str(overlap) + '_r2'\n",
    "        load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()    \n",
    "        pars_est  = load_file['pars_est']\n",
    "        \n",
    "        print('final subsp. proj. error: ', calc_subspace_proj_error(pars_est['C'], pars_true['C']))\n",
    "        \n",
    "        subsp_errs[i, rndsidx] = calc_subspace_proj_error(pars_est['C'], pars_true['C'])\n",
    "        \n",
    "        print('per-subpops principal angles')\n",
    "        C = pars_est['C'].copy()\n",
    "        print(principal_angle(pars_true['C'][sub_pops[0],:], C[sub_pops[0],:]))\n",
    "        print(principal_angle(pars_true['C'][sub_pops[1],:], C[sub_pops[1],:]))\n",
    "\n",
    "        print('final principal angles')\n",
    "        C = pars_est['C'].copy()\n",
    "        print(principal_angle(pars_true['C'], C))\n",
    "\n",
    "        print('final principal angles (sign-flipped)')\n",
    "        C = pars_est['C'].copy()\n",
    "        C[sub_pops[0],:] *= -1\n",
    "        print(principal_angle(pars_true['C'], C))\n",
    "        \n",
    "        i += 1\n",
    "    rndsidx += 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subsp_errs[0,10] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.nanmean(subsp_errs), np.nanstd(subsp_errs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add GROUSE fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os, psutil, time\n",
    "from scipy import linalg as la\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "from ssidid.utility import get_subpop_stats, gen_data\n",
    "from ssidid import ObservationScheme\n",
    "from subtracking import Grouse, calc_subspace_proj_error\n",
    "from ssidid.icml_scripts import run_default\n",
    "\n",
    "run = '_e3_slim'\n",
    "# define problem size\n",
    "lag_range = np.arange(30)\n",
    "kl_ = np.max(lag_range)+1\n",
    "p, n = 1000, 10\n",
    "T_full = 100000 + kl_\n",
    "T = T_full\n",
    "\n",
    "nr = 0 # number of real eigenvalues\n",
    "snr = (1., 1.)\n",
    "whiten = True\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.90, 0.99, 0.90, 0.99\n",
    "\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "\n",
    "\n",
    "# I/O matter\n",
    "mmap, chunksize = True, np.min((p,1000))\n",
    "verbose=True\n",
    "\n",
    "rnd_seeds = range(30,40)\n",
    "overlaps = (5000, 50000)\n",
    "\n",
    "\n",
    "for rnd_seed in rnd_seeds:\n",
    "    \n",
    "    data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e3/sso/explore/seed_' + str(rnd_seed) + '/'\n",
    "\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('seed:', str(rnd_seed))\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    \n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "        \n",
    "    idx_a, idx_b = np.arange(p), np.arange(p)\n",
    "\n",
    "    file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T_full)+'_e3_init'\n",
    "    load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()    \n",
    "    pars_true = load_file['pars_true']\n",
    "    sso = True\n",
    "\n",
    "    for overlap in overlaps:\n",
    "\n",
    "        # compute length of recordings to keep total observation count stable    \n",
    "        print('(p,n,k+l,T) = ', (p,n,len(lag_range),T), '\\n')\n",
    "        \n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run)+'_'+str(overlap)\n",
    "        load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()            \n",
    "        pars_est = load_file['pars_est']\n",
    "        traces = load_file['traces']\n",
    "        ts = load_file['ts']\n",
    "        W,Qs,Om =  load_file['W'],load_file['Qs'],load_file['Om']\n",
    "        obs_scheme = load_file['obs_scheme']\n",
    "        obs_scheme.use_mask = False # sso scheme! just to make sure...\n",
    "        \n",
    "        W = obs_scheme.comp_coocurrence_weights(lag_range, sso=sso, idx_a=idx_a, idx_b=idx_b)\n",
    "        if overlap < p:\n",
    "            for m in range(len(lag_range)):\n",
    "                W[m][0,1] = 0\n",
    "                W[m][1,0] = 0\n",
    "\n",
    "        print('computing time-lagged covariances')\n",
    "        Qs, Om = f_l2_Hankel_comp_Q_Om(n=n,y=y,lag_range=lag_range,obs_scheme=obs_scheme,\n",
    "                              idx_a=idx_a,idx_b=idx_b,W=W,sso=sso,\n",
    "                              mmap=mmap,data_path=data_path,ts=None,ms=None)    \n",
    "        \n",
    "        \n",
    "        print_slim(Qs,Om,lag_range,pars_true,idx_a,idx_b,None,False,data_path)\n",
    "        print('true param. loss: ', f_l2_Hankel_nl(C=pars_true['C'],X=pars_true['X'],R=pars_true['R'],\n",
    "                                       Qs=Qs,Om=Om,lag_range=lag_range,ms=range(len(lag_range)),idx_a=idx_a,idx_b=idx_b))        \n",
    "\n",
    "                                                   \n",
    "        print_slim(Qs,Om,lag_range,pars_est,idx_a,idx_b,traces[-1],False,data_path)\n",
    "        print('est. param. loss: ', f_l2_Hankel_nl(C=pars_est['C'],X=pars_est['X'],R=pars_est['R'],\n",
    "                                       Qs=Qs,Om=Om,lag_range=lag_range,ms=range(len(lag_range)),idx_a=idx_a,idx_b=idx_b))        \n",
    "                \n",
    "        sub_pops = obs_scheme.sub_pops\n",
    "        print('\\n')\n",
    "        if len(sub_pops) > 1:\n",
    "            print('overlap: ', str(len(np.intersect1d(sub_pops[0], sub_pops[1]))))            \n",
    "\n",
    "        ts_g = load_file['ts_g']\n",
    "        traces_g = load_file['traces_g']\n",
    "        pars_est_g = load_file['pars_est_g'].copy()\n",
    "        rnd_seed = load_file['rnd_seed']\n",
    "        \n",
    "        \"\"\"        \n",
    "        # settings for GROUSE\n",
    "        a_grouse = 1.\n",
    "        tracker = Grouse(p, n, a_grouse )\n",
    "        max_epoch_size = 1000\n",
    "        max_iter_grouse = 1500\n",
    "        get_obs = obs_scheme.gen_get_observed()\n",
    "\n",
    "        # fit GROUSE\n",
    "        print('\\n - GROUSE')\n",
    "        tracker.step = a_grouse\n",
    "        ct = 1.\n",
    "        error = np.zeros((max_iter_grouse, n+1))\n",
    "        t = time.time()\n",
    "        get_obs = obs_scheme.gen_get_observed()\n",
    "        \n",
    "        for i in range(max_iter_grouse):\n",
    "            if np.mod(i,max_iter_grouse//10) == 0:\n",
    "                print('finished % ' + str((100*i)//max_iter_grouse))\n",
    "            idx = np.random.permutation(T-np.max(lag_range)-1)\n",
    "            idx = idx[:max_epoch_size] if len(idx) > max_epoch_size else idx\n",
    "            for j in range(len(idx)):\n",
    "                obs_idx =  np.zeros((p,1), dtype=bool)\n",
    "                obs_idx[get_obs(idx[j])] = True\n",
    "                tracker.consume(y[idx[j],:].reshape(-1,1), obs_idx)\n",
    "                ct += 1     \n",
    "                tracker.step = a_grouse / ct\n",
    "        \n",
    "            error[i] = np.hstack((calc_subspace_proj_error(pars_true['C'], tracker.U), principal_angle(pars_true['C'], tracker.U)))\n",
    "        t = time.time() - t\n",
    "        pars_est_g = {'C' : tracker.U.copy()}\n",
    "\n",
    "        print('final proj. error (est.): ', str(error[-1][0]))\n",
    "\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(error[:,1:])\n",
    "        plt.title('subspace proj. error (GROUSE)')\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.loglog(error[:,1:])\n",
    "        plt.title('subspace proj. error (GROUSE)')\n",
    "        plt.show()\n",
    "\n",
    "        print('per-subpops principal angles')\n",
    "        C = pars_est_g['C'].copy()\n",
    "        print(principal_angle(pars_true['C'][sub_pops[0],:], C[sub_pops[0],:]))\n",
    "        print(principal_angle(pars_true['C'][sub_pops[1],:], C[sub_pops[1],:]))\n",
    "\n",
    "        print('final principal angles')\n",
    "        C = pars_est_g['C'].copy()\n",
    "        print(principal_angle(pars_true['C'], C))\n",
    "\n",
    "        print('final principal angles (sign-flipped)')\n",
    "        C = pars_est_g['C'].copy()\n",
    "        C[sub_pops[0],:] *= -1\n",
    "        print(principal_angle(pars_true['C'], C))\n",
    "\n",
    "        del C    \n",
    "        traces_g = [error.copy()]\n",
    "        ts_g = [t]         \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        print('filtering data') \n",
    "        obs_scheme.gen_mask_from_scheme()\n",
    "        tracker = Grouse(p, n, 0. )\n",
    "        tracker.U = pars_est_g['C'].copy()\n",
    "        x_g = np.zeros((T,n))\n",
    "        for t in range (T):\n",
    "            x_g[t,:] = tracker._project(y[t,:].reshape(p,1), obs_scheme.mask[t,:].reshape(p,1)).reshape(-1)\n",
    "        obs_scheme.mask = None\n",
    "\n",
    "        print('extracting dynamics parameters') \n",
    "        pars_est_g['X'] = np.vstack([np.cov(x_g[m:-(kl_+1)+m, :].T, x_g[:-(kl_+1), :].T)[:n,n:] for m in lag_range])\n",
    "        pars_est_g['A'] = np.linalg.lstsq(pars_est_g['X'][:(len(lag_range)-1)*n,:], pars_est_g['X'][n:len(lag_range)*n,:])[0]\n",
    "        pars_est_g['Pi'] = (pars_est_g['X'][:n,:] + pars_est_g['X'][:n,:].T)/2 \n",
    "        ev_est = np.linalg.eigvals(pars_est_g['A'])\n",
    "        \n",
    "        \n",
    "        save_dict = {'p' : p,'n' : n,'T' : T,'snr' : snr,'lag_range' : lag_range,\n",
    "                     'obs_scheme' : obs_scheme, 'mmap' : mmap,'y' : data_path if mmap else y,\n",
    "                     'pars_true' : pars_true, 'pars_est' : pars_est, 'pars_est_g' : pars_est_g,\n",
    "                     'idx_a' : idx_a,'idx_b' : idx_b, 'W' : None,'Qs' : None,'Om' : None,\n",
    "                     'traces' : traces, 'traces_g' : traces_g, 'ts':ts, 'ts_g':ts_g,\n",
    "                     'rnd_seed' : rnd_seed\n",
    "                    }\n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run)+'_'+str(overlap)\n",
    "        np.savez(data_path + file_name, save_dict)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get estimates of linear latent dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import linalg as la\n",
    "import glob, os, psutil, time\n",
    "\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "from ssidid import ObservationScheme, progprint_xrange\n",
    "from subtracking import Grouse, calc_subspace_proj_error\n",
    "\n",
    "rnd_seed = 32\n",
    "\n",
    "data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e3/seed_' + str(rnd_seed) + '/'\n",
    "mmap, verbose = True, True\n",
    "\n",
    "#run = '_e3_init'\n",
    "#p,T_full,n,snr,lag_range = 1000, 200020, 20, (1., 1.), np.arange(20)\n",
    "#file_name = 'p' + str(p) + 'n' + str(n) + 'T' + str(T_full) +  run\n",
    "#load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "#pars_true = load_file['pars_true'].copy()\n",
    "#del file_name\n",
    "#kl_ = np.max(lag_range)+1\n",
    "#ev_true = np.linalg.eigvals(pars_true['A'])\n",
    "\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "\n",
    "rnd_seeds = range(30,40)\n",
    "overlaps = (10,15,20,25,50,100,300)\n",
    "run = '_e3_slim'\n",
    "    \n",
    "p,T_full,n,snr = 1000, 100030, 10, (1., 1.)\n",
    "lag_range = np.arange(20)\n",
    "kl_ = np.max(lag_range) + 1\n",
    "\n",
    "for rnd_seed in rnd_seeds:\n",
    "    \n",
    "    data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e3/sso/seed_'+str(rnd_seed)+'/'\n",
    "\n",
    "    for i in range(len(overlaps)):\n",
    "\n",
    "        T = T_full\n",
    "        overlap = overlaps[i]\n",
    "\n",
    "        print('T = ', T)\n",
    "        print('overlap =', overlap)\n",
    "        y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "\n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T_full)+str(run)+'_'+str(overlap)\n",
    "        load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "        \n",
    "        obs_scheme, W,Qs,Om = load_file['obs_scheme'], load_file['W'],load_file['Qs'],load_file['Om']\n",
    "        pars_est_g = load_file['pars_est_g']\n",
    "        traces_g = load_file['traces_g']\n",
    "        idx_a, idx_b = load_file['idx_a'].copy(), load_file['idx_b'].copy()\n",
    "\n",
    "        print('filtering data') \n",
    "        obs_scheme.gen_mask_from_scheme()\n",
    "        tracker = Grouse(p, n, 0. )\n",
    "        tracker.U = pars_est_g['C'].copy()\n",
    "        x_g = np.zeros((T,n))\n",
    "        for t in range (T):\n",
    "            x_g[t,:] = tracker._project(y[t,:].reshape(p,1), obs_scheme.mask[t,:].reshape(p,1)).reshape(-1)\n",
    "        obs_scheme.mask = None\n",
    "\n",
    "        print('extracting dynamics parameters') \n",
    "        pars_est_g['X'] = np.vstack([np.cov(x_g[m:-(kl_+1)+m, :].T, x_g[:-(kl_+1), :].T)[:n,n:] for m in lag_range])\n",
    "        pars_est_g['A'] = np.linalg.lstsq(pars_est_g['X'][:(len(lag_range)-1)*n,:], pars_est_g['X'][n:len(lag_range)*n,:])[0]\n",
    "        pars_est_g['Pi'] = (pars_est_g['X'][:n,:] + pars_est_g['X'][:n,:].T)/2 \n",
    "        ev_est = np.linalg.eigvals(pars_est_g['A'])\n",
    "\n",
    "        print('storing')\n",
    "        save_dict = {'p' : p,'n' : n,'T' : T,'snr' : snr,'lag_range' : lag_range,\n",
    "                     'obs_scheme' : obs_scheme, 'mmap' : mmap,'y' : data_path if mmap else y,\n",
    "                     'pars_true' : load_file['pars_true'], 'pars_est' : load_file['pars_est'], \n",
    "                     'idx_a' : load_file['idx_a'],'idx_b' : load_file['idx_b'], 'W' : W,'Qs' : Qs,'Om' : Om,\n",
    "                     'traces' : load_file['traces'], 'ts': load_file['ts'], \n",
    "                     'rnd_seed' : load_file['rnd_seed'], \n",
    "                     'pars_est_g' : pars_est_g, 'traces_g' :  load_file['traces_g'], 'ts_g': load_file['ts_g']\n",
    "                    }    \n",
    "\n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run)+'_'+str(overlap)\n",
    "        np.savez(data_path + file_name, save_dict)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# missing at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os, psutil, time\n",
    "from scipy import linalg as la\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "from ssidid.utility import get_subpop_stats, gen_data\n",
    "from ssidid import ObservationScheme, progprint_xrange\n",
    "from subtracking import Grouse, calc_subspace_proj_error\n",
    "from ssidid.icml_scripts import run_default\n",
    "\n",
    "run = '_e3rnd'\n",
    "\n",
    "# define problem size\n",
    "lag_range = np.arange(10)\n",
    "lag_range_g = np.arange(20)\n",
    "\n",
    "kl_ = np.max(lag_range)+1\n",
    "p, n = 1000, 10\n",
    "T_full = 100030\n",
    "T = 10000 + kl_\n",
    "\n",
    "nr = 0 # number of real eigenvalues\n",
    "snr = (9., 9.)\n",
    "whiten = True\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.90, 0.99, 0.90, 0.99\n",
    "\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "\n",
    "\n",
    "# I/O matter\n",
    "mmap, chunksize = True, np.min((p,1000))\n",
    "verbose=True\n",
    "\n",
    "\n",
    "sso = True\n",
    "\n",
    "obs_scheme = ObservationScheme(p=p, T=T, \n",
    "                                sub_pops=(np.arange(p),), \n",
    "                                obs_pops=(0,), \n",
    "                                obs_time=(T,))\n",
    "idx_a, idx_b = np.arange(p), np.arange(p)\n",
    "\n",
    "\n",
    "rnd_seeds = range(11,20)\n",
    "fracs_obs = (0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0)\n",
    "\n",
    "for rnd_seed in rnd_seeds:\n",
    "    \n",
    "    #data_path = '/media/marcel/636f7b46-1fd1-4600-b69e-86d2ed82002c/stitching/hankel/icml_e3/rnd/seed_' + str(rnd_seed) + '/'\n",
    "    data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e1/seed_' + str(int(rnd_seed)) + '/'\n",
    "    save_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e3/rnd/seed_' + str(int(rnd_seed)) + '/'\n",
    "\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('seed:', str(rnd_seed))\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    np.random.seed(rnd_seed)\n",
    "    pars_true, x, y, _, _ = gen_data(p,n,lag_range,T, nr,\n",
    "                                     eig_m_r, eig_M_r, \n",
    "                                     eig_m_c, eig_M_c,\n",
    "                                     mmap, chunksize,\n",
    "                                     data_path,\n",
    "                                     snr=snr, whiten=whiten)        \n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='r+', shape=(T,p))\n",
    "    y -= y.mean(axis=0)\n",
    "    #y[np.invert(obs_scheme.mask)] = np.nan\n",
    "    del y\n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "    idx_a, idx_b = np.arange(p), np.arange(p)\n",
    "    \"\"\"\n",
    "    \n",
    "    file_name = 'p' + str(p) + 'n' + str(n) + 'T' + str(T_full) + 'snr' + str(np.int(np.mean(snr)//1)) + 'e1_init'\n",
    "    load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "    pars_true = load_file['pars_true']    \n",
    "    \n",
    "    y_full = np.memmap(data_path+'y_full', dtype=np.float, mode='r', shape=(T_full,p))\n",
    "    y = np.memmap(save_path+'y', dtype=np.float, mode='w+', shape=(T,p))\n",
    "    y[:] = y_full[:T, :].copy()\n",
    "    del y_full\n",
    "    del y\n",
    "    chunksize = np.minimum(p, 100)\n",
    "    if mmap: \n",
    "        print('ensuring zero-mean data for given observation scheme')\n",
    "        for i in progprint_xrange(p//chunksize, perline=10):\n",
    "            y = np.memmap(save_path+'y', dtype=np.float, mode='r+', shape=(T,p))\n",
    "            y[:, i*chunksize:(i+1)*chunksize] = y[:, i*chunksize:(i+1)*chunksize] - y[:, i*chunksize:(i+1)*chunksize].mean(axis=0)\n",
    "            del y\n",
    "        if (p//chunksize)*chunksize < p:\n",
    "            y = np.memmap(save_path+'y', dtype=np.float, mode='r+', shape=(T,p))\n",
    "            y[:, (p//chunksize)*chunksize:] = y[:, (p//chunksize)*chunksize:] - y[:, (p//chunksize)*chunksize:].mean(axis=0)\n",
    "            del y        \n",
    "        y = np.memmap(save_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "    else:\n",
    "        y -= y.mean(axis=0)\n",
    "    \n",
    "    for frac_obs in fracs_obs:\n",
    "        \n",
    "        print('\\n')\n",
    "        print('fraction observed:', str(frac_obs))\n",
    "        print('\\n')\n",
    "        \n",
    "        n_obs = np.ceil(p * frac_obs)\n",
    "        mask = np.zeros((T,p),dtype=bool)\n",
    "        for t in range(T):\n",
    "            mask[t, np.random.choice(p, n_obs, replace=False)] = 1\n",
    "        obs_scheme.mask = mask\n",
    "\n",
    "        print('(p,n,k+l,T) = ', (p,n,len(lag_range),T), '\\n')\n",
    "\n",
    "        if p*T < 1e8:\n",
    "            plt.figure(figsize=(20,10))\n",
    "            plt.imshow(obs_scheme.mask.T, interpolation='None', aspect='auto')\n",
    "            plt.grid('off')\n",
    "            plt.show()\n",
    "\n",
    "        print('computing time-lagged covariances')    \n",
    "        obs_scheme.use_mask = False\n",
    "        W_ = obs_scheme.comp_coocurrence_weights(lag_range, sso=True, idx_a=idx_a, idx_b=idx_b)\n",
    "        Qs, Om = f_l2_Hankel_comp_Q_Om(n=n,y=y,lag_range=lag_range,obs_scheme=obs_scheme,\n",
    "                              idx_a=idx_a,idx_b=idx_b,W=W_,sso=True,\n",
    "                              mmap=mmap,data_path=data_path,ts=None,ms=None)\n",
    "\n",
    "        obs_scheme.use_mask = True\n",
    "        W = [ 1 / (frac_obs**2 * T * np.ones((1,1))) for m in range(len(lag_range))]\n",
    "        #Om = [np.ones((p,p), dtype=bool) for m in lag_range]\n",
    "        #Qs = [np.zeros((p,p)) for m in lag_range]\n",
    "        \n",
    "        \n",
    "        pars_true['X'] = np.vstack([ np.linalg.matrix_power(pars_true['A'],m).dot(pars_true['Pi']) for m in lag_range])\n",
    "        print('true param. loss: ', f_l2_Hankel_nl(C=pars_true['C'],X=pars_true['X'],R=pars_true['R'],\n",
    "                                       Qs=Qs,Om=Om,lag_range=lag_range,ms=range(len(lag_range)),idx_a=idx_a,idx_b=idx_b))        \n",
    "        print_slim(Qs,Om,lag_range,pars_true,idx_a,idx_b,_,False,data_path)\n",
    "\n",
    "        rnd_seed = np.random.get_state()\n",
    "        #np.random.seed(rnd_seed)\n",
    "        pars_est, traces, ts= run_default(\n",
    "                    alphas    = (0.01, 0.001), \n",
    "                    b1s       = (0.98, 0.95), \n",
    "                    a_decays  = (0.98, 0.98), \n",
    "                    batch_sizes = (1, 10), \n",
    "                    max_zip_sizes =  (1000,250), \n",
    "                    max_iters = (250, 100),\n",
    "                    parametrizations = ('nl', 'ln'),\n",
    "                    pars_est='default', pars_true=pars_true, n=n, \n",
    "                    y=y, sso=sso, obs_scheme=obs_scheme, lag_range=lag_range, \n",
    "                    idx_a=idx_a, idx_b=idx_b,Qs=Qs,Om=Om, W=W,\n",
    "                    traces=[[], [], []], ts = [])    \n",
    "        \n",
    "        # settings for GROUSE\n",
    "        a_grouse = 1.\n",
    "        tracker = Grouse(p, n, a_grouse )\n",
    "        max_epoch_size = 1000\n",
    "        max_iter_grouse = 1000\n",
    "        get_obs = obs_scheme.gen_get_observed()\n",
    "\n",
    "        # fit GROUSE\n",
    "        print('\\n - GROUSE')\n",
    "        tracker.step = a_grouse\n",
    "        ct = 1.\n",
    "        error = np.zeros((max_iter_grouse, n+1))\n",
    "        t = time.time()\n",
    "\n",
    "        for i in range(max_iter_grouse):\n",
    "            if verbose and np.mod(i,max_iter_grouse//10) == 0:\n",
    "                print('finished % ' + str((100*i)//max_iter_grouse))\n",
    "            idx = np.random.permutation(T-np.max(lag_range)-1)\n",
    "            idx = idx[:max_epoch_size] if len(idx) > max_epoch_size else idx\n",
    "            for j in range(len(idx)):\n",
    "                tracker.consume(y[idx[j],:].reshape(-1,1), obs_scheme.mask[idx[j],:].reshape(-1,1))\n",
    "                ct += 1     \n",
    "                tracker.step = a_grouse / ct\n",
    "\n",
    "            error[i] = np.hstack((calc_subspace_proj_error(pars_true['C'], tracker.U), principal_angle(pars_true['C'], tracker.U)))\n",
    "\n",
    "        t = time.time() - t\n",
    "\n",
    "        pars_est_g = {'C' : tracker.U.copy()}\n",
    "        traces_g = [error.copy()]\n",
    "        ts_g = [t]\n",
    "        \n",
    "        # extracting dynamics for GROUSE\n",
    "        print('filtering data') \n",
    "        obs_scheme.gen_mask_from_scheme()\n",
    "        tracker = Grouse(p, n, 0. )\n",
    "        tracker.U = pars_est_g['C'].copy()\n",
    "        x_g = np.zeros((T,n))\n",
    "        for t in range (T):\n",
    "            x_g[t,:] = tracker._project(y[t,:].reshape(p,1), obs_scheme.mask[t,:].reshape(p,1)).reshape(-1)\n",
    "        \n",
    "        kl_ = np.max(lag_range_g) + 1\n",
    "        print('extracting dynamics parameters') \n",
    "        pars_est_g['X'] = np.vstack([np.cov(x_g[m:-(kl_+1)+m, :].T, x_g[:-(kl_+1), :].T)[:n,n:] for m in lag_range_g])\n",
    "        pars_est_g['A'] = np.linalg.lstsq(pars_est_g['X'][:(len(lag_range_g)-1)*n,:], pars_est_g['X'][n:len(lag_range_g)*n,:])[0]\n",
    "        pars_est_g['Pi'] = (pars_est_g['X'][:n,:] + pars_est_g['X'][:n,:].T)/2 \n",
    "        ev_est = np.linalg.eigvals(pars_est_g['A'])\n",
    "        del x_g\n",
    "\n",
    "        plt.plot(np.real(np.linalg.eigvals( pars_est['A'])), 'go-')\n",
    "        plt.plot(np.real(np.linalg.eigvals(pars_est_g['A'])), 'bo-')\n",
    "        plt.plot(np.real(np.linalg.eigvals(pars_true['A'])), 'k')\n",
    "        plt.show()\n",
    "        plt.plot(np.imag(np.linalg.eigvals( pars_est['A'])), 'go-')\n",
    "        plt.plot(np.imag(np.linalg.eigvals(pars_est_g['A'])), 'bo-')\n",
    "        plt.plot(np.imag(np.linalg.eigvals(pars_true['A'])), 'k')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "\n",
    "        save_dict = {'p' : p,'n' : n,'T' : T,'snr' : snr,'lag_range' : lag_range,\n",
    "                     'obs_scheme' : obs_scheme, 'mmap' : mmap,'y' : save_path if mmap else y,\n",
    "                     'pars_true' : pars_true, 'pars_est' : pars_est, 'pars_est_g' : pars_est_g,\n",
    "                     'idx_a' : idx_a,'idx_b' : idx_b, 'W' : None,'Qs' : None,'Om' : None,\n",
    "                     'traces' : traces, 'traces_g' : traces_g, 'ts':ts, 'ts_g':ts_g,\n",
    "                     'rnd_seed' : rnd_seed\n",
    "                    }\n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run)+'_'+str(int(100*frac_obs))\n",
    "        np.savez(save_path + file_name, save_dict)    \n",
    "\n",
    "        print('final proj. error (est.): ', str(error[-1][0]))\n",
    "\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(error[:,1:])\n",
    "        plt.title('subspace proj. error (GROUSE)')\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.loglog(error[:,1:])\n",
    "        plt.title('subspace proj. error (GROUSE)')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.plot(principal_angle(pars_true['C'], tracker.U), 'ro')\n",
    "        plt.plot(principal_angle(pars_true['C'], pars_est['C']), 'bo')\n",
    "        plt.legend(('GROUSE', 'SSIDID'))\n",
    "        plt.ylabel('principal angles')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os, psutil, time\n",
    "from scipy import linalg as la\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "from ssidid.utility import get_subpop_stats, gen_data\n",
    "from ssidid import ObservationScheme, progprint_xrange\n",
    "from subtracking import Grouse, calc_subspace_proj_error\n",
    "from ssidid.icml_scripts import run_default\n",
    "\n",
    "run = '_e3rnd'\n",
    "\n",
    "# define problem size\n",
    "lag_range = np.arange(10)\n",
    "lag_range_g = np.arange(20)\n",
    "\n",
    "kl_ = np.max(lag_range)+1\n",
    "p, n = 1000, 10\n",
    "T_full = 100030\n",
    "T = 10000 + kl_\n",
    "\n",
    "nr = 0 # number of real eigenvalues\n",
    "snr = (9., 9.)\n",
    "whiten = True\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.90, 0.99, 0.90, 0.99\n",
    "\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "\n",
    "\n",
    "# I/O matter\n",
    "mmap, chunksize = True, np.min((p,1000))\n",
    "verbose=True\n",
    "\n",
    "\n",
    "sso = True\n",
    "\n",
    "obs_scheme = ObservationScheme(p=p, T=T, \n",
    "                                sub_pops=(np.arange(p),), \n",
    "                                obs_pops=(0,), \n",
    "                                obs_time=(T,))\n",
    "idx_a, idx_b = np.arange(p), np.arange(p)\n",
    "\n",
    "\n",
    "rnd_seeds = range(19,20)\n",
    "fracs_obs = (0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0)\n",
    "\n",
    "for rnd_seed in rnd_seeds:\n",
    "    \n",
    "    #data_path = '/media/marcel/636f7b46-1fd1-4600-b69e-86d2ed82002c/stitching/hankel/icml_e3/rnd/seed_' + str(rnd_seed) + '/'\n",
    "    data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e1/seed_' + str(int(rnd_seed)) + '/'\n",
    "    save_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e3/rnd/seed_' + str(int(rnd_seed)) + '/'\n",
    "\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('seed:', str(rnd_seed))\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    np.random.seed(rnd_seed)\n",
    "    pars_true, x, y, _, _ = gen_data(p,n,lag_range,T, nr,\n",
    "                                     eig_m_r, eig_M_r, \n",
    "                                     eig_m_c, eig_M_c,\n",
    "                                     mmap, chunksize,\n",
    "                                     data_path,\n",
    "                                     snr=snr, whiten=whiten)        \n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='r+', shape=(T,p))\n",
    "    y -= y.mean(axis=0)\n",
    "    #y[np.invert(obs_scheme.mask)] = np.nan\n",
    "    del y\n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "    idx_a, idx_b = np.arange(p), np.arange(p)\n",
    "    \"\"\"\n",
    "    \n",
    "    file_name = 'p' + str(p) + 'n' + str(n) + 'T' + str(T_full) + 'snr' + str(np.int(np.mean(snr)//1)) + 'e1_init'\n",
    "    load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "    pars_true = load_file['pars_true']    \n",
    "    \n",
    "    y_full = np.memmap(data_path+'y_full', dtype=np.float, mode='r', shape=(T_full,p))\n",
    "    y = np.memmap(save_path+'y', dtype=np.float, mode='w+', shape=(T,p))\n",
    "    y[:] = y_full[:T, :].copy()\n",
    "    del y_full\n",
    "    del y\n",
    "    chunksize = np.minimum(p, 100)\n",
    "    if mmap: \n",
    "        print('ensuring zero-mean data for given observation scheme')\n",
    "        for i in progprint_xrange(p//chunksize, perline=10):\n",
    "            y = np.memmap(save_path+'y', dtype=np.float, mode='r+', shape=(T,p))\n",
    "            y[:, i*chunksize:(i+1)*chunksize] = y[:, i*chunksize:(i+1)*chunksize] - y[:, i*chunksize:(i+1)*chunksize].mean(axis=0)\n",
    "            del y\n",
    "        if (p//chunksize)*chunksize < p:\n",
    "            y = np.memmap(save_path+'y', dtype=np.float, mode='r+', shape=(T,p))\n",
    "            y[:, (p//chunksize)*chunksize:] = y[:, (p//chunksize)*chunksize:] - y[:, (p//chunksize)*chunksize:].mean(axis=0)\n",
    "            del y        \n",
    "        y = np.memmap(save_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "    else:\n",
    "        y -= y.mean(axis=0)\n",
    "    \n",
    "    for frac_obs in fracs_obs:\n",
    "        \n",
    "        print('\\n')\n",
    "        print('fraction observed:', str(frac_obs))\n",
    "        print('\\n')\n",
    "        \n",
    "        n_obs = np.ceil(p * frac_obs)\n",
    "        mask = np.zeros((T,p),dtype=bool)\n",
    "        for t in range(T):\n",
    "            mask[t, np.random.choice(p, n_obs, replace=False)] = 1\n",
    "        obs_scheme.mask = mask\n",
    "\n",
    "        print('(p,n,k+l,T) = ', (p,n,len(lag_range),T), '\\n')\n",
    "\n",
    "        if p*T < 1e8:\n",
    "            plt.figure(figsize=(20,10))\n",
    "            plt.imshow(obs_scheme.mask.T, interpolation='None', aspect='auto')\n",
    "            plt.grid('off')\n",
    "            plt.show()\n",
    "\n",
    "        print('computing time-lagged covariances')    \n",
    "        obs_scheme.use_mask = False\n",
    "        W_ = obs_scheme.comp_coocurrence_weights(lag_range, sso=True, idx_a=idx_a, idx_b=idx_b)\n",
    "        Qs, Om = f_l2_Hankel_comp_Q_Om(n=n,y=y,lag_range=lag_range,obs_scheme=obs_scheme,\n",
    "                              idx_a=idx_a,idx_b=idx_b,W=W_,sso=True,\n",
    "                              mmap=mmap,data_path=data_path,ts=None,ms=None)\n",
    "\n",
    "        obs_scheme.use_mask = True\n",
    "        W = [ 1 / (frac_obs**2 * T * np.ones((1,1))) for m in range(len(lag_range))]\n",
    "        #Om = [np.ones((p,p), dtype=bool) for m in lag_range]\n",
    "        #Qs = [np.zeros((p,p)) for m in lag_range]\n",
    "        \n",
    "        \n",
    "        pars_true['X'] = np.vstack([ np.linalg.matrix_power(pars_true['A'],m).dot(pars_true['Pi']) for m in lag_range])\n",
    "        print('true param. loss: ', f_l2_Hankel_nl(C=pars_true['C'],X=pars_true['X'],R=pars_true['R'],\n",
    "                                       Qs=Qs,Om=Om,lag_range=lag_range,ms=range(len(lag_range)),idx_a=idx_a,idx_b=idx_b))        \n",
    "        print_slim(Qs,Om,lag_range,pars_true,idx_a,idx_b,_,False,data_path)\n",
    "\n",
    "        rnd_seed = np.random.get_state()\n",
    "        #np.random.seed(rnd_seed)\n",
    "        pars_est, traces, ts= run_default(\n",
    "                    alphas    = (0.01, 0.001), \n",
    "                    b1s       = (0.98, 0.95), \n",
    "                    a_decays  = (0.98, 0.98), \n",
    "                    batch_sizes = (1, 10), \n",
    "                    max_zip_sizes =  (1000,250), \n",
    "                    max_iters = (250, 100),\n",
    "                    parametrizations = ('nl', 'ln'),\n",
    "                    pars_est='default', pars_true=pars_true, n=n, \n",
    "                    y=y, sso=sso, obs_scheme=obs_scheme, lag_range=lag_range, \n",
    "                    idx_a=idx_a, idx_b=idx_b,Qs=Qs,Om=Om, W=W,\n",
    "                    traces=[[], [], []], ts = [])    \n",
    "        \n",
    "        # settings for GROUSE\n",
    "        a_grouse = 1.\n",
    "        tracker = Grouse(p, n, a_grouse )\n",
    "        max_epoch_size = 1000\n",
    "        max_iter_grouse = 1000\n",
    "        get_obs = obs_scheme.gen_get_observed()\n",
    "\n",
    "        # fit GROUSE\n",
    "        print('\\n - GROUSE')\n",
    "        tracker.step = a_grouse\n",
    "        ct = 1.\n",
    "        error = np.zeros((max_iter_grouse, n+1))\n",
    "        t = time.time()\n",
    "\n",
    "        for i in range(max_iter_grouse):\n",
    "            if verbose and np.mod(i,max_iter_grouse//10) == 0:\n",
    "                print('finished % ' + str((100*i)//max_iter_grouse))\n",
    "            idx = np.random.permutation(T-np.max(lag_range)-1)\n",
    "            idx = idx[:max_epoch_size] if len(idx) > max_epoch_size else idx\n",
    "            for j in range(len(idx)):\n",
    "                tracker.consume(y[idx[j],:].reshape(-1,1), obs_scheme.mask[idx[j],:].reshape(-1,1))\n",
    "                ct += 1     \n",
    "                tracker.step = a_grouse / ct\n",
    "\n",
    "            error[i] = np.hstack((calc_subspace_proj_error(pars_true['C'], tracker.U), principal_angle(pars_true['C'], tracker.U)))\n",
    "\n",
    "        t = time.time() - t\n",
    "\n",
    "        pars_est_g = {'C' : tracker.U.copy()}\n",
    "        traces_g = [error.copy()]\n",
    "        ts_g = [t]\n",
    "        \n",
    "        # extracting dynamics for GROUSE\n",
    "        print('filtering data') \n",
    "        obs_scheme.gen_mask_from_scheme()\n",
    "        tracker = Grouse(p, n, 0. )\n",
    "        tracker.U = pars_est_g['C'].copy()\n",
    "        x_g = np.zeros((T,n))\n",
    "        for t in range (T):\n",
    "            x_g[t,:] = tracker._project(y[t,:].reshape(p,1), obs_scheme.mask[t,:].reshape(p,1)).reshape(-1)\n",
    "        \n",
    "        kl_ = np.max(lag_range_g) + 1\n",
    "        print('extracting dynamics parameters') \n",
    "        pars_est_g['X'] = np.vstack([np.cov(x_g[m:-(kl_+1)+m, :].T, x_g[:-(kl_+1), :].T)[:n,n:] for m in lag_range_g])\n",
    "        pars_est_g['A'] = np.linalg.lstsq(pars_est_g['X'][:(len(lag_range_g)-1)*n,:], pars_est_g['X'][n:len(lag_range_g)*n,:])[0]\n",
    "        pars_est_g['Pi'] = (pars_est_g['X'][:n,:] + pars_est_g['X'][:n,:].T)/2 \n",
    "        ev_est = np.linalg.eigvals(pars_est_g['A'])\n",
    "        del x_g\n",
    "\n",
    "        plt.plot(np.real(np.linalg.eigvals( pars_est['A'])), 'go-')\n",
    "        plt.plot(np.real(np.linalg.eigvals(pars_est_g['A'])), 'bo-')\n",
    "        plt.plot(np.real(np.linalg.eigvals(pars_true['A'])), 'k')\n",
    "        plt.show()\n",
    "        plt.plot(np.imag(np.linalg.eigvals( pars_est['A'])), 'go-')\n",
    "        plt.plot(np.imag(np.linalg.eigvals(pars_est_g['A'])), 'bo-')\n",
    "        plt.plot(np.imag(np.linalg.eigvals(pars_true['A'])), 'k')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "\n",
    "        save_dict = {'p' : p,'n' : n,'T' : T,'snr' : snr,'lag_range' : lag_range,\n",
    "                     'obs_scheme' : obs_scheme, 'mmap' : mmap,'y' : save_path if mmap else y,\n",
    "                     'pars_true' : pars_true, 'pars_est' : pars_est, 'pars_est_g' : pars_est_g,\n",
    "                     'idx_a' : idx_a,'idx_b' : idx_b, 'W' : None,'Qs' : None,'Om' : None,\n",
    "                     'traces' : traces, 'traces_g' : traces_g, 'ts':ts, 'ts_g':ts_g,\n",
    "                     'rnd_seed' : rnd_seed\n",
    "                    }\n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run)+'_'+str(int(100*frac_obs))\n",
    "        np.savez(save_path + file_name, save_dict)    \n",
    "\n",
    "        print('final proj. error (est.): ', str(error[-1][0]))\n",
    "\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(error[:,1:])\n",
    "        plt.title('subspace proj. error (GROUSE)')\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.loglog(error[:,1:])\n",
    "        plt.title('subspace proj. error (GROUSE)')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.plot(principal_angle(pars_true['C'], tracker.U), 'ro')\n",
    "        plt.plot(principal_angle(pars_true['C'], pars_est['C']), 'bo')\n",
    "        plt.legend(('GROUSE', 'SSIDID'))\n",
    "        plt.ylabel('principal angles')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os, psutil, time\n",
    "from scipy import linalg as la\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "from ssidid.utility import get_subpop_stats, gen_data\n",
    "from ssidid import ObservationScheme, progprint_xrange\n",
    "from subtracking import Grouse, calc_subspace_proj_error\n",
    "from ssidid.icml_scripts import run_default\n",
    "\n",
    "run = '_e3rnd'\n",
    "\n",
    "# define problem size\n",
    "lag_range = np.arange(10)\n",
    "lag_range_g = np.arange(20)\n",
    "\n",
    "kl_ = np.max(lag_range)+1\n",
    "p, n = 1000, 10\n",
    "T_full = 100030\n",
    "T = 10000 + kl_\n",
    "\n",
    "nr = 0 # number of real eigenvalues\n",
    "snr = (9., 9.)\n",
    "whiten = True\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.90, 0.99, 0.90, 0.99\n",
    "\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "\n",
    "\n",
    "# I/O matter\n",
    "mmap, chunksize = True, np.min((p,1000))\n",
    "verbose=True\n",
    "\n",
    "\n",
    "sso = True\n",
    "\n",
    "obs_scheme = ObservationScheme(p=p, T=T, \n",
    "                                sub_pops=(np.arange(p),), \n",
    "                                obs_pops=(0,), \n",
    "                                obs_time=(T,))\n",
    "idx_a, idx_b = np.arange(p), np.arange(p)\n",
    "\n",
    "\n",
    "rnd_seeds = range(10,20)\n",
    "fracs_obs = (0.1, )\n",
    "\n",
    "for rnd_seed in rnd_seeds:\n",
    "    \n",
    "    #data_path = '/media/marcel/636f7b46-1fd1-4600-b69e-86d2ed82002c/stitching/hankel/icml_e3/rnd/seed_' + str(rnd_seed) + '/'\n",
    "    data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e1/seed_' + str(int(rnd_seed)) + '/'\n",
    "    save_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e3/rnd/seed_' + str(int(rnd_seed)) + '/'\n",
    "\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('seed:', str(rnd_seed))\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    np.random.seed(rnd_seed)\n",
    "    pars_true, x, y, _, _ = gen_data(p,n,lag_range,T, nr,\n",
    "                                     eig_m_r, eig_M_r, \n",
    "                                     eig_m_c, eig_M_c,\n",
    "                                     mmap, chunksize,\n",
    "                                     data_path,\n",
    "                                     snr=snr, whiten=whiten)        \n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='r+', shape=(T,p))\n",
    "    y -= y.mean(axis=0)\n",
    "    #y[np.invert(obs_scheme.mask)] = np.nan\n",
    "    del y\n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "    idx_a, idx_b = np.arange(p), np.arange(p)\n",
    "    \"\"\"\n",
    "    \n",
    "    file_name = 'p' + str(p) + 'n' + str(n) + 'T' + str(T_full) + 'snr' + str(np.int(np.mean(snr)//1)) + 'e1_init'\n",
    "    load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "    pars_true = load_file['pars_true']    \n",
    "    \n",
    "    y_full = np.memmap(data_path+'y_full', dtype=np.float, mode='r', shape=(T_full,p))\n",
    "    y = np.memmap(save_path+'y', dtype=np.float, mode='w+', shape=(T,p))\n",
    "    y[:] = y_full[:T, :].copy()\n",
    "    del y_full\n",
    "    del y\n",
    "    chunksize = np.minimum(p, 100)\n",
    "    if mmap: \n",
    "        print('ensuring zero-mean data for given observation scheme')\n",
    "        for i in progprint_xrange(p//chunksize, perline=10):\n",
    "            y = np.memmap(save_path+'y', dtype=np.float, mode='r+', shape=(T,p))\n",
    "            y[:, i*chunksize:(i+1)*chunksize] = y[:, i*chunksize:(i+1)*chunksize] - y[:, i*chunksize:(i+1)*chunksize].mean(axis=0)\n",
    "            del y\n",
    "        if (p//chunksize)*chunksize < p:\n",
    "            y = np.memmap(save_path+'y', dtype=np.float, mode='r+', shape=(T,p))\n",
    "            y[:, (p//chunksize)*chunksize:] = y[:, (p//chunksize)*chunksize:] - y[:, (p//chunksize)*chunksize:].mean(axis=0)\n",
    "            del y        \n",
    "        y = np.memmap(save_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "    else:\n",
    "        y -= y.mean(axis=0)\n",
    "    \n",
    "    for frac_obs in fracs_obs:\n",
    "        \n",
    "        print('\\n')\n",
    "        print('fraction observed:', str(frac_obs))\n",
    "        print('\\n')\n",
    "        \n",
    "        n_obs = np.ceil(p * frac_obs)\n",
    "        mask = np.zeros((T,p),dtype=bool)\n",
    "        for t in range(T):\n",
    "            mask[t, np.random.choice(p, n_obs, replace=False)] = 1\n",
    "        obs_scheme.mask = mask\n",
    "\n",
    "        print('(p,n,k+l,T) = ', (p,n,len(lag_range),T), '\\n')\n",
    "\n",
    "        if p*T < 1e8:\n",
    "            plt.figure(figsize=(20,10))\n",
    "            plt.imshow(obs_scheme.mask.T, interpolation='None', aspect='auto')\n",
    "            plt.grid('off')\n",
    "            plt.show()\n",
    "\n",
    "        print('computing time-lagged covariances')    \n",
    "        obs_scheme.use_mask = False\n",
    "        W_ = obs_scheme.comp_coocurrence_weights(lag_range, sso=True, idx_a=idx_a, idx_b=idx_b)\n",
    "        Qs, Om = f_l2_Hankel_comp_Q_Om(n=n,y=y,lag_range=lag_range,obs_scheme=obs_scheme,\n",
    "                              idx_a=idx_a,idx_b=idx_b,W=W_,sso=True,\n",
    "                              mmap=mmap,data_path=data_path,ts=None,ms=None)\n",
    "\n",
    "        obs_scheme.use_mask = True\n",
    "        W = [ 1 / (frac_obs**2 * T * np.ones((1,1))) for m in range(len(lag_range))]\n",
    "        #Om = [np.ones((p,p), dtype=bool) for m in lag_range]\n",
    "        #Qs = [np.zeros((p,p)) for m in lag_range]\n",
    "        \n",
    "        \n",
    "        pars_true['X'] = np.vstack([ np.linalg.matrix_power(pars_true['A'],m).dot(pars_true['Pi']) for m in lag_range])\n",
    "        print('true param. loss: ', f_l2_Hankel_nl(C=pars_true['C'],X=pars_true['X'],R=pars_true['R'],\n",
    "                                       Qs=Qs,Om=Om,lag_range=lag_range,ms=range(len(lag_range)),idx_a=idx_a,idx_b=idx_b))        \n",
    "        print_slim(Qs,Om,lag_range,pars_true,idx_a,idx_b,_,False,data_path)\n",
    "\n",
    "        rnd_seed = np.random.get_state()\n",
    "        #np.random.seed(rnd_seed)\n",
    "        pars_est, traces, ts= run_default(\n",
    "                    alphas    = (0.01, 0.001), \n",
    "                    b1s       = (0.98, 0.95), \n",
    "                    a_decays  = (0.98, 0.98), \n",
    "                    batch_sizes = (1, 10), \n",
    "                    max_zip_sizes =  (1000,500), \n",
    "                    max_iters = (200, 200),\n",
    "                    parametrizations = ('nl', 'ln'),\n",
    "                    pars_est='default', pars_true=pars_true, n=n, \n",
    "                    y=y, sso=sso, obs_scheme=obs_scheme, lag_range=lag_range, \n",
    "                    idx_a=idx_a, idx_b=idx_b,Qs=Qs,Om=Om, W=W,\n",
    "                    traces=[[], [], []], ts = [])    \n",
    "        \n",
    "        # settings for GROUSE\n",
    "        a_grouse = 10.\n",
    "        tracker = Grouse(p, n, a_grouse )\n",
    "        max_epoch_size = 1000\n",
    "        max_iter_grouse = 1000\n",
    "        get_obs = obs_scheme.gen_get_observed()\n",
    "\n",
    "        # fit GROUSE\n",
    "        print('\\n - GROUSE')\n",
    "        tracker.step = a_grouse\n",
    "        ct = 1.\n",
    "        error = np.zeros((max_iter_grouse, n+1))\n",
    "        t = time.time()\n",
    "\n",
    "        for i in range(max_iter_grouse):\n",
    "            if verbose and np.mod(i,max_iter_grouse//10) == 0:\n",
    "                print('finished % ' + str((100*i)//max_iter_grouse))\n",
    "            idx = np.random.permutation(T-np.max(lag_range)-1)\n",
    "            idx = idx[:max_epoch_size] if len(idx) > max_epoch_size else idx\n",
    "            for j in range(len(idx)):\n",
    "                tracker.consume(y[idx[j],:].reshape(-1,1), obs_scheme.mask[idx[j],:].reshape(-1,1))\n",
    "                ct += 1     \n",
    "                tracker.step = a_grouse / ct\n",
    "\n",
    "            error[i] = np.hstack((calc_subspace_proj_error(pars_true['C'], tracker.U), principal_angle(pars_true['C'], tracker.U)))\n",
    "\n",
    "        t = time.time() - t\n",
    "\n",
    "        pars_est_g = {'C' : tracker.U.copy()}\n",
    "        traces_g = [error.copy()]\n",
    "        ts_g = [t]\n",
    "        \n",
    "        # extracting dynamics for GROUSE\n",
    "        print('filtering data') \n",
    "        obs_scheme.gen_mask_from_scheme()\n",
    "        tracker = Grouse(p, n, 0. )\n",
    "        tracker.U = pars_est_g['C'].copy()\n",
    "        x_g = np.zeros((T,n))\n",
    "        for t in range (T):\n",
    "            x_g[t,:] = tracker._project(y[t,:].reshape(p,1), obs_scheme.mask[t,:].reshape(p,1)).reshape(-1)\n",
    "        \n",
    "        kl_ = np.max(lag_range_g) + 1\n",
    "        print('extracting dynamics parameters') \n",
    "        pars_est_g['X'] = np.vstack([np.cov(x_g[m:-(kl_+1)+m, :].T, x_g[:-(kl_+1), :].T)[:n,n:] for m in lag_range_g])\n",
    "        pars_est_g['A'] = np.linalg.lstsq(pars_est_g['X'][:(len(lag_range_g)-1)*n,:], pars_est_g['X'][n:len(lag_range_g)*n,:])[0]\n",
    "        pars_est_g['Pi'] = (pars_est_g['X'][:n,:] + pars_est_g['X'][:n,:].T)/2 \n",
    "        ev_est = np.linalg.eigvals(pars_est_g['A'])\n",
    "        del x_g\n",
    "\n",
    "        plt.plot(np.real(np.linalg.eigvals( pars_est['A'])), 'go-')\n",
    "        plt.plot(np.real(np.linalg.eigvals(pars_est_g['A'])), 'bo-')\n",
    "        plt.plot(np.real(np.linalg.eigvals(pars_true['A'])), 'k')\n",
    "        plt.show()\n",
    "        plt.plot(np.imag(np.linalg.eigvals( pars_est['A'])), 'go-')\n",
    "        plt.plot(np.imag(np.linalg.eigvals(pars_est_g['A'])), 'bo-')\n",
    "        plt.plot(np.imag(np.linalg.eigvals(pars_true['A'])), 'k')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "\n",
    "        save_dict = {'p' : p,'n' : n,'T' : T,'snr' : snr,'lag_range' : lag_range,\n",
    "                     'obs_scheme' : obs_scheme, 'mmap' : mmap,'y' : save_path if mmap else y,\n",
    "                     'pars_true' : pars_true, 'pars_est' : pars_est, 'pars_est_g' : pars_est_g,\n",
    "                     'idx_a' : idx_a,'idx_b' : idx_b, 'W' : None,'Qs' : None,'Om' : None,\n",
    "                     'traces' : traces, 'traces_g' : traces_g, 'ts':ts, 'ts_g':ts_g,\n",
    "                     'rnd_seed' : rnd_seed\n",
    "                    }\n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run)+'_'+str(int(100*frac_obs))\n",
    "        np.savez(save_path + file_name, save_dict)    \n",
    "\n",
    "        print('final proj. error (est.): ', str(error[-1][0]))\n",
    "\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(error[:,1:])\n",
    "        plt.title('subspace proj. error (GROUSE)')\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.loglog(error[:,1:])\n",
    "        plt.title('subspace proj. error (GROUSE)')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.plot(principal_angle(pars_true['C'], tracker.U), 'ro')\n",
    "        plt.plot(principal_angle(pars_true['C'], pars_est['C']), 'bo')\n",
    "        plt.legend(('GROUSE', 'SSIDID'))\n",
    "        plt.ylabel('principal angles')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add GROUSE fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os, psutil, time\n",
    "from scipy import linalg as la\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "from ssidid.utility import get_subpop_stats, gen_data\n",
    "from ssidid import ObservationScheme, progprint_xrange\n",
    "from subtracking import Grouse, calc_subspace_proj_error\n",
    "from ssidid.icml_scripts import run_default\n",
    "\n",
    "run = '_e3rnd'\n",
    "\n",
    "# define problem size\n",
    "lag_range = np.arange(10)\n",
    "lag_range_g = np.arange(20)\n",
    "\n",
    "kl_ = np.max(lag_range)+1\n",
    "p, n = 1000, 10\n",
    "T_full = 100030\n",
    "T = 10000 + kl_\n",
    "\n",
    "nr = 0 # number of real eigenvalues\n",
    "snr = (9., 9.)\n",
    "whiten = True\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.90, 0.99, 0.90, 0.99\n",
    "\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "\n",
    "\n",
    "# I/O matter\n",
    "mmap, chunksize = True, np.min((p,1000))\n",
    "verbose=True\n",
    "\n",
    "\n",
    "sso = True\n",
    "\n",
    "obs_scheme = ObservationScheme(p=p, T=T, \n",
    "                                sub_pops=(np.arange(p),), \n",
    "                                obs_pops=(0,), \n",
    "                                obs_time=(T,))\n",
    "idx_a, idx_b = np.arange(p), np.arange(p)\n",
    "\n",
    "\n",
    "rnd_seeds = range(10,20)\n",
    "fracs_obs = (0.1, )\n",
    "\n",
    "for rnd_seed in rnd_seeds:\n",
    "    \n",
    "    #data_path = '/media/marcel/636f7b46-1fd1-4600-b69e-86d2ed82002c/stitching/hankel/icml_e3/rnd/seed_' + str(rnd_seed) + '/'\n",
    "    data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e1/seed_' + str(int(rnd_seed)) + '/'\n",
    "    save_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e3/rnd/seed_' + str(int(rnd_seed)) + '/'\n",
    "\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('seed:', str(rnd_seed))\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    np.random.seed(rnd_seed)\n",
    "    pars_true, x, y, _, _ = gen_data(p,n,lag_range,T, nr,\n",
    "                                     eig_m_r, eig_M_r, \n",
    "                                     eig_m_c, eig_M_c,\n",
    "                                     mmap, chunksize,\n",
    "                                     data_path,\n",
    "                                     snr=snr, whiten=whiten)        \n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='r+', shape=(T,p))\n",
    "    y -= y.mean(axis=0)\n",
    "    #y[np.invert(obs_scheme.mask)] = np.nan\n",
    "    del y\n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "    idx_a, idx_b = np.arange(p), np.arange(p)\n",
    "    \"\"\"\n",
    "    \n",
    "    file_name = 'p' + str(p) + 'n' + str(n) + 'T' + str(T_full) + 'snr' + str(np.int(np.mean(snr)//1)) + 'e1_init'\n",
    "    load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "    pars_true = load_file['pars_true']    \n",
    "    \n",
    "    y_full = np.memmap(data_path+'y_full', dtype=np.float, mode='r', shape=(T_full,p))\n",
    "    y = np.memmap(save_path+'y', dtype=np.float, mode='w+', shape=(T,p))\n",
    "    y[:] = y_full[:T, :].copy()\n",
    "    del y_full\n",
    "    del y\n",
    "    chunksize = np.minimum(p, 100)\n",
    "    if mmap: \n",
    "        print('ensuring zero-mean data for given observation scheme')\n",
    "        for i in progprint_xrange(p//chunksize, perline=10):\n",
    "            y = np.memmap(save_path+'y', dtype=np.float, mode='r+', shape=(T,p))\n",
    "            y[:, i*chunksize:(i+1)*chunksize] = y[:, i*chunksize:(i+1)*chunksize] - y[:, i*chunksize:(i+1)*chunksize].mean(axis=0)\n",
    "            del y\n",
    "        if (p//chunksize)*chunksize < p:\n",
    "            y = np.memmap(save_path+'y', dtype=np.float, mode='r+', shape=(T,p))\n",
    "            y[:, (p//chunksize)*chunksize:] = y[:, (p//chunksize)*chunksize:] - y[:, (p//chunksize)*chunksize:].mean(axis=0)\n",
    "            del y        \n",
    "        y = np.memmap(save_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "    else:\n",
    "        y -= y.mean(axis=0)\n",
    "    \n",
    "    for frac_obs in fracs_obs:\n",
    "        \n",
    "        print('\\n')\n",
    "        print('fraction observed:', str(frac_obs))\n",
    "        print('\\n')\n",
    "        \n",
    "        n_obs = np.ceil(p * frac_obs)\n",
    "        mask = np.zeros((T,p),dtype=bool)\n",
    "        for t in range(T):\n",
    "            mask[t, np.random.choice(p, n_obs, replace=False)] = 1\n",
    "        obs_scheme.mask = mask\n",
    "\n",
    "        print('(p,n,k+l,T) = ', (p,n,len(lag_range),T), '\\n')\n",
    "\n",
    "        if p*T < 1e8:\n",
    "            plt.figure(figsize=(20,10))\n",
    "            plt.imshow(obs_scheme.mask.T, interpolation='None', aspect='auto')\n",
    "            plt.grid('off')\n",
    "            plt.show()\n",
    "\n",
    "        print('computing time-lagged covariances')    \n",
    "        obs_scheme.use_mask = False\n",
    "        W_ = obs_scheme.comp_coocurrence_weights(lag_range, sso=True, idx_a=idx_a, idx_b=idx_b)\n",
    "        Qs, Om = f_l2_Hankel_comp_Q_Om(n=n,y=y,lag_range=lag_range,obs_scheme=obs_scheme,\n",
    "                              idx_a=idx_a,idx_b=idx_b,W=W_,sso=True,\n",
    "                              mmap=mmap,data_path=data_path,ts=None,ms=None)\n",
    "\n",
    "        obs_scheme.use_mask = True\n",
    "        W = [ 1 / (frac_obs**2 * T * np.ones((1,1))) for m in range(len(lag_range))]\n",
    "        #Om = [np.ones((p,p), dtype=bool) for m in lag_range]\n",
    "        #Qs = [np.zeros((p,p)) for m in lag_range]\n",
    "        \n",
    "        \n",
    "        pars_true['X'] = np.vstack([ np.linalg.matrix_power(pars_true['A'],m).dot(pars_true['Pi']) for m in lag_range])\n",
    "        print('true param. loss: ', f_l2_Hankel_nl(C=pars_true['C'],X=pars_true['X'],R=pars_true['R'],\n",
    "                                       Qs=Qs,Om=Om,lag_range=lag_range,ms=range(len(lag_range)),idx_a=idx_a,idx_b=idx_b))        \n",
    "        print_slim(Qs,Om,lag_range,pars_true,idx_a,idx_b,_,False,data_path)\n",
    "\n",
    "        rnd_seed = np.random.get_state()\n",
    "        #np.random.seed(rnd_seed)\n",
    "        pars_est, traces, ts= run_default(\n",
    "                    alphas    = (0.01, 0.001), \n",
    "                    b1s       = (0.98, 0.95), \n",
    "                    a_decays  = (0.98, 0.98), \n",
    "                    batch_sizes = (1, 10), \n",
    "                    max_zip_sizes =  (1000,500), \n",
    "                    max_iters = (200, 200),\n",
    "                    parametrizations = ('nl', 'ln'),\n",
    "                    pars_est='default', pars_true=pars_true, n=n, \n",
    "                    y=y, sso=sso, obs_scheme=obs_scheme, lag_range=lag_range, \n",
    "                    idx_a=idx_a, idx_b=idx_b,Qs=Qs,Om=Om, W=W,\n",
    "                    traces=[[], [], []], ts = [])    \n",
    "        \n",
    "        # settings for GROUSE\n",
    "        a_grouse = 1.\n",
    "        tracker = Grouse(p, n, a_grouse )\n",
    "        max_epoch_size = 1000\n",
    "        max_iter_grouse = 2000\n",
    "        get_obs = obs_scheme.gen_get_observed()\n",
    "\n",
    "        # fit GROUSE\n",
    "        print('\\n - GROUSE')\n",
    "        tracker.step = a_grouse\n",
    "        ct = 1.\n",
    "        error = np.zeros((max_iter_grouse, n+1))\n",
    "        t = time.time()\n",
    "\n",
    "        for i in range(max_iter_grouse):\n",
    "            if verbose and np.mod(i,max_iter_grouse//10) == 0:\n",
    "                print('finished % ' + str((100*i)//max_iter_grouse))\n",
    "            idx = np.random.permutation(T-np.max(lag_range)-1)\n",
    "            idx = idx[:max_epoch_size] if len(idx) > max_epoch_size else idx\n",
    "            for j in range(len(idx)):\n",
    "                tracker.consume(y[idx[j],:].reshape(-1,1), obs_scheme.mask[idx[j],:].reshape(-1,1))\n",
    "                ct += 1     \n",
    "                tracker.step = a_grouse / ct\n",
    "\n",
    "            error[i] = np.hstack((calc_subspace_proj_error(pars_true['C'], tracker.U), principal_angle(pars_true['C'], tracker.U)))\n",
    "\n",
    "        t = time.time() - t\n",
    "\n",
    "        pars_est_g = {'C' : tracker.U.copy()}\n",
    "        traces_g = [error.copy()]\n",
    "        ts_g = [t]\n",
    "        \n",
    "        # extracting dynamics for GROUSE\n",
    "        print('filtering data') \n",
    "        obs_scheme.gen_mask_from_scheme()\n",
    "        tracker = Grouse(p, n, 0. )\n",
    "        tracker.U = pars_est_g['C'].copy()\n",
    "        x_g = np.zeros((T,n))\n",
    "        for t in range (T):\n",
    "            x_g[t,:] = tracker._project(y[t,:].reshape(p,1), obs_scheme.mask[t,:].reshape(p,1)).reshape(-1)\n",
    "        \n",
    "        kl_ = np.max(lag_range_g) + 1\n",
    "        print('extracting dynamics parameters') \n",
    "        pars_est_g['X'] = np.vstack([np.cov(x_g[m:-(kl_+1)+m, :].T, x_g[:-(kl_+1), :].T)[:n,n:] for m in lag_range_g])\n",
    "        pars_est_g['A'] = np.linalg.lstsq(pars_est_g['X'][:(len(lag_range_g)-1)*n,:], pars_est_g['X'][n:len(lag_range_g)*n,:])[0]\n",
    "        pars_est_g['Pi'] = (pars_est_g['X'][:n,:] + pars_est_g['X'][:n,:].T)/2 \n",
    "        ev_est = np.linalg.eigvals(pars_est_g['A'])\n",
    "        del x_g\n",
    "\n",
    "        plt.plot(np.real(np.linalg.eigvals( pars_est['A'])), 'go-')\n",
    "        plt.plot(np.real(np.linalg.eigvals(pars_est_g['A'])), 'bo-')\n",
    "        plt.plot(np.real(np.linalg.eigvals(pars_true['A'])), 'k')\n",
    "        plt.show()\n",
    "        plt.plot(np.imag(np.linalg.eigvals( pars_est['A'])), 'go-')\n",
    "        plt.plot(np.imag(np.linalg.eigvals(pars_est_g['A'])), 'bo-')\n",
    "        plt.plot(np.imag(np.linalg.eigvals(pars_true['A'])), 'k')\n",
    "        plt.show()\n",
    "        \n",
    "        save_dict = {'p' : p,'n' : n,'T' : T,'snr' : snr,'lag_range' : lag_range,\n",
    "                     'obs_scheme' : obs_scheme, 'mmap' : mmap,'y' : save_path if mmap else y,\n",
    "                     'pars_true' : pars_true, 'pars_est' : pars_est, 'pars_est_g' : pars_est_g,\n",
    "                     'idx_a' : idx_a,'idx_b' : idx_b, 'W' : None,'Qs' : None,'Om' : None,\n",
    "                     'traces' : traces, 'traces_g' : traces_g, 'ts':ts, 'ts_g':ts_g,\n",
    "                     'rnd_seed' : rnd_seed\n",
    "                    }\n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run)+'_'+str(int(100*frac_obs))\n",
    "        np.savez(save_path + file_name, save_dict)    \n",
    "\n",
    "        print('final proj. error (est.): ', str(error[-1][0]))\n",
    "\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(error[:,1:])\n",
    "        plt.title('subspace proj. error (GROUSE)')\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.loglog(error[:,1:])\n",
    "        plt.title('subspace proj. error (GROUSE)')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.plot(principal_angle(pars_true['C'], tracker.U), 'ro')\n",
    "        plt.plot(principal_angle(pars_true['C'], pars_est['C']), 'bo')\n",
    "        plt.legend(('GROUSE', 'SSIDID'))\n",
    "        plt.ylabel('principal angles')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os, psutil, time\n",
    "from scipy import linalg as la\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "from ssidid.utility import get_subpop_stats, gen_data\n",
    "from ssidid import ObservationScheme\n",
    "from subtracking import Grouse, calc_subspace_proj_error\n",
    "from ssidid.icml_scripts import run_default\n",
    "\n",
    "run = '_e3_slim'\n",
    "# define problem size\n",
    "lag_range = np.arange(30)\n",
    "kl_ = np.max(lag_range)+1\n",
    "p, n = 1000, 10\n",
    "T_full = 100000 + kl_\n",
    "T = T_full\n",
    "\n",
    "nr = 0 # number of real eigenvalues\n",
    "snr = (1., 1.)\n",
    "whiten = True\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.90, 0.99, 0.90, 0.99\n",
    "\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "\n",
    "\n",
    "# I/O matter\n",
    "mmap, chunksize = True, np.min((p,1000))\n",
    "verbose=True\n",
    "\n",
    "rnd_seeds = range(30,40)\n",
    "overlaps = (5000, 50000)\n",
    "\n",
    "\n",
    "for rnd_seed in rnd_seeds:\n",
    "    \n",
    "    data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e3/sso/explore/seed_' + str(rnd_seed) + '/'\n",
    "\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('seed:', str(rnd_seed))\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    \n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "        \n",
    "    idx_a, idx_b = np.arange(p), np.arange(p)\n",
    "\n",
    "    file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T_full)+'_e3_init'\n",
    "    load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()    \n",
    "    pars_true = load_file['pars_true']\n",
    "    sso = True\n",
    "\n",
    "    for overlap in overlaps:\n",
    "\n",
    "        # compute length of recordings to keep total observation count stable    \n",
    "        print('(p,n,k+l,T) = ', (p,n,len(lag_range),T), '\\n')\n",
    "        \n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run)+'_'+str(overlap)\n",
    "        load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()            \n",
    "        pars_est = load_file['pars_est']\n",
    "        traces = load_file['traces']\n",
    "        ts = load_file['ts']\n",
    "        W,Qs,Om =  load_file['W'],load_file['Qs'],load_file['Om']\n",
    "        obs_scheme = load_file['obs_scheme']\n",
    "        obs_scheme.use_mask = False # sso scheme! just to make sure...\n",
    "        \n",
    "        W = obs_scheme.comp_coocurrence_weights(lag_range, sso=sso, idx_a=idx_a, idx_b=idx_b)\n",
    "        if overlap < p:\n",
    "            for m in range(len(lag_range)):\n",
    "                W[m][0,1] = 0\n",
    "                W[m][1,0] = 0\n",
    "\n",
    "        print('computing time-lagged covariances')\n",
    "        Qs, Om = f_l2_Hankel_comp_Q_Om(n=n,y=y,lag_range=lag_range,obs_scheme=obs_scheme,\n",
    "                              idx_a=idx_a,idx_b=idx_b,W=W,sso=sso,\n",
    "                              mmap=mmap,data_path=data_path,ts=None,ms=None)    \n",
    "        \n",
    "        \n",
    "        print_slim(Qs,Om,lag_range,pars_true,idx_a,idx_b,None,False,data_path)\n",
    "        print('true param. loss: ', f_l2_Hankel_nl(C=pars_true['C'],X=pars_true['X'],R=pars_true['R'],\n",
    "                                       Qs=Qs,Om=Om,lag_range=lag_range,ms=range(len(lag_range)),idx_a=idx_a,idx_b=idx_b))        \n",
    "\n",
    "                                                   \n",
    "        print_slim(Qs,Om,lag_range,pars_est,idx_a,idx_b,traces[-1],False,data_path)\n",
    "        print('est. param. loss: ', f_l2_Hankel_nl(C=pars_est['C'],X=pars_est['X'],R=pars_est['R'],\n",
    "                                       Qs=Qs,Om=Om,lag_range=lag_range,ms=range(len(lag_range)),idx_a=idx_a,idx_b=idx_b))        \n",
    "                \n",
    "        sub_pops = obs_scheme.sub_pops\n",
    "        print('\\n')\n",
    "        if len(sub_pops) > 1:\n",
    "            print('overlap: ', str(len(np.intersect1d(sub_pops[0], sub_pops[1]))))            \n",
    "\n",
    "        ts_g = load_file['ts_g']\n",
    "        traces_g = load_file['traces_g']\n",
    "        pars_est_g = load_file['pars_est_g'].copy()\n",
    "        rnd_seed = load_file['rnd_seed']\n",
    "        \n",
    "        \"\"\"        \n",
    "        # settings for GROUSE\n",
    "        a_grouse = 1.\n",
    "        tracker = Grouse(p, n, a_grouse )\n",
    "        max_epoch_size = 1000\n",
    "        max_iter_grouse = 1500\n",
    "        get_obs = obs_scheme.gen_get_observed()\n",
    "\n",
    "        # fit GROUSE\n",
    "        print('\\n - GROUSE')\n",
    "        tracker.step = a_grouse\n",
    "        ct = 1.\n",
    "        error = np.zeros((max_iter_grouse, n+1))\n",
    "        t = time.time()\n",
    "        get_obs = obs_scheme.gen_get_observed()\n",
    "        \n",
    "        for i in range(max_iter_grouse):\n",
    "            if np.mod(i,max_iter_grouse//10) == 0:\n",
    "                print('finished % ' + str((100*i)//max_iter_grouse))\n",
    "            idx = np.random.permutation(T-np.max(lag_range)-1)\n",
    "            idx = idx[:max_epoch_size] if len(idx) > max_epoch_size else idx\n",
    "            for j in range(len(idx)):\n",
    "                obs_idx =  np.zeros((p,1), dtype=bool)\n",
    "                obs_idx[get_obs(idx[j])] = True\n",
    "                tracker.consume(y[idx[j],:].reshape(-1,1), obs_idx)\n",
    "                ct += 1     \n",
    "                tracker.step = a_grouse / ct\n",
    "        \n",
    "            error[i] = np.hstack((calc_subspace_proj_error(pars_true['C'], tracker.U), principal_angle(pars_true['C'], tracker.U)))\n",
    "        t = time.time() - t\n",
    "        pars_est_g = {'C' : tracker.U.copy()}\n",
    "\n",
    "        print('final proj. error (est.): ', str(error[-1][0]))\n",
    "\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(error[:,1:])\n",
    "        plt.title('subspace proj. error (GROUSE)')\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.loglog(error[:,1:])\n",
    "        plt.title('subspace proj. error (GROUSE)')\n",
    "        plt.show()\n",
    "\n",
    "        print('per-subpops principal angles')\n",
    "        C = pars_est_g['C'].copy()\n",
    "        print(principal_angle(pars_true['C'][sub_pops[0],:], C[sub_pops[0],:]))\n",
    "        print(principal_angle(pars_true['C'][sub_pops[1],:], C[sub_pops[1],:]))\n",
    "\n",
    "        print('final principal angles')\n",
    "        C = pars_est_g['C'].copy()\n",
    "        print(principal_angle(pars_true['C'], C))\n",
    "\n",
    "        print('final principal angles (sign-flipped)')\n",
    "        C = pars_est_g['C'].copy()\n",
    "        C[sub_pops[0],:] *= -1\n",
    "        print(principal_angle(pars_true['C'], C))\n",
    "\n",
    "        del C    \n",
    "        traces_g = [error.copy()]\n",
    "        ts_g = [t]         \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        print('filtering data') \n",
    "        obs_scheme.gen_mask_from_scheme()\n",
    "        tracker = Grouse(p, n, 0. )\n",
    "        tracker.U = pars_est_g['C'].copy()\n",
    "        x_g = np.zeros((T,n))\n",
    "        for t in range (T):\n",
    "            x_g[t,:] = tracker._project(y[t,:].reshape(p,1), obs_scheme.mask[t,:].reshape(p,1)).reshape(-1)\n",
    "        obs_scheme.mask = None\n",
    "\n",
    "        print('extracting dynamics parameters') \n",
    "        pars_est_g['X'] = np.vstack([np.cov(x_g[m:-(kl_+1)+m, :].T, x_g[:-(kl_+1), :].T)[:n,n:] for m in lag_range])\n",
    "        pars_est_g['A'] = np.linalg.lstsq(pars_est_g['X'][:(len(lag_range)-1)*n,:], pars_est_g['X'][n:len(lag_range)*n,:])[0]\n",
    "        pars_est_g['Pi'] = (pars_est_g['X'][:n,:] + pars_est_g['X'][:n,:].T)/2 \n",
    "        ev_est = np.linalg.eigvals(pars_est_g['A'])\n",
    "        \n",
    "        \n",
    "        save_dict = {'p' : p,'n' : n,'T' : T,'snr' : snr,'lag_range' : lag_range,\n",
    "                     'obs_scheme' : obs_scheme, 'mmap' : mmap,'y' : data_path if mmap else y,\n",
    "                     'pars_true' : pars_true, 'pars_est' : pars_est, 'pars_est_g' : pars_est_g,\n",
    "                     'idx_a' : idx_a,'idx_b' : idx_b, 'W' : None,'Qs' : None,'Om' : None,\n",
    "                     'traces' : traces, 'traces_g' : traces_g, 'ts':ts, 'ts_g':ts_g,\n",
    "                     'rnd_seed' : rnd_seed\n",
    "                    }\n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run)+'_'+str(overlap)\n",
    "        np.savez(data_path + file_name, save_dict)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get estimates for linear dynamics for GROUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import linalg as la\n",
    "import glob, os, psutil, time\n",
    "\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "from ssidid import ObservationScheme, progprint_xrange\n",
    "from subtracking import Grouse, calc_subspace_proj_error\n",
    "\n",
    "mmap, verbose = True, True\n",
    "\n",
    "p,T,n,snr = 1000, 20020, 10, (1., 1.)\n",
    "rnd_seeds = range(30,40)\n",
    "fracs_obs = (0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0)\n",
    "\n",
    "lag_range = np.arange(20)\n",
    "run = '_e3rnd'\n",
    "\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "\n",
    "for rnd_seed in rnd_seeds:\n",
    "    \n",
    "    data_path = '/media/marcel/636f7b46-1fd1-4600-b69e-86d2ed82002c/stitching/hankel/icml_e3/rnd/seed_' + str(rnd_seed) + '/'\n",
    "\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('seed:', str(rnd_seed))\n",
    "    print('\\n')\n",
    "    print('\\n')    \n",
    "    \n",
    "    #file_name = 'p' + str(p) + 'n' + str(n) + 'T' + str(T_full) +  run\n",
    "    file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run)+'_'+str(int(100*frac_obs))\n",
    "    load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "    pars_true = load_file['pars_true'].copy()\n",
    "    del load_file\n",
    "    kl_ = np.max(lag_range)+1\n",
    "    ev_true = np.linalg.eigvals(pars_true['A'])\n",
    "\n",
    "    for i in range(len(fracs_obs)):\n",
    "\n",
    "        frac_obs = fracs_obs[i]\n",
    "\n",
    "        print('T = ', T)\n",
    "        print('frac_obs =', frac_obs)\n",
    "        y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "\n",
    "\n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run)+'_'+str(int(100*frac_obs))\n",
    "        load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "        obs_scheme, W,Qs,Om = load_file['obs_scheme'], load_file['W'],load_file['Qs'],load_file['Om']\n",
    "        pars_est_g = load_file['pars_est_g']\n",
    "        traces_g = load_file['traces_g']\n",
    "        idx_a, idx_b = load_file['idx_a'].copy(), load_file['idx_b'].copy()\n",
    "\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.imshow(obs_scheme.mask.T, interpolation='None')\n",
    "        plt.show()\n",
    "        \n",
    "        print('filtering data') \n",
    "        tracker = Grouse(p, n, 0. )\n",
    "        tracker.U = pars_est_g['C'].copy()\n",
    "        x_g = np.zeros((T,n))\n",
    "        for t in range (T):\n",
    "            x_g[t,:] = tracker._project(y[t,:].reshape(p,1), obs_scheme.mask[t,:].reshape(p,1)).reshape(-1)\n",
    "\n",
    "        print('extracting dynamics parameters') \n",
    "        pars_est_g['X'] = np.vstack([np.cov(x_g[m:-(kl_+1)+m, :].T, x_g[:-(kl_+1), :].T)[:n,n:] for m in lag_range])\n",
    "        pars_est_g['A'] = np.linalg.lstsq(pars_est_g['X'][:(len(lag_range)-1)*n,:], pars_est_g['X'][n:len(lag_range)*n,:])[0]\n",
    "        pars_est_g['Pi'] = (pars_est_g['X'][:n,:] + pars_est_g['X'][:n,:].T)/2 \n",
    "        ev_est = np.linalg.eigvals(pars_est_g['A'])\n",
    "\n",
    "        print('storing')\n",
    "        save_dict = {'p' : p,'n' : n,'T' : T,'snr' : snr,'lag_range' : lag_range,\n",
    "                     'obs_scheme' : obs_scheme, 'mmap' : mmap,'y' : data_path if mmap else y,\n",
    "                     'pars_true' : load_file['pars_true'], 'pars_est' : load_file['pars_est'], \n",
    "                     'idx_a' : load_file['idx_a'],'idx_b' : load_file['idx_b'], 'W' : W,'Qs' : Qs,'Om' : Om,\n",
    "                     'traces' : load_file['traces'], 'ts': load_file['ts'], \n",
    "                     'rnd_seed' : load_file['rnd_seed'], \n",
    "                     'pars_est_g' : pars_est_g, 'traces_g' :  load_file['traces_g'], 'ts_g': load_file['ts_g']\n",
    "                    }\n",
    "        \n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run)+'_'+str(int(100*frac_obs))\n",
    "        np.savez(data_path + file_name, save_dict)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
