{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ST-Stochastic descent\n",
    "\n",
    "- using SGD on $C$, $\\{X_m\\}_{m=0}^{k+l}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os, psutil, time\n",
    "\n",
    "os.chdir('../core')\n",
    "import ssm_scripts, ssm_fit\n",
    "from utility import get_subpop_stats, gen_data\n",
    "from SSID_Hankel_loss import run_bad, plot_slim, plot_outputs_l2_gradient_test\n",
    "os.chdir('../dev')\n",
    "\n",
    "#np.random.seed(0)\n",
    "\n",
    "# define problem size\n",
    "p, n, k, l, T = 100, 10, 3, 3, 500\n",
    "\n",
    "# settings for fitting algorithm\n",
    "batch_size, max_zip_size, max_iter = 1, 100, 100\n",
    "a, b1, b2, e = 0.1, 0.9, 0.99, 1e-8\n",
    "linearity, stable, sym_psd = 'False', False, False\n",
    "\n",
    "# I/O matter\n",
    "mmap, chunksize = True, np.min((p,2000))\n",
    "data_path, save_file = '../fits/', 'test'\n",
    "verbose=True\n",
    "\n",
    "# create subpopulations\n",
    "sub_pops = (np.arange(0,p), np.arange(0,p))\n",
    "\n",
    "obs_idx, idx_grp, co_obs, _, _, _, Om, _, _ = \\\n",
    "    get_subpop_stats(sub_pops=sub_pops, p=p, verbose=False)\n",
    "\n",
    "# draw system matrices \n",
    "print('(p,n,k+l,T) = ', (p,n,k+l,T), '\\n')\n",
    "nr = 2 # number of real eigenvalues\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.8, 0.99, 0.8, 0.99\n",
    "pars_true, x, y, Qs, idx_a, idx_b = gen_data(p,n,k,l,T, nr,\n",
    "                                             eig_m_r, eig_M_r, \n",
    "                                             eig_m_c, eig_M_c,\n",
    "                                             mmap, chunksize,\n",
    "                                             data_path)\n",
    "\n",
    "pars_init='default'        \n",
    "np.savez(data_path + save_file, \n",
    "         pars_init=pars_init,\n",
    "         pars_true=pars_true, \n",
    "         pars_est=None,\n",
    "         sub_pops=sub_pops,\n",
    "         p=p,n=n,T=T,k=k,l=l,\n",
    "         idx_a=idx_a, idx_b=idx_b,\n",
    "         x=x)          \n",
    "\n",
    "print('\\n')\n",
    "print(psutil.virtual_memory())\n",
    "print(psutil.swap_memory())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test dynamic texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os\n",
    "\n",
    "os.chdir('../core')\n",
    "import SSID_Hankel_loss \n",
    "from utility import get_subpop_stats, draw_sys, gen_data, gen_pars\n",
    "from SSID_Hankel_loss import run_bad, plot_outputs_l2_gradient_test, l2_bad_sis_setup\n",
    "os.chdir('../dev')\n",
    "\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "from scipy.io import loadmat\n",
    "data = loadmat('/home/mackelab/Desktop/Projects/Stitching/data/dynamic_textures/fire.mat')['data']\n",
    "T = data.shape[0]\n",
    "p = data.shape[1] * data.shape[2] // 64\n",
    "#  reshape data\n",
    "y = np.zeros((T, p))\n",
    "for t in range(T):\n",
    "    y[t,:] = np.ravel(np.mean(data[t,:,:,:],axis=2)[np.ix_(np.arange(0,data.shape[1],8),np.arange(0,data.shape[2],8))])\n",
    "\n",
    "\n",
    "# set fitting parameters\n",
    "k,l = 2,2\n",
    "n = 27\n",
    "\n",
    "# settings for fitting algorithm\n",
    "batch_size, max_zip_size, max_iter = 1, 100, 100\n",
    "a, b1, b2, e = 0.1, 0.9, 0.99, 1e-8\n",
    "linearity, stable, sym_psd = 'False', False, False\n",
    "\n",
    "# I/O matter\n",
    "mmap, chunksize = False, np.min((p,2000))\n",
    "data_path, save_file = '../fits/', 'test'\n",
    "verbose=True\n",
    "\n",
    "\n",
    "# create subpopulations\n",
    "sub_pops = (np.arange(0,p), np.arange(0,p))\n",
    "obs_idx, idx_grp, co_obs, _, _, _, Om, _, _ = \\\n",
    "    get_subpop_stats(sub_pops=sub_pops, p=p, verbose=False)\n",
    "\n",
    "# generate (subsampled) covariance matrices\n",
    "pa, pb = np.min((p,1000)), np.min((p,1000))\n",
    "idx_a = np.sort(np.random.choice(p, pa, replace=False))\n",
    "idx_b = np.sort(np.random.choice(p, pb, replace=False))    \n",
    "Qs = []\n",
    "for m in range(k+l):\n",
    "    Qs.append(None)\n",
    "    print('computing time-lagged covariance for lag ', str(m))\n",
    "    if mmap:\n",
    "        Q = np.memmap(data_path+'Qs_'+str(m), dtype=np.float, mode='w+', shape=(pa,pb))\n",
    "    else:\n",
    "        Q = np.empty((pa,pb))\n",
    "    Q[:] = np.cov(y[m:m-(k+l),idx_a].T, y[:-(k+l),idx_b].T)[:pa,pb:]     \n",
    "    if mmap:\n",
    "        del Q\n",
    "        Qs[m] = np.memmap(data_path+'Qs_'+str(m), dtype=np.float, mode='r', shape=(pa,pb))\n",
    "    else:\n",
    "        Qs[m] = Q           \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "t = time.time()\n",
    "pars_init, pars_est, traces = run_bad(k=k,l=l,n=n,y=y, Qs=Qs,Om=Om,idx_a=idx_a, idx_b=idx_b,\n",
    "                                      sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                                      linearity=linearity,stable=stable,init=pars_init,\n",
    "                                      alpha=a,b1=b1,b2=b2,e=e,max_iter=max_iter,batch_size=batch_size,\n",
    "                                      verbose=verbose, sym_psd=sym_psd, max_zip_size=max_zip_size)\n",
    "\n",
    "print('fitting time was ', time.time() - t, 's')\n",
    "print('\\n')\n",
    "print(psutil.virtual_memory())\n",
    "print(psutil.swap_memory())\n",
    "\n",
    "plot_slim(Qs,k,l,pars_est,idx_a,idx_b,traces,mmap,data_path)\n",
    "\n",
    "if p <= 50:\n",
    "    plot_outputs_l2_gradient_test(pars_true=pars_true, pars_init=pars_init, \n",
    "                                  pars_est=pars_est, k=k, l=l, Qs=Qs, \n",
    "                                       Om=Om, traces = traces, idx_a=idx_a, idx_b=idx_b,\n",
    "                                       linearity=linearity, idx_grp = idx_grp, co_obs = co_obs, \n",
    "                                       if_flip = True, m = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data (+intermediate results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.optimize import fmin_bfgs, check_grad\n",
    "import glob, os\n",
    "\n",
    "os.chdir('../core')\n",
    "import SSID_Hankel_loss \n",
    "from utility import get_subpop_stats, draw_sys, gen_data\n",
    "from SSID_Hankel_loss import run_bad, plot_outputs_l2_gradient_test, l2_bad_sis_setup\n",
    "os.chdir('../dev')\n",
    "\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "# load ancient code for drawing from LDS ...\n",
    "os.chdir('../../../../pyRRHDLDS/core')\n",
    "import ssm_scripts\n",
    "import ssm_fit\n",
    "os.chdir('../../code_le_stitch/iterSSID/python/dev')\n",
    "\n",
    "\n",
    "from scipy.io import savemat # store results for comparison with Matlab code   \n",
    "\n",
    "os.chdir('../fits/')\n",
    "\n",
    "mmap = True\n",
    "data_path = '../fits/'\n",
    "\n",
    "save_file = np.load('test.npz')\n",
    "p,n,T,k,l = save_file['p'], save_file['n'], save_file['T'], save_file['k'], save_file['l']\n",
    "pars_true = save_file['pars_true'].tolist()\n",
    "pars_est, pars_init = save_file['pars_est'].tolist(), save_file['pars_init'].tolist()\n",
    "idx_a, idx_b = save_file['idx_a'], save_file['idx_b']\n",
    "pa, pb = len(idx_a), len(idx_b)\n",
    "#pa, pb = p,p\n",
    "\n",
    "Qs = []\n",
    "for m in range(k+l):\n",
    "    print('loading time-lagged covariance for lag ', str(m))\n",
    "    Qs.append(np.memmap('Qs_'+str(m), dtype=np.float, mode='r', shape=(pa,pb)))\n",
    "\n",
    "y = np.memmap('y', dtype=np.float, mode='r', shape=(T,p))\n",
    "\n",
    "\n",
    "sub_pops = (np.arange(p), np.arange(p))\n",
    "obs_idx, idx_grp, co_obs, _, _, _, Om, _, _ = \\\n",
    "    get_subpop_stats(sub_pops=sub_pops, p=p, verbose=False)\n",
    "\n",
    "chunksize = 5000\n",
    "max_zip_size = 5000\n",
    "\n",
    "verbose=True\n",
    "            \n",
    "print('\\n')\n",
    "print(psutil.virtual_memory())\n",
    "print(psutil.swap_memory())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional turns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# just one more turn..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
