{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ST-Stochastic descent\n",
    "\n",
    "- using SGD on $C$, $\\{X_m\\}_{m=0}^{k+l}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os, psutil, time\n",
    "\n",
    "os.chdir('../core')\n",
    "import ssm_scripts, ssm_fit\n",
    "from utility import get_subpop_stats, gen_data\n",
    "from SSID_Hankel_loss import run_bad, plot_slim, print_slim\n",
    "os.chdir('../dev')\n",
    "\n",
    "#np.random.seed(0)\n",
    "\n",
    "# define problem size\n",
    "p, n, k, l, T = 5, 2, 3, 3, int(10e4)\n",
    "lag_range = np.arange(0, 50, 10)\n",
    "\n",
    "# settings for fitting algorithm\n",
    "batch_size, max_zip_size, max_iter = 1, 100, 1000\n",
    "a, b1, b2, e = 0.01, 0.9, 0.99, 1e-8\n",
    "linearity, stable, sym_psd = 'False', False, False\n",
    "\n",
    "# I/O matter\n",
    "mmap, chunksize = True, np.min((p,2000))\n",
    "data_path, save_file = '../fits/', 'test'\n",
    "verbose=True\n",
    "\n",
    "# create subpopulations\n",
    "sub_pops = (np.arange(p),)\n",
    "obs_pops = np.array([0])\n",
    "obs_time = np.array([T])\n",
    "\n",
    "#sub_pops = (np.arange(0,p//2), np.arange(p//4,3*(p//4)), np.arange(p//2, p)) \n",
    "#obs_pops = np.array([0,1,2])\n",
    "#obs_time = np.array([T//3, 2*T//3, T])\n",
    "\n",
    "obs_idx, idx_grp, co_obs, _, _, _, Om, _, _ = \\\n",
    "    get_subpop_stats(sub_pops=sub_pops, p=p, verbose=False)\n",
    "\n",
    "# draw system matrices \n",
    "print('(p,n,k+l,T) = ', (p,n,k+l,T), '\\n')\n",
    "nr = 0 # number of real eigenvalues\n",
    "snr = (.000, .000)\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.99, 0.999, 0.99, 0.999\n",
    "pars_true, x, y, Qs, idx_a, idx_b = gen_data(p,n,lag_range,T, nr,\n",
    "                                             eig_m_r, eig_M_r, \n",
    "                                             eig_m_c, eig_M_c,\n",
    "                                             mmap, chunksize,\n",
    "                                             data_path,snr=snr)\n",
    "\n",
    "pars_init='default'        \n",
    "np.savez(data_path + save_file, \n",
    "         pars_init=pars_init,\n",
    "         pars_true=pars_true, \n",
    "         pars_est=None,\n",
    "         sub_pops=sub_pops,\n",
    "         p=p,n=n,T=T,k=k,l=l,\n",
    "         idx_a=idx_a, idx_b=idx_b,\n",
    "         x=x)          \n",
    "\n",
    "print('\\n')\n",
    "print(psutil.virtual_memory())\n",
    "print(psutil.swap_memory())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(Qs[1] - pars_true['C'].dot(np.cov(x[2:-1,:].T, x[0:-3,:].T)[:n,n:]).dot(pars_true['C'].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = 4\n",
    "m_ = lag_range[m]\n",
    "plt.imshow(Qs[m], interpolation='None')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow(pars_true['C'].dot(np.cov(x[m_:-1,:].T, x[0:-(m_+1),:].T)[:n,n:]).dot(pars_true['C'].T), interpolation='None')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "print(Qs[m] - pars_true['C'].dot(np.cov(x[m_:-1,:].T, x[0:-(m_+1),:].T)[:n,n:]).dot(pars_true['C'].T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# settings for fitting algorithm\n",
    "batch_size, max_zip_size, max_iter = 1, 100, 100\n",
    "a, b1, b2, e = 0.01, 0.9, 0.99, 1e-8\n",
    "a_R = 10 * a\n",
    "linearity, stable, sym_psd = 'False', False, False\n",
    "\n",
    "t = time.time()\n",
    "pars_init, pars_est, traces = run_bad(lag_range=lag_range,n=n,y=y, Qs=Qs,Om=Om,idx_a=idx_a, idx_b=idx_b,\n",
    "                                      sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                                      obs_pops=obs_pops,obs_time=obs_time,\n",
    "                                      linearity=linearity,stable=stable,init=pars_init,\n",
    "                                      alpha=a,alpha_R=a_R,b1=b1,b2=b2,e=e,max_iter=max_iter,batch_size=batch_size,\n",
    "                                      verbose=verbose, sym_psd=sym_psd, max_zip_size=max_zip_size)\n",
    "\n",
    "print('fitting time was ', time.time() - t, 's')\n",
    "print('\\n')\n",
    "print(psutil.virtual_memory())\n",
    "print(psutil.swap_memory())\n",
    "\n",
    "print_slim(Qs,lag_range,pars_est,idx_a,idx_b,traces,mmap,data_path)\n",
    "\n",
    "plot_slim(Qs,lag_range,pars_est,idx_a,idx_b,traces,mmap,data_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# settings for fitting algorithm\n",
    "batch_size, max_zip_size, max_iter = 50, 100, 100\n",
    "a, b1, b2, e = 0.0001, 0.9, 0.99, 1e-8\n",
    "a_R = a\n",
    "linearity, stable, sym_psd = 'False', False, False\n",
    "\n",
    "t = time.time()\n",
    "_, pars_est, traces = run_bad(lag_range=lag_range,n=n,y=y, Qs=Qs,Om=Om,idx_a=idx_a, idx_b=idx_b,\n",
    "                                      sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                                      obs_pops=obs_pops,obs_time=obs_time,\n",
    "                                      linearity=linearity,stable=stable,init=pars_est,\n",
    "                                      alpha=a,alpha_R=a_R,b1=b1,b2=b2,e=e,max_iter=max_iter,batch_size=batch_size,\n",
    "                                      verbose=verbose, sym_psd=sym_psd, max_zip_size=max_zip_size)\n",
    "\n",
    "print('fitting time was ', time.time() - t, 's')\n",
    "print('\\n')\n",
    "print(psutil.virtual_memory())\n",
    "print(psutil.swap_memory())\n",
    "\n",
    "plot_slim(Qs,lag_range,pars_est,idx_a,idx_b,traces,mmap,data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# settings for fitting algorithm\n",
    "batch_size, max_zip_size, max_iter = 50, 100, 100\n",
    "a, b1, b2, e = 0.00005, 0.9, 0.99, 1e-8\n",
    "a_R = a\n",
    "linearity, stable, sym_psd = 'False', False, False\n",
    "\n",
    "t = time.time()\n",
    "_, pars_est, traces = run_bad(lag_range=lag_range,n=n,y=y, Qs=Qs,Om=Om,idx_a=idx_a, idx_b=idx_b,\n",
    "                                      sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                                      obs_pops=obs_pops,obs_time=obs_time,\n",
    "                                      linearity=linearity,stable=stable,init=pars_est,\n",
    "                                      alpha=a,alpha_R=a_R,b1=b1,b2=b2,e=e,max_iter=max_iter,batch_size=batch_size,\n",
    "                                      verbose=verbose, sym_psd=sym_psd, max_zip_size=max_zip_size)\n",
    "\n",
    "print('fitting time was ', time.time() - t, 's')\n",
    "print('\\n')\n",
    "print(psutil.virtual_memory())\n",
    "print(psutil.swap_memory())\n",
    "\n",
    "plot_slim(Qs,lag_range,pars_est,idx_a,idx_b,traces,mmap,data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# settings for fitting algorithm\n",
    "batch_size, max_zip_size, max_iter = 100, 100, 20\n",
    "a, b1, b2, e = 0.0005, 0.9, 0.99, 1e-8\n",
    "a_R = a\n",
    "linearity, stable, sym_psd = 'False', False, False\n",
    "\n",
    "t = time.time()\n",
    "_, pars_est, traces = run_bad(lag_range=lag_range,n=n,y=y, Qs=Qs,Om=Om,idx_a=idx_a, idx_b=idx_b,\n",
    "                                      sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                                      obs_pops=obs_pops,obs_time=obs_time,\n",
    "                                      linearity=linearity,stable=stable,init=pars_est,\n",
    "                                      alpha=a,alpha_R=a_R,b1=b1,b2=b2,e=e,max_iter=max_iter,batch_size=batch_size,\n",
    "                                      verbose=verbose, sym_psd=sym_psd, max_zip_size=max_zip_size)\n",
    "\n",
    "print('fitting time was ', time.time() - t, 's')\n",
    "print('\\n')\n",
    "print(psutil.virtual_memory())\n",
    "print(psutil.swap_memory())\n",
    "\n",
    "plot_slim(Qs,lag_range,pars_est,idx_a,idx_b,traces,mmap,data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(y)\n",
    "explained_variance_ratio_ = np.hstack((pca.explained_variance_ratio_, np.zeros(np.max((p-T,0)))))\n",
    "plt.plot(range(1,p+1), np.cumsum(explained_variance_ratio_)/np.sum(explained_variance_ratio_))\n",
    "plt.hold(True)\n",
    "plt.plot(np.linspace(0,p+1,np.min((20,p))), \n",
    "         np.cumsum(pca.explained_variance_ratio_[:np.min((20,p))])/np.sum(pca.explained_variance_ratio_), \n",
    "         'r--')\n",
    "plt.legend(('cum. var. expl.', 'first 20, x-axis rescaled'))\n",
    "\n",
    "pars_pca = {}\n",
    "pars_pca['C'] = pca.components_[:n].T\n",
    "pars_pca['Pi'] = np.diag(pca.explained_variance_[:n])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pa, pb = idx_a.size, idx_b.size\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for m in range(1):\n",
    "    print('computing time-lagged covariance for lag ', str(m))\n",
    "    \n",
    "    Qf = np.empty((pa,pb))\n",
    "    Qf[:] = np.cov(y[m:m-(k+l),idx_a].T, y[:-(k+l),idx_b].T)[:pa,pa:]    \n",
    "    \n",
    "    Q = np.empty((pa,pb))\n",
    "    Q[:] = (pars_est['C'][idx_a,:].dot(pars_est['X'][:n,:]).dot(pars_est['C'][idx_b,:].T))\n",
    "    plt.plot(Qf[:], Q[:], 'r.')\n",
    "    plt.hold(True)\n",
    "    plt.title('corr. est. us:' + str(np.corrcoef(Qf.reshape(-1), Q.reshape(-1))[0,1]))\n",
    "    \n",
    "    Q = np.empty((pa,pb))\n",
    "    Q[:] = (pars_pca['C'][idx_a,:].dot(pars_pca['Pi']).dot(pars_pca['C'][idx_b,:].T))\n",
    "    plt.plot(Qf[:], Q[:], 'b.')\n",
    "    \n",
    "    plt.xlabel('corr. est. PCA:' + str(np.corrcoef(Qf.reshape(-1), Q.reshape(-1))[0,1]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "savemat('../fits/'+'parameters', {'pars' : pars_true,\n",
    "                                 'pars_est_full':pars_est,\n",
    "                                 'pars_est_partial':{}, \n",
    "                                 'pars_pca':pars_pca})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(pars_est['R'], 'k')\n",
    "plt.hold(True)\n",
    "plt.plot(pars_true['R'], 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.mean(np.abs(pars_est['C']),1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test dynamic texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os\n",
    "\n",
    "os.chdir('../core')\n",
    "import SSID_Hankel_loss \n",
    "from utility import get_subpop_stats, draw_sys, gen_data, gen_pars\n",
    "from SSID_Hankel_loss import run_bad, plot_outputs_l2_gradient_test, l2_bad_sis_setup\n",
    "os.chdir('../dev')\n",
    "\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "from scipy.io import loadmat\n",
    "data = loadmat('/home/mackelab/Desktop/Projects/Stitching/data/dynamic_textures/fire.mat')['data']\n",
    "T = data.shape[0]\n",
    "p = data.shape[1] * data.shape[2] // 64\n",
    "#  reshape data\n",
    "y = np.zeros((T, p))\n",
    "for t in range(T):\n",
    "    y[t,:] = np.ravel(np.mean(data[t,:,:,:],axis=2)[np.ix_(np.arange(0,data.shape[1],8),np.arange(0,data.shape[2],8))])\n",
    "\n",
    "\n",
    "# set fitting parameters\n",
    "k,l = 2,2\n",
    "n = 27\n",
    "\n",
    "# settings for fitting algorithm\n",
    "batch_size, max_zip_size, max_iter = 1, 100, 100\n",
    "a, b1, b2, e = 0.1, 0.9, 0.99, 1e-8\n",
    "linearity, stable, sym_psd = 'False', False, False\n",
    "\n",
    "# I/O matter\n",
    "mmap, chunksize = False, np.min((p,2000))\n",
    "data_path, save_file = '../fits/', 'test'\n",
    "verbose=True\n",
    "\n",
    "\n",
    "# create subpopulations\n",
    "sub_pops = (np.arange(0,p), np.arange(0,p))\n",
    "obs_idx, idx_grp, co_obs, _, _, _, Om, _, _ = \\\n",
    "    get_subpop_stats(sub_pops=sub_pops, p=p, verbose=False)\n",
    "\n",
    "# generate (subsampled) covariance matrices\n",
    "pa, pb = np.min((p,1000)), np.min((p,1000))\n",
    "idx_a = np.sort(np.random.choice(p, pa, replace=False))\n",
    "idx_b = np.sort(np.random.choice(p, pb, replace=False))    \n",
    "Qs = []\n",
    "for m in range(k+l):\n",
    "    Qs.append(None)\n",
    "    print('computing time-lagged covariance for lag ', str(m))\n",
    "    if mmap:\n",
    "        Q = np.memmap(data_path+'Qs_'+str(m), dtype=np.float, mode='w+', shape=(pa,pb))\n",
    "    else:\n",
    "        Q = np.empty((pa,pb))\n",
    "    Q[:] = np.cov(y[m:m-(k+l),idx_a].T, y[:-(k+l),idx_b].T)[:pa,pb:]     \n",
    "    if mmap:\n",
    "        del Q\n",
    "        Qs[m] = np.memmap(data_path+'Qs_'+str(m), dtype=np.float, mode='r', shape=(pa,pb))\n",
    "    else:\n",
    "        Qs[m] = Q           \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data (+intermediate results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.optimize import fmin_bfgs, check_grad\n",
    "import glob, os\n",
    "\n",
    "os.chdir('../core')\n",
    "import SSID_Hankel_loss \n",
    "from utility import get_subpop_stats, draw_sys, gen_data\n",
    "from SSID_Hankel_loss import run_bad, plot_outputs_l2_gradient_test, l2_bad_sis_setup\n",
    "os.chdir('../dev')\n",
    "\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "# load ancient code for drawing from LDS ...\n",
    "os.chdir('../../../../pyRRHDLDS/core')\n",
    "import ssm_scripts\n",
    "import ssm_fit\n",
    "os.chdir('../../code_le_stitch/iterSSID/python/dev')\n",
    "\n",
    "from scipy.io import savemat # store results for comparison with Matlab code   \n",
    "\n",
    "os.chdir('../fits/')\n",
    "\n",
    "mmap = True\n",
    "data_path = '../fits/'\n",
    "\n",
    "save_file = np.load('test.npz')\n",
    "p,n,T,k,l = save_file['p'], save_file['n'], save_file['T'], save_file['k'], save_file['l']\n",
    "pars_true = save_file['pars_true'].tolist()\n",
    "pars_est, pars_init = save_file['pars_est'].tolist(), save_file['pars_init'].tolist()\n",
    "idx_a, idx_b = save_file['idx_a'], save_file['idx_b']\n",
    "pa, pb = len(idx_a), len(idx_b)\n",
    "#pa, pb = p,p\n",
    "\n",
    "Qs = []\n",
    "for m in range(k+l):\n",
    "    print('loading time-lagged covariance for lag ', str(m))\n",
    "    Qs.append(np.memmap('Qs_'+str(m), dtype=np.float, mode='r', shape=(pa,pb)))\n",
    "\n",
    "y = np.memmap('y', dtype=np.float, mode='r', shape=(T,p))\n",
    "\n",
    "\n",
    "sub_pops = (np.arange(p), np.arange(p))\n",
    "obs_idx, idx_grp, co_obs, _, _, _, Om, _, _ = \\\n",
    "    get_subpop_stats(sub_pops=sub_pops, p=p, verbose=False)\n",
    "\n",
    "chunksize = 5000\n",
    "max_zip_size = 5000\n",
    "\n",
    "verbose=True\n",
    "            \n",
    "print('\\n')\n",
    "print(psutil.virtual_memory())\n",
    "print(psutil.swap_memory())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional turns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# just one more turn..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
