{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summarize results on small index set extracted from zebra-fish data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 non-overlapping subpopulations (4 z-planes each, last with 5 z-planes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os, psutil, time\n",
    "\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl\n",
    "from ssidid.utility import get_subpop_stats, gen_data\n",
    "from ssidid import ObservationScheme\n",
    "from subtracking import Grouse, calc_subspace_proj_error\n",
    "\n",
    "\n",
    "run = '_10sp'\n",
    "ns = (10,20)\n",
    "\n",
    "#data_path = '../fits/lsfm/grid_quick/'\n",
    "data_path = '/media/marcel/636f7b46-1fd1-4600-b69e-86d2ed82002c/stitching/hankel/zebrafish/'\n",
    "\n",
    "idx_str = 'small'\n",
    "idx_fish = np.load(data_path + 'idx_' + idx_str + '.npy')\n",
    "\n",
    "T, p = 1200, len(idx_fish)\n",
    "lag_range = np.arange(0,10)\n",
    "kl_ = np.max(lag_range)+1\n",
    "snr = (0., 0.)\n",
    "verbose=True\n",
    "\n",
    "def get_corrs(Qs,Om,lag_range,pars,idx_a,idx_b,traces,mmap):\n",
    "    kl = len(lag_range)\n",
    "    p,n = pars['C'].shape\n",
    "    pa, pb = idx_a.size, idx_b.size\n",
    "    idx_ab = np.intersect1d(idx_a, idx_b)\n",
    "    idx_a_ab = np.where(np.in1d(idx_a, idx_ab))[0]\n",
    "    idx_b_ab = np.where(np.in1d(idx_b, idx_ab))[0]\n",
    "    out = np.zeros(len(lag_range))\n",
    "    for m in range(kl): \n",
    "        m_ = lag_range[m] \n",
    "        Qrec = pars['C'][idx_a,:].dot(pars['X'][m*n:(m+1)*n, :]).dot(pars['C'][idx_b,:].T) \n",
    "        if m_ == 0:\n",
    "            Qrec[np.ix_(idx_a_ab, idx_b_ab)] += np.diag(pars['R'][idx_ab])\n",
    "        if mmap:\n",
    "            Q = np.memmap(data_path+'Qs_'+str(m_), dtype=np.float, mode='r', shape=(pa,pb))\n",
    "        else:\n",
    "            Q = Qs[m]\n",
    "        out[m] = np.corrcoef( Qrec[Om[m]].reshape(-1), (Qs[m][Om[m]]).reshape(-1) )[0,1]\n",
    "        if mmap:\n",
    "            del Q\n",
    "    return out\n",
    "\n",
    "obs_corrs = np.zeros((len(ns), len(lag_range)))\n",
    "stc_corrs = np.zeros((len(ns), len(lag_range)))\n",
    "loss      = np.zeros( len(ns) )\n",
    "for ni in range(len(ns)):\n",
    "    \n",
    "    n = ns[ni]\n",
    "\n",
    "    file_name = 'p' + str(p) + 'n' + str(n) + 'T' + str(T) + str(run)\n",
    "\n",
    "    load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "    mmap = load_file['mmap']\n",
    "    pars_true, pars_est, obs_scheme = load_file['pars_true'], load_file['pars_est'],load_file['obs_scheme']\n",
    "    W = load_file['W']\n",
    "    W = obs_scheme.comp_coocurrence_weights(lag_range, sso=True, idx_a=idx_a, idx_b=idx_b) if W is None else W\n",
    "    if ni == 0:\n",
    "        Qs = load_file['Qs']\n",
    "        Om=  load_file['Om']\n",
    "        idx_a, idx_b = load_file['idx_a'], load_file['idx_b']\n",
    "    y = np.memmap(data_path+'y_small', dtype=np.float, mode='r', shape=(T,p))\n",
    "\n",
    "    print('(T,p,n)', (T,p,n))\n",
    "    \n",
    "\n",
    "    for i in range(0,len(sub_pops),2):\n",
    "        pars_est['C'][sub_pops[i],:] *=-1\n",
    "\n",
    "    for m in range(1,len(lag_range),2):\n",
    "        pars_est['X'][m*n:(m+1)*n,:] *= -1 \n",
    "\n",
    "    #print_slim(Qs,Om,lag_range,pars_est,idx_a,idx_b,_,False,data_path)\n",
    "    obs_corrs[ni,:] = get_corrs(Qs,Om,lag_range,pars_est,idx_a,idx_b,None,False)\n",
    "    loss[ni] = f_l2_Hankel_nl(C=pars_est['C'],\n",
    "                                   X=pars_est['X'],\n",
    "                                   R=pars_est['R'],\n",
    "                                   Qs=Qs,\n",
    "                                   Om=Om,\n",
    "                                   lag_range=lag_range,\n",
    "                                   ms=range(len(lag_range)),\n",
    "                                   idx_a=idx_a,\n",
    "                                   idx_b=idx_b)\n",
    "    \n",
    "\n",
    "    for m in lag_range:   \n",
    "        print('m = ', str(m))\n",
    "        y_ = np.memmap(data_path+'y_' + idx_str + '_zscore', dtype=np.float, mode='r', shape=(T,p))\n",
    "        Qgd = np.cov(y_[np.ix_(np.arange(m, T-kl_+m), idx_a)].T,\n",
    "                     y_[np.ix_(np.arange(0, T-kl_),   idx_a)].T)[:len(idx_a),len(idx_b):]\n",
    "        Qest = pars_est['C'][idx_a,:].dot(pars_est['X'][m*n:(m+1)*n,:]).dot(pars_est['C'][idx_b,:].T)\n",
    "        if lag_range[m] == 0 and np.all(idx_a == idx_b):\n",
    "            Qest += np.diag(pars_est['R'][idx_a])\n",
    "        stc_corrs[ni,m] = np.corrcoef(Qgd[np.invert(Om[m])], Qest[np.invert(Om[m])])[0,1]\n",
    "        del Qest\n",
    "        del Qgd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import seaborn\n",
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "\n",
    "# further subsample for displaying purposes!\n",
    "idx_Q = np.ix_(np.arange(0,len(idx_a),10), np.arange(0,len(idx_b),10))\n",
    "idx_a = idx_a[::10]\n",
    "idx_b = idx_b[::10]\n",
    "\n",
    "clims = [np.min(Qs[0]), np.max(Qs[0])]\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "plt.imshow(Qs[0][idx_Q], interpolation='None')\n",
    "plt.colorbar()\n",
    "plt.grid('off')\n",
    "plt.title('observed inst. covariances')\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "y_ = np.memmap(data_path+'y_' + idx_str + '_zscore', dtype=np.float, mode='r', shape=(T,p))\n",
    "Qgd = np.cov(y_[np.ix_(np.arange(0, T-kl_), idx_a)].T,\n",
    "             y_[np.ix_(np.arange(0, T-kl_), idx_a)].T)[:len(idx_a),len(idx_b):]\n",
    "del y_\n",
    "clims = [np.minimum(clims[0], np.min(Qgd)), np.maximum(clims[1], np.max(Qgd))]\n",
    "plt.imshow(Qgd, interpolation='None')\n",
    "plt.colorbar()\n",
    "del Qgd\n",
    "plt.grid('off')\n",
    "plt.title('full instantaneous covariances')\n",
    "\n",
    "plt.subplot(2,3,3)\n",
    "n, m = 20, 0\n",
    "pars_est =  np.load(data_path + 'p160495n' + str(n) + 'T1200_10sp.npz')['arr_0'].tolist()['pars_est']\n",
    "for i in range(0,len(sub_pops),2):\n",
    "    pars_est['C'][sub_pops[i],:] *=-1\n",
    "for m in range(1,len(lag_range),2):\n",
    "    pars_est['X'][m*n:(m+1)*n,:] *= -1 \n",
    "Qest = pars_est['C'][idx_a,:].dot(pars_est['X'][:n,:]).dot(pars_est['C'][idx_b,:].T)\n",
    "#del pars_est\n",
    "plt.imshow(Qest, interpolation='None')\n",
    "plt.colorbar()\n",
    "clims = [np.minimum(clims[0], np.min(Qest)), np.maximum(clims[1], np.max(Qest))]\n",
    "del Qest\n",
    "plt.grid('off')\n",
    "plt.title('reconstructed inst. covariances')\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "plt.clim(clims[0], clims[1])\n",
    "plt.subplot(2,3,2)\n",
    "plt.clim(clims[0], clims[1])\n",
    "plt.subplot(2,3,3)\n",
    "plt.clim(clims[0], clims[1])\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "plt.plot(ns, loss, 'o-')\n",
    "plt.ylabel('(partial) training loss')\n",
    "plt.xlabel('time lag')\n",
    "plt.box('off')\n",
    "plt.title('training loss vs. latent dim.')\n",
    "plt.xticks(ns)\n",
    "\n",
    "plt.subplot(2,3,5)\n",
    "plt.plot(obs_corrs.T)\n",
    "plt.xlabel('time lag')\n",
    "plt.ylabel('corr. of covariances')\n",
    "plt.legend(['n = ' + str(n) for n in ns], loc=3, frameon=False)\n",
    "plt.box('off')\n",
    "plt.axis([0,np.max(lag_range), 0.8, 1.])\n",
    "plt.title('corr. of observed covariances ')\n",
    "\n",
    "plt.subplot(2,3,6)\n",
    "plt.plot(stc_corrs.T)\n",
    "plt.xlabel('time lag')\n",
    "plt.ylabel('corr. of covariances')\n",
    "#plt.legend(['n = ' + str(n) for n in ns], loc=3, frameon=False)\n",
    "plt.box('off')\n",
    "plt.axis([0,np.max(lag_range), .55, 1.])\n",
    "plt.title('corr. of stitched covariances ')\n",
    "plt.savefig(data_path + 'res_summary_10subpops_zebrafish_small.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obs_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ssidid.SSID_Hankel_loss import f_l2_Hankel_comp_Q_Om\n",
    "from ssidid import ObservationScheme\n",
    "\n",
    "data_path = '/media/marcel/636f7b46-1fd1-4600-b69e-86d2ed82002c/stitching/hankel/zebrafish/'\n",
    "idx_str = 'small'\n",
    "idx_fish = np.load(data_path + 'idx_' + idx_str + '.npy')\n",
    "p = len(idx_fish)\n",
    "\n",
    "\"\"\"\n",
    "nx, ny, nz = 41, 1024, 2048\n",
    "p_full = nx * ny * nz\n",
    "tmp = np.arange(p_full)\n",
    "tmp =tmp.reshape(nx,ny,nz)\n",
    "\n",
    "ns = 10\n",
    "sub_pops = [np.where(np.in1d(idx_fish, np.intersect1d(tmp[i*nx//ns:(i+1)*nx//ns,:,:].reshape(-1), idx_fish)))[0] for i in range(ns-1)]\n",
    "sub_pops.append(np.where(np.in1d(idx_fish, np.intersect1d(tmp[(ns-1)*nx//ns:,:,:].reshape(-1), idx_fish)))[0])\n",
    "\n",
    "reps = 60\n",
    "obs_pops = np.concatenate([ np.arange(len(sub_pops)) for r in range(reps) ])\n",
    "obs_time = np.linspace(0,T, len(obs_pops)+1)[1:].astype(int)\n",
    "obs_scheme = ObservationScheme(p=p, T=T, \n",
    "                                sub_pops=sub_pops, \n",
    "                                obs_pops=obs_pops, \n",
    "                                obs_time=obs_time)\n",
    "obs_scheme.comp_subpop_stats()\n",
    "\n",
    "tmp = np.round([2000/p * len(sub_pops[i]) for i in range(len(sub_pops))]).astype(np.int)\n",
    "idx_a = np.hstack([np.sort(np.random.choice(sub_pops[i], tmp[i], replace=False)) for i in range(len(sub_pops))])\n",
    "idx_b = idx_a.copy()\n",
    "del tmp\n",
    "\n",
    "\n",
    "y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "\n",
    "\n",
    "W = obs_scheme.comp_coocurrence_weights(lag_range, sso=True, idx_a=idx_a, idx_b=idx_b)\n",
    "Qs, Om = f_l2_Hankel_comp_Q_Om(n=n,y=y,lag_range=lag_range,obs_scheme=obs_scheme,\n",
    "                      idx_a=idx_a,idx_b=idx_b,W=W,\n",
    "                      mmap=mmap,data_path=data_path,ts=None,ms=None)\n",
    "\n",
    "plt.figure(figsize=(3*kl_,3))\n",
    "plt.imshow(np.hstack([1./W[m] for m in range(len(lag_range))]), aspect='auto', interpolation='None')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "sub_pops = obs_scheme.sub_pops\n",
    "\n",
    "m = 0\n",
    "y_ = np.memmap(data_path+'y_' + idx_str + '_zscore', dtype=np.float, mode='r', shape=(T,p))\n",
    "ya = y_[m:-kl_+m, idx_a].copy()\n",
    "yb = y_[:-kl_, idx_b].copy()\n",
    "del y_\n",
    "\n",
    "Qgd = np.cov(ya.T, yb.T)[:len(idx_a), len(idx_b):]\n",
    "del ya\n",
    "del yb    \n",
    "Qest = pars_est['C'][idx_a,:].dot(pars_est['X'][m*n:(m+1)*n,:]).dot(pars_est['C'][idx_b,:].T)\n",
    "\n",
    "corrcoeffs = np.zeros((len(sub_pops), len(sub_pops)))\n",
    "for i in range(len(sub_pops)):\n",
    "    idx_ai = np.where( np.in1d(idx_a, sub_pops[i]) )[0]\n",
    "    for j in range(len(sub_pops)):\n",
    "        idx_bi = np.where( np.in1d(idx_b, sub_pops[j]) )[0]\n",
    "        corrcoeffs[i,j] = np.corrcoef(Qest[np.ix_(idx_ai, idx_bi)].reshape(-1), Qgd[np.ix_(idx_ai, idx_bi)].reshape(-1))[0,1]\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(corrcoeffs, interpolation='None')\n",
    "plt.title('pairwise subpopulation correlations ')\n",
    "plt.colorbar()\n",
    "plt.subplot(1,2,1)\n",
    "idx_plot = np.random.choice(np.invert(Om[0]).sum(), 10000, replace=False)\n",
    "plt.plot(Qgd[np.invert(Om[m])][idx_plot],Qest[np.invert(Om[m])][idx_plot], '.')\n",
    "plt.title('stitched covariances')\n",
    "#plt.savefig(data_path + 'sign_flips_n2.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = obs_scheme.comp_coocurrence_weights(lag_range, sso=True, idx_a=idx_a, idx_b=idx_b)\n",
    "\n",
    "plt.figure(figsize=(2*kl_,5))\n",
    "obs_scheme.gen_mask_from_scheme()\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(obs_scheme.mask[:100,1:-1:100].T, aspect='auto', interpolation='None')\n",
    "plt.grid('off')\n",
    "plt.title('observation scheme')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(np.hstack([1./W[m] for m in range(len(lag_range))]), aspect='auto', interpolation='None')\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(0,kl_*len(obs_scheme.idx_grp), 10))\n",
    "plt.hold(True)\n",
    "#for i in range(kl_):\n",
    "#    plt.plot([i*len(obs_scheme.idx_grp), i*len(obs_scheme.idx_grp)], [9, len(obs_scheme.idx_grp)], color='w')\n",
    "plt.hold(False)\n",
    "plt.title('subpop co-observation counts [bins]')\n",
    "plt.savefig(data_path + '10subpops_no_overlap_obs_scheme.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 overlapping subpopulations (z-planes 1:21 & 21:41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os, psutil, time\n",
    "\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl\n",
    "from ssidid.utility import get_subpop_stats, gen_data\n",
    "from ssidid import ObservationScheme\n",
    "from subtracking import Grouse, calc_subspace_proj_error\n",
    "\n",
    "run = '_overlap_stitch'\n",
    "ns = (5, 10, 50)\n",
    "\n",
    "data_path = '../fits/lsfm/grid_quick/'\n",
    "idx_str = 'small'\n",
    "idx_fish = np.load(data_path + 'idx_' + idx_str + '.npy')\n",
    "\n",
    "T, p = 1200, len(idx_fish)\n",
    "lag_range = np.arange(0,10)\n",
    "kl_ = np.max(lag_range)+1\n",
    "snr = (0., 0.)\n",
    "verbose=True\n",
    "\n",
    "def get_corrs(Qs,Om,lag_range,pars,idx_a,idx_b,traces,mmap):\n",
    "    kl = len(lag_range)\n",
    "    p,n = pars['C'].shape\n",
    "    pa, pb = idx_a.size, idx_b.size\n",
    "    idx_ab = np.intersect1d(idx_a, idx_b)\n",
    "    idx_a_ab = np.where(np.in1d(idx_a, idx_ab))[0]\n",
    "    idx_b_ab = np.where(np.in1d(idx_b, idx_ab))[0]\n",
    "    out = np.zeros(len(lag_range))\n",
    "    for m in range(kl): \n",
    "        m_ = lag_range[m] \n",
    "        Qrec = pars['C'][idx_a,:].dot(pars['X'][m*n:(m+1)*n, :]).dot(pars['C'][idx_b,:].T) \n",
    "        if m_ == 0:\n",
    "            Qrec[np.ix_(idx_a_ab, idx_b_ab)] += np.diag(pars['R'][idx_ab])\n",
    "        if mmap:\n",
    "            Q = np.memmap(data_path+'Qs_'+str(m_), dtype=np.float, mode='r', shape=(pa,pb))\n",
    "        else:\n",
    "            Q = Qs[m]\n",
    "        out[m] = np.corrcoef( Qrec[Om[m]].reshape(-1), (Qs[m][Om[m]]).reshape(-1) )[0,1]\n",
    "        if mmap:\n",
    "            del Q\n",
    "    return out\n",
    "\n",
    "obs_corrs = np.zeros((len(ns), len(lag_range)))\n",
    "stc_corrs = np.zeros((len(ns), len(lag_range)))\n",
    "loss      = np.zeros( len(ns) )\n",
    "for ni in range(len(ns)):\n",
    "    \n",
    "    n = ns[ni]\n",
    "\n",
    "    file_name = 'p' + str(p) + 'n' + str(n) + 'T' + str(T) + 'snr' + str(np.int(np.mean(snr)//1)) + '_run' + str(run)\n",
    "\n",
    "    load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "    mmap = load_file['mmap']\n",
    "    y, x, snr, idx_a, idx_b = load_file['y'], load_file['x'], load_file['snr'], load_file['idx_a'], load_file['idx_b'] \n",
    "    pars_true, pars_est, obs_scheme = load_file['pars_true'], load_file['pars_est'],load_file['obs_scheme']\n",
    "    W, Om= load_file['W'], load_file['Om']\n",
    "    Qs = [np.load(data_path+'Qs_'+str(lag_range[m])+'.npy') for m in range(len(lag_range)) ]\n",
    "    W = obs_scheme.comp_coocurrence_weights(lag_range, sso=True, idx_a=idx_a, idx_b=idx_b) if W is None else W\n",
    "\n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "\n",
    "    print('(T,p,n)', (T,p,n))\n",
    "\n",
    "    #print_slim(Qs,Om,lag_range,pars_est,idx_a,idx_b,_,False,data_path)\n",
    "    obs_corrs[ni,:] = get_corrs(Qs,Om,lag_range,pars_est,idx_a,idx_b,None,False)\n",
    "    loss[ni] = f_l2_Hankel_nl(C=pars_est['C'],\n",
    "                                   X=pars_est['X'],\n",
    "                                   R=pars_est['R'],\n",
    "                                   Qs=Qs,\n",
    "                                   Om=Om,\n",
    "                                   lag_range=lag_range,\n",
    "                                   ms=range(len(lag_range)),\n",
    "                                   idx_a=idx_a,\n",
    "                                   idx_b=idx_b)\n",
    "    \n",
    "\n",
    "    for m in lag_range:    \n",
    "        y_ = np.memmap(data_path+'y_' + idx_str + '_zscore', dtype=np.float, mode='r', shape=(T,p))\n",
    "        ya = y_[m:-kl_+m, idx_a].copy()\n",
    "        yb = y_[:-kl_, idx_b].copy()\n",
    "        del y_\n",
    "\n",
    "        Qgd = np.cov(ya.T, yb.T)[:len(idx_a), len(idx_b):]\n",
    "        del ya\n",
    "        del yb    \n",
    "        Qest = pars_est['C'][idx_a,:].dot(pars_est['X'][m*n:(m+1)*n,:]).dot(pars_est['C'][idx_b,:].T)\n",
    "\n",
    "        # notice that we take Om[0] for all m below: Om[1] etc. is 'fully observed' because it's only two subpops\n",
    "        # and we keep switching a couple of times. Actually however, this is something one would not take\n",
    "        # into account when fitting systems individually, so we reduce to inst. co-observations, i.e. Om[0]\n",
    "        stc_corrs[ni,m] = np.corrcoef(Qgd[np.invert(Om[0])], Qest[np.invert(Om[0])])[0,1]\n",
    "        del Qest\n",
    "        del Qgd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import seaborn\n",
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "\n",
    "clims = [np.min(Qs[0]), np.max(Qs[0])]\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "plt.imshow(Qs[0], interpolation='None')\n",
    "plt.colorbar()\n",
    "plt.grid('off')\n",
    "plt.title('observed inst. covariances')\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "y_ = np.memmap(data_path+'y_' + idx_str + '_zscore', dtype=np.float, mode='r', shape=(T,p))\n",
    "ya = y_[:-kl_, idx_a].copy()\n",
    "yb = y_[:-kl_, idx_b].copy()\n",
    "del y_\n",
    "Qgd = np.cov(ya.T, yb.T)[:len(idx_a), len(idx_b):]\n",
    "clims = [np.minimum(clims[0], np.min(Qgd)), np.maximum(clims[1], np.max(Qgd))]\n",
    "del ya\n",
    "del yb       \n",
    "plt.imshow(Qgd, interpolation='None')\n",
    "plt.colorbar()\n",
    "del Qgd\n",
    "plt.grid('off')\n",
    "plt.title('full instantaneous covariances')\n",
    "\n",
    "plt.subplot(2,3,3)\n",
    "n, m = 10, 0\n",
    "pars_est =  np.load(data_path + 'p160495n' + str(n) + 'T1200snr0_run_real_stitch.npz')['arr_0'].tolist()['pars_est']\n",
    "Qest = pars_est['C'][idx_a,:].dot(pars_est['X'][m*n:(m+1)*n,:]).dot(pars_est['C'][idx_b,:].T)\n",
    "del pars_est\n",
    "plt.imshow(Qest, interpolation='None')\n",
    "plt.colorbar()\n",
    "clims = [np.minimum(clims[0], np.min(Qest)), np.maximum(clims[1], np.max(Qest))]\n",
    "del Qest\n",
    "plt.grid('off')\n",
    "plt.title('reconstructed inst. covariances')\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "plt.clim(clims[0], clims[1])\n",
    "plt.subplot(2,3,2)\n",
    "plt.clim(clims[0], clims[1])\n",
    "plt.subplot(2,3,3)\n",
    "plt.clim(clims[0], clims[1])\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "plt.plot(ns, loss, 'o-')\n",
    "plt.ylabel('(partial) training loss')\n",
    "plt.xlabel('time lag')\n",
    "plt.box('off')\n",
    "plt.title('training loss vs. latent dim.')\n",
    "plt.xticks(ns)\n",
    "\n",
    "plt.subplot(2,3,5)\n",
    "plt.plot(obs_corrs.T)\n",
    "plt.xlabel('time lag')\n",
    "plt.ylabel('corr. of covariances')\n",
    "plt.legend(['n = ' + str(n) for n in ns], loc=3, frameon=False)\n",
    "plt.box('off')\n",
    "plt.axis([0,np.max(lag_range), 0.75, 1.])\n",
    "plt.title('corr. of observed covariances ')\n",
    "\n",
    "plt.subplot(2,3,6)\n",
    "plt.plot(stc_corrs.T)\n",
    "plt.xlabel('time lag')\n",
    "plt.ylabel('corr. of covariances')\n",
    "#plt.legend(['n = ' + str(n) for n in ns], loc=3, frameon=False)\n",
    "plt.box('off')\n",
    "plt.axis([0,np.max(lag_range), 0.75, 1.])\n",
    "plt.title('corr. of stitched covariances ')\n",
    "plt.savefig(data_path + 'res_summary_2subpops_zebrafish_small.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ssidid.SSID_Hankel_loss import f_l2_Hankel_comp_Q_Om\n",
    "data_path = '../fits/lsfm/grid_quick/'\n",
    "pars_true,x=None,None\n",
    "\n",
    "y_ = np.memmap(data_path+'y_' + idx_str + '_zscore', dtype=np.float, mode='r', shape=(T,p))\n",
    "y = np.memmap(data_path+'y', dtype=np.float, mode='w+', shape=(T,p))\n",
    "y[:] = y_.copy()\n",
    "del y_\n",
    "\n",
    "for i in range(len(obs_scheme.idx_grp)):\n",
    "    m = y[np.ix_(obs_scheme.idx_time[i], obs_scheme.idx_grp[i])].mean(axis=0)\n",
    "    assert len(m)==len(obs_scheme.idx_grp[i])\n",
    "    y[np.ix_(obs_scheme.idx_time[i], obs_scheme.idx_grp[i])] -= m.reshape(1, len(obs_scheme.idx_grp[i]))\n",
    "    plt.plot(m, 'g')\n",
    "    plt.hold(True)\n",
    "    plt.plot(y[np.ix_(obs_scheme.idx_time[i], obs_scheme.idx_grp[i])].mean(axis=0), 'b')\n",
    "    plt.show()\n",
    "del y\n",
    "y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "\n",
    "#idx_a = np.sort(np.random.choice(p,2000,replace=False)) if p > 2000 else np.arange(p)\n",
    "#idx_b = idx_a.copy() #np.sort(np.random.choice(p,1000,replace=False)) if p > 1000 else np.arange(p)\n",
    "\n",
    "W = obs_scheme.comp_coocurrence_weights(lag_range, sso=True, idx_a=idx_a, idx_b=idx_b)\n",
    "Qs, Om = f_l2_Hankel_comp_Q_Om(n=n,y=y,lag_range=lag_range,obs_scheme=obs_scheme,\n",
    "                      idx_a=idx_a,idx_b=idx_b,W=W,\n",
    "                      mmap=mmap,data_path=data_path,ts=None,ms=None)\n",
    "\n",
    "plt.figure(figsize=(3*kl_,3))\n",
    "plt.imshow(np.hstack([1./W[m] for m in range(len(lag_range))]), aspect='auto', interpolation='None')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
