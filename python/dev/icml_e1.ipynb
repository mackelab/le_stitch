{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 'e1': recovering LDS parameters from varying amounts of data\n",
    "\n",
    "- system size fixed, i.e. p = 1k, n = 20, and signal-to-noise ratio such that R gives 90% of total variance. \n",
    "- fitting first dynamics-agnostic, then switching to linearized parameterization with in particular $A$ exctracted from agnostic fit\n",
    "- direct comparison with GROUSE on subspace identification task (principal angles). \n",
    "\n",
    "## notes:\n",
    "- this is a master file. Individual runs for different data-set lengths $T \\in [10^3, 10^4, 10^5]$ were run on instances of this file that might have been slightly altered (e.g. reducing max batch size and instead running more epochs for small T's). They should be backed up at the lab dropbox folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load stored full data, extract observed data for this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "from ssidid.icml_scripts import run_default\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import linalg as la\n",
    "import glob, os, psutil, time\n",
    "\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "from ssidid import ObservationScheme, progprint_xrange\n",
    "from ssidid.utility import get_subpop_stats, gen_data\n",
    "from subtracking import Grouse, calc_subspace_proj_error\n",
    "\n",
    "lag_range = np.arange(30)\n",
    "kl_ = np.max(lag_range) + 1\n",
    "sso = True\n",
    "\n",
    "init = 'e1_init'\n",
    "p,T_full,n,snr = 1000, 100000 + kl_, 10, (9., 9.)\n",
    "nr = 0 # number of real eigenvalues\n",
    "snr = (9., 9.)\n",
    "whiten = True\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.9, 0.99, 0.9, 0.99\n",
    "mmap, verbose = True, True\n",
    "chunksize=np.min((p,100))\n",
    "\n",
    "Ts = np.array([1000, 3000, 10000, 30000, 100000]) + kl_\n",
    "\n",
    "rnd_seeds = range(10,20)\n",
    "\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "\n",
    "\n",
    "for rnd_seed in rnd_seeds:\n",
    "    data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e1/seed_' + str(int(rnd_seed)) + '/'\n",
    "\n",
    "    np.random.seed(rnd_seed)\n",
    "    pars_true, x, y, _, _ = gen_data(p,n,lag_range,T_full, nr,\n",
    "                                     eig_m_r, eig_M_r, \n",
    "                                     eig_m_c, eig_M_c,\n",
    "                                     mmap, chunksize,\n",
    "                                     data_path,\n",
    "                                     snr=snr, whiten=whiten)    \n",
    "\n",
    "    y_full = np.memmap(data_path+'y_full', dtype=np.float, mode='w+', shape=(T_full,p))\n",
    "    y_full[:] = y[:].copy()\n",
    "    y_full -= np.mean(y_full, axis=0)\n",
    "    del y_full\n",
    "    \n",
    "    save_dict = {'p' : p,\n",
    "                 'n' : n,\n",
    "                 'T' : T_full,\n",
    "                 'snr' : snr,\n",
    "                 'obs_scheme' : None,\n",
    "                 'lag_range' : lag_range,\n",
    "                 'x' : x,\n",
    "                 'mmap' : mmap,\n",
    "                 'y' : data_path if mmap else y,\n",
    "                 'pars_true' : pars_true,\n",
    "                 'pars_est' : None,\n",
    "                 'idx_a' : np.arange(p),\n",
    "                 'idx_b' : np.arange(p),\n",
    "                 'W' : None,\n",
    "                 'Qs' : None,\n",
    "                 'Om' : None,\n",
    "                 'rnd_seed' : rnd_seed\n",
    "                }\n",
    "    file_name = 'p' + str(p) + 'n' + str(n) + 'T' + str(T_full) + 'snr' + str(np.int(np.mean(snr)//1)) + 'e1_init'\n",
    "    np.savez(data_path + file_name, save_dict)    \n",
    "    \n",
    "    \n",
    "    for T in Ts:\n",
    "\n",
    "        print('T = ' , str(T))\n",
    "\n",
    "        file_name = 'p' + str(p) + 'n' + str(n) + 'T' + str(T_full) + 'snr' + str(np.int(np.mean(snr)//1)) +  init\n",
    "        load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "        pars_true = load_file['pars_true']\n",
    "        idx_a, idx_b = load_file['idx_a'].copy(), load_file['idx_b'].copy()\n",
    "\n",
    "        y_full = np.memmap(data_path+'y_full', dtype=np.float, mode='r', shape=(T_full,p))\n",
    "        y = np.memmap(data_path+'y', dtype=np.float, mode='w+', shape=(T,p))\n",
    "        y[:] = y_full[:T, :].copy()\n",
    "        del y_full\n",
    "        del y\n",
    "        chunksize = np.minimum(p, 100)\n",
    "        if mmap: \n",
    "            print('ensuring zero-mean data for given observation scheme')\n",
    "            for i in progprint_xrange(p//chunksize, perline=10):\n",
    "                y = np.memmap(data_path+'y', dtype=np.float, mode='r+', shape=(T,p))\n",
    "                y[:, i*chunksize:(i+1)*chunksize] = y[:, i*chunksize:(i+1)*chunksize] - y[:, i*chunksize:(i+1)*chunksize].mean(axis=0)\n",
    "                del y\n",
    "            if (p//chunksize)*chunksize < p:\n",
    "                y = np.memmap(data_path+'y', dtype=np.float, mode='r+', shape=(T,p))\n",
    "                y[:, (p//chunksize)*chunksize:] = y[:, (p//chunksize)*chunksize:] - y[:, (p//chunksize)*chunksize:].mean(axis=0)\n",
    "                del y        \n",
    "            y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "        else:\n",
    "            y -= y.mean(axis=0)\n",
    "\n",
    "        run = '_e1'    \n",
    "\n",
    "        print('re-computing observation scheme')    \n",
    "        obs_scheme = ObservationScheme(p=p, T=T, \n",
    "                                        sub_pops=(np.arange(p),), \n",
    "                                        obs_pops=(0,), \n",
    "                                        obs_time=(T,))\n",
    "        obs_scheme.comp_subpop_stats()    \n",
    "        sub_pops = obs_scheme.sub_pops\n",
    "\n",
    "        W = obs_scheme.comp_coocurrence_weights(lag_range, sso=True, idx_a=idx_a, idx_b=idx_b)\n",
    "\n",
    "        print('re-computing observed covariance matrices')    \n",
    "        Qs, Om = f_l2_Hankel_comp_Q_Om(n=n,y=y,lag_range=lag_range,obs_scheme=obs_scheme,\n",
    "                              idx_a=idx_a,idx_b=idx_b,W=W,sso=True,\n",
    "                              mmap=mmap,data_path=data_path,ts=None,ms=None)\n",
    "\n",
    "        pars_true['X'] = np.vstack([ np.linalg.matrix_power(pars_true['A'],m).dot(pars_true['Pi']) for m in lag_range])\n",
    "        print('true param. loss: ', f_l2_Hankel_nl(C=pars_true['C'],\n",
    "                                       X=pars_true['X'],\n",
    "                                       R=pars_true['R'],\n",
    "                                       Qs=Qs,\n",
    "                                       Om=Om,\n",
    "                                       lag_range=lag_range,\n",
    "                                       ms=range(len(lag_range)),\n",
    "                                       idx_a=idx_a,\n",
    "                                       idx_b=idx_b))\n",
    "        print_slim(Qs,Om,lag_range,pars_true,idx_a,idx_b,None,False,data_path)\n",
    "\n",
    "        rnd_seed = np.random.get_state()\n",
    "        #np.random.seed(rnd_seed)\n",
    "        pars_est, traces, ts= run_default(\n",
    "                    alphas    = (0.01, 0.001), \n",
    "                    b1s       = (0.98, 0.95), \n",
    "                    a_decays  = (0.98, 0.98), \n",
    "                    batch_sizes = (1, 10), \n",
    "                    max_zip_sizes =  (1000,250), \n",
    "                    max_iters = (100, 200),\n",
    "                    parametrizations = ('nl', 'ln'),\n",
    "                    pars_est='default', pars_true=pars_true, n=n, \n",
    "                    y=y, sso=sso, obs_scheme=obs_scheme, lag_range=lag_range, \n",
    "                    idx_a=idx_a, idx_b=idx_b,Qs=Qs,Om=Om, W=W,\n",
    "                    traces=[[], [], []], ts = [])    \n",
    "\n",
    "\n",
    "        pars_est_g = 'default'\n",
    "        # settings for GROUSE\n",
    "        a_grouse = 1\n",
    "        tracker = Grouse(p, n, a_grouse )\n",
    "        max_epoch_size = 1000\n",
    "        max_iter_grouse = 1000\n",
    "        get_obs = obs_scheme.gen_get_observed()\n",
    "\n",
    "        # fit GROUSE\n",
    "        print('\\n - GROUSE')\n",
    "        tracker.step = a_grouse\n",
    "        ct = 1.\n",
    "        error = np.zeros((max_iter_grouse, n+1))\n",
    "        t = time.time()\n",
    "        get_obs = obs_scheme.gen_get_observed()\n",
    "\n",
    "        for i in range(max_iter_grouse):\n",
    "            if np.mod(i,max_iter_grouse//10) == 0:\n",
    "                print('finished % ' + str((100*i)//max_iter_grouse))\n",
    "            idx = np.random.permutation(T-np.max(lag_range)-1)\n",
    "            idx = idx[:max_epoch_size] if len(idx) > max_epoch_size else idx\n",
    "            for j in range(len(idx)):\n",
    "                obs_idx =  np.zeros((p,1), dtype=bool)\n",
    "                obs_idx[get_obs(idx[j])] = True\n",
    "                tracker.consume(y[idx[j],:].reshape(-1,1), obs_idx)\n",
    "                ct += 1     \n",
    "                tracker.step = a_grouse / ct\n",
    "\n",
    "            error[i] = np.hstack((calc_subspace_proj_error(pars_true['C'], tracker.U), principal_angle(pars_true['C'], tracker.U)))\n",
    "        t = time.time() - t\n",
    "        pars_est_g = {'C' : tracker.U.copy()}\n",
    "\n",
    "        print('final proj. error (est.): ', str(error[-1][0]))\n",
    "\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(error[:,1:])\n",
    "        plt.title('subspace proj. error (GROUSE)')\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.loglog(error[:,1:])\n",
    "        plt.title('subspace proj. error (GROUSE)')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        print('final principal angles')\n",
    "        C = pars_est_g['C'].copy()\n",
    "        print(principal_angle(pars_true['C'], C))\n",
    "\n",
    "        del C    \n",
    "        traces_g = [error.copy()]\n",
    "        ts_g = [t]            \n",
    "\n",
    "        # extracting dynamics for GROUSE\n",
    "        print('filtering data') \n",
    "        obs_scheme.gen_mask_from_scheme()\n",
    "        tracker = Grouse(p, n, 0. )\n",
    "        tracker.U = pars_est_g['C'].copy()\n",
    "        x_g = np.zeros((T,n))\n",
    "        for t in range (T):\n",
    "            x_g[t,:] = tracker._project(y[t,:].reshape(p,1), obs_scheme.mask[t,:].reshape(p,1)).reshape(-1)\n",
    "        obs_scheme.mask = None    \n",
    "        print('extracting dynamics parameters') \n",
    "        pars_est_g['X'] = np.vstack([np.cov(x_g[m:-(kl_+1)+m, :].T, x_g[:-(kl_+1), :].T)[:n,n:] for m in lag_range])\n",
    "        pars_est_g['A'] = np.linalg.lstsq(pars_est_g['X'][:(len(lag_range)-1)*n,:], pars_est_g['X'][n:len(lag_range)*n,:])[0]\n",
    "        pars_est_g['Pi'] = (pars_est_g['X'][:n,:] + pars_est_g['X'][:n,:].T)/2 \n",
    "        ev_est = np.linalg.eigvals(pars_est_g['A'])\n",
    "        del x_g\n",
    "\n",
    "        plt.plot(np.real(np.linalg.eigvals( pars_est['A'])), 'go-')\n",
    "        plt.plot(np.real(np.linalg.eigvals(pars_est_g['A'])), 'bo-')\n",
    "        plt.plot(np.real(np.linalg.eigvals(pars_true['A'])), 'k')\n",
    "        plt.show()\n",
    "        plt.plot(np.imag(np.linalg.eigvals( pars_est['A'])), 'go-')\n",
    "        plt.plot(np.imag(np.linalg.eigvals(pars_est_g['A'])), 'bo-')\n",
    "        plt.plot(np.imag(np.linalg.eigvals(pars_true['A'])), 'k')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        save_dict = {'p' : p,'n' : n,'T' : T,'snr' : snr,'lag_range' : lag_range,\n",
    "                     'obs_scheme' : obs_scheme, 'mmap' : mmap,'y' : data_path if mmap else y,\n",
    "                     'pars_true' : pars_true, 'pars_est' : pars_est, 'pars_est_g' : pars_est_g,\n",
    "                     'idx_a' : idx_a,'idx_b' : idx_b, 'W' : W,'Qs' : None,'Om' : None,\n",
    "                     'traces' : traces, 'traces_g' : traces_g, 'ts':ts, 'ts_g':ts_g,\n",
    "                     'rnd_seed' : rnd_seed\n",
    "                    }\n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+'snr'+str(np.int(np.mean(snr)//1))+'_run'+str(run)                \n",
    "        #file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run)+'_'+str(overlap)\n",
    "        np.savez(data_path + file_name, save_dict)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding ssidid fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "from ssidid.icml_scripts import run_default\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import linalg as la\n",
    "import glob, os, psutil, time\n",
    "\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "from ssidid import ObservationScheme, progprint_xrange\n",
    "from ssidid.utility import get_subpop_stats, gen_data\n",
    "from subtracking import Grouse, calc_subspace_proj_error\n",
    "\n",
    "lag_range = np.arange(10)\n",
    "kl_ = np.max(lag_range) + 1\n",
    "sso = True\n",
    "\n",
    "run = 'e1'\n",
    "p,T_full,n,snr = 1000, 100030, 10, (9., 9.)\n",
    "nr = 0 # number of real eigenvalues\n",
    "snr = (9., 9.)\n",
    "whiten = True\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.9, 0.99, 0.9, 0.99\n",
    "mmap, verbose = True, True\n",
    "chunksize=np.min((p,100))\n",
    "\n",
    "rnd_seeds = range(10,20)\n",
    "Ts = np.array([5000, 50000]) + kl_\n",
    "\n",
    "\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "\n",
    "\n",
    "for rnd_seed in rnd_seeds:\n",
    "    \n",
    "    print('seed : ' + str(rnd_seed))\n",
    "    \n",
    "    data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e1/seed_' + str(int(rnd_seed)) + '/'\n",
    "\n",
    "    y_full = np.memmap(data_path+'y_full', dtype=np.float, mode='r', shape=(T_full,p))\n",
    "    \n",
    "    file_name = 'p' + str(p) + 'n' + str(n) + 'T' + str(T_full) + 'snr' + str(np.int(np.mean(snr)//1)) + 'e1_init'\n",
    "    load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "    pars_true = load_file['pars_true'].copy()\n",
    "    \n",
    "    for T in Ts:\n",
    "\n",
    "        print('T = ' , str(T))\n",
    "\n",
    "        file_name = 'p' + str(p) + 'n' + str(n) + 'T' + str(T_full) + 'snr' + str(np.int(np.mean(snr)//1)) +  init\n",
    "        load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "        pars_true = load_file['pars_true']\n",
    "        idx_a, idx_b = load_file['idx_a'].copy(), load_file['idx_b'].copy()\n",
    "\n",
    "        y_full = np.memmap(data_path+'y_full', dtype=np.float, mode='r', shape=(T_full,p))\n",
    "        y = np.memmap(data_path+'y', dtype=np.float, mode='w+', shape=(T,p))\n",
    "        y[:] = y_full[:T, :].copy()\n",
    "        del y_full\n",
    "        del y\n",
    "        chunksize = np.minimum(p, 100)\n",
    "        if mmap: \n",
    "            print('ensuring zero-mean data for given observation scheme')\n",
    "            for i in progprint_xrange(p//chunksize, perline=10):\n",
    "                y = np.memmap(data_path+'y', dtype=np.float, mode='r+', shape=(T,p))\n",
    "                y[:, i*chunksize:(i+1)*chunksize] = y[:, i*chunksize:(i+1)*chunksize] - y[:, i*chunksize:(i+1)*chunksize].mean(axis=0)\n",
    "                del y\n",
    "            if (p//chunksize)*chunksize < p:\n",
    "                y = np.memmap(data_path+'y', dtype=np.float, mode='r+', shape=(T,p))\n",
    "                y[:, (p//chunksize)*chunksize:] = y[:, (p//chunksize)*chunksize:] - y[:, (p//chunksize)*chunksize:].mean(axis=0)\n",
    "                del y        \n",
    "            y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "        else:\n",
    "            y -= y.mean(axis=0)\n",
    "\n",
    "        run = '_e1'    \n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+'snr'+str(np.int(np.mean(snr)//1))+'_run'+str(run)                \n",
    "        load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "\n",
    "        print('re-computing observation scheme')    \n",
    "        obs_scheme = ObservationScheme(p=p, T=T, \n",
    "                                        sub_pops=(np.arange(p),), \n",
    "                                        obs_pops=(0,), \n",
    "                                        obs_time=(T,))\n",
    "        obs_scheme.comp_subpop_stats()    \n",
    "        sub_pops = obs_scheme.sub_pops\n",
    "\n",
    "        W = obs_scheme.comp_coocurrence_weights(lag_range, sso=True, idx_a=idx_a, idx_b=idx_b)\n",
    "\n",
    "        print('re-computing observed covariance matrices')    \n",
    "        Qs, Om = f_l2_Hankel_comp_Q_Om(n=n,y=y,lag_range=lag_range,obs_scheme=obs_scheme,\n",
    "                              idx_a=idx_a,idx_b=idx_b,W=W,sso=True,\n",
    "                              mmap=mmap,data_path=data_path,ts=None,ms=None)\n",
    "\n",
    "        pars_true['X'] = np.vstack([ np.linalg.matrix_power(pars_true['A'],m).dot(pars_true['Pi']) for m in lag_range])\n",
    "        print('true param. loss: ', f_l2_Hankel_nl(C=pars_true['C'],\n",
    "                                       X=pars_true['X'],\n",
    "                                       R=pars_true['R'],\n",
    "                                       Qs=Qs,\n",
    "                                       Om=Om,\n",
    "                                       lag_range=lag_range,\n",
    "                                       ms=range(len(lag_range)),\n",
    "                                       idx_a=idx_a,\n",
    "                                       idx_b=idx_b))\n",
    "        print_slim(Qs,Om,lag_range,pars_true,idx_a,idx_b,None,False,data_path)\n",
    "\n",
    "        rnd_seed = np.random.get_state()\n",
    "        #np.random.seed(rnd_seed)\n",
    "        pars_est, traces, ts= run_default(\n",
    "                    alphas    = (0.01, 0.001), \n",
    "                    b1s       = (0.98, 0.95), \n",
    "                    a_decays  = (0.98, 0.98), \n",
    "                    batch_sizes = (1, 10), \n",
    "                    max_zip_sizes =  (1000,250), \n",
    "                    max_iters = (100, 200),\n",
    "                    parametrizations = ('nl', 'ln'),\n",
    "                    pars_est='default', pars_true=pars_true, n=n, \n",
    "                    y=y, sso=sso, obs_scheme=obs_scheme, lag_range=lag_range, \n",
    "                    idx_a=idx_a, idx_b=idx_b,Qs=Qs,Om=Om, W=W,\n",
    "                    traces=[[], [], []], ts = [])    \n",
    "\n",
    "\n",
    "        plt.plot(np.real(np.linalg.eigvals( pars_est['A'])), 'go-')\n",
    "        plt.plot(np.real(np.linalg.eigvals(pars_true['A'])), 'k')\n",
    "        plt.show()\n",
    "        plt.plot(np.imag(np.linalg.eigvals( pars_est['A'])), 'go-')\n",
    "        plt.plot(np.imag(np.linalg.eigvals(pars_true['A'])), 'k')\n",
    "        plt.show()\n",
    "\n",
    "        save_dict = {'p' : p,'n' : n,'T' : T,'snr' : snr,'lag_range' : load_file['lag_range'],\n",
    "                     'obs_scheme' : load_file['obs_scheme'], 'mmap' : mmap,'y' : data_path if mmap else y,\n",
    "                     'pars_true' : load_file['pars_true'], 'pars_est' : pars_est, \n",
    "                     'idx_a' : idx_a,'idx_b' : idx_b, 'W' : None,'Qs' : None,'Om' : None,\n",
    "                     'traces' : traces, 'ts': ts, \n",
    "                     'rnd_seed' : rnd_seed, \n",
    "                     'pars_est_g' : load_file['pars_est_g'], 'traces_g' :  load_file['traces_g'], 'ts_g': load_file['ts_g']\n",
    "                    }\n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+'snr'+str(np.int(np.mean(snr)//1))+'_run'+str(run)                \n",
    "        #file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+str(run)+'_'+str(overlap)\n",
    "        np.savez(data_path + file_name, save_dict)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding GROUSE fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "from ssidid.icml_scripts import run_default\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import linalg as la\n",
    "import glob, os, psutil, time\n",
    "\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "from ssidid import ObservationScheme, progprint_xrange\n",
    "from ssidid.utility import get_subpop_stats, gen_data\n",
    "from subtracking import Grouse, calc_subspace_proj_error\n",
    "\n",
    "lag_range = np.arange(10)\n",
    "kl_ = np.max(lag_range) + 1\n",
    "sso = True\n",
    "\n",
    "init = 'e1_init'\n",
    "p,T_full,n,snr = 1000, 100030, 10, (9., 9.)\n",
    "nr = 0 # number of real eigenvalues\n",
    "snr = (9., 9.)\n",
    "whiten = True\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.9, 0.99, 0.9, 0.99\n",
    "mmap, verbose = True, True\n",
    "chunksize=np.min((p,100))\n",
    "\n",
    "rnd_seeds = range(10,20)\n",
    "Ts = np.array([5000, 50000]) + kl_\n",
    "\n",
    "\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "\n",
    "\n",
    "for rnd_seed in rnd_seeds:\n",
    "    \n",
    "    print('seed : ' + str(rnd_seed))\n",
    "    \n",
    "    data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e1/seed_' + str(int(rnd_seed)) + '/'\n",
    "\n",
    "    y_full = np.memmap(data_path+'y_full', dtype=np.float, mode='r', shape=(T_full,p))\n",
    "    \n",
    "    file_name = 'p' + str(p) + 'n' + str(n) + 'T' + str(T_full) + 'snr' + str(np.int(np.mean(snr)//1)) + 'e1_init'\n",
    "    load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "    pars_true = load_file['pars_true'].copy()\n",
    "    \n",
    "    for T in Ts:\n",
    "\n",
    "        print('T = ' , str(T))\n",
    "\n",
    "        file_name = 'p' + str(p) + 'n' + str(n) + 'T' + str(T_full) + 'snr' + str(np.int(np.mean(snr)//1)) +  init\n",
    "        load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "        pars_true = load_file['pars_true']\n",
    "        idx_a, idx_b = load_file['idx_a'].copy(), load_file['idx_b'].copy()\n",
    "\n",
    "        y_full = np.memmap(data_path+'y_full', dtype=np.float, mode='r', shape=(T_full,p))\n",
    "        y = np.memmap(data_path+'y', dtype=np.float, mode='w+', shape=(T,p))\n",
    "        y[:] = y_full[:T, :].copy()\n",
    "        del y_full\n",
    "        del y\n",
    "        chunksize = np.minimum(p, 100)\n",
    "        if mmap: \n",
    "            print('ensuring zero-mean data for given observation scheme')\n",
    "            for i in progprint_xrange(p//chunksize, perline=10):\n",
    "                y = np.memmap(data_path+'y', dtype=np.float, mode='r+', shape=(T,p))\n",
    "                y[:, i*chunksize:(i+1)*chunksize] = y[:, i*chunksize:(i+1)*chunksize] - y[:, i*chunksize:(i+1)*chunksize].mean(axis=0)\n",
    "                del y\n",
    "            if (p//chunksize)*chunksize < p:\n",
    "                y = np.memmap(data_path+'y', dtype=np.float, mode='r+', shape=(T,p))\n",
    "                y[:, (p//chunksize)*chunksize:] = y[:, (p//chunksize)*chunksize:] - y[:, (p//chunksize)*chunksize:].mean(axis=0)\n",
    "                del y        \n",
    "            y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "        else:\n",
    "            y -= y.mean(axis=0)\n",
    "\n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+'snr'+str(np.int(np.mean(snr)//1))+'_run'+str(run)                \n",
    "        load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "        pars_est_g = load_file['pars_est_g']\n",
    "\n",
    "        print('re-computing observation scheme')    \n",
    "        obs_scheme = ObservationScheme(p=p, T=T, \n",
    "                                        sub_pops=(np.arange(p),), \n",
    "                                        obs_pops=(0,), \n",
    "                                        obs_time=(T,))\n",
    "        obs_scheme.comp_subpop_stats()    \n",
    "        sub_pops = obs_scheme.sub_pops\n",
    "\n",
    "\n",
    "        print('filtering data') \n",
    "        obs_scheme.gen_mask_from_scheme()\n",
    "        tracker = Grouse(p, n, 0. )\n",
    "        tracker.U = pars_est_g['C'].copy()\n",
    "        x_g = np.zeros((T,n))\n",
    "        for t in range (T):\n",
    "            x_g[t,:] = tracker._project(y[t,:].reshape(p,1), obs_scheme.mask[t,:].reshape(p,1)).reshape(-1)\n",
    "        obs_scheme.mask = None\n",
    "\n",
    "\n",
    "        lag_range_g = np.arange(20)\n",
    "        kl_ = np.max(lag_range_g) + 1\n",
    "        print('extracting dynamics parameters') \n",
    "        pars_est_g['X'] = np.vstack([np.cov(x_g[m:-(kl_+1)+m, :].T, x_g[:-(kl_+1), :].T)[:n,n:] for m in lag_range_g])\n",
    "        pars_est_g['A'] = np.linalg.lstsq(pars_est_g['X'][:(len(lag_range_g)-1)*n,:], pars_est_g['X'][n:len(lag_range_g)*n,:])[0]\n",
    "        pars_est_g['Pi'] = (pars_est_g['X'][:n,:] + pars_est_g['X'][:n,:].T)/2 \n",
    "        ev_est = np.linalg.eigvals(pars_est_g['A'])\n",
    "        del x_g\n",
    "\n",
    "        print('storing')\n",
    "        save_dict = {'p' : p,'n' : n,'T' : T,'snr' : snr,'lag_range' : load_file['lag_range'],\n",
    "                     'obs_scheme' : load_file['obs_scheme'], 'mmap' : mmap,'y' : data_path if mmap else y,\n",
    "                     'pars_true' : load_file['pars_true'], 'pars_est' : load_file['pars_est'], \n",
    "                     'idx_a' : load_file['idx_a'],'idx_b' : load_file['idx_b'], 'W' : None,'Qs' : None,'Om' : None,\n",
    "                     'traces' : load_file['traces'], 'ts': load_file['ts'], \n",
    "                     'rnd_seed' : rnd_seed, \n",
    "                     'pars_est_g' : load_file['pars_est_g'], 'traces_g' :  load_file['traces_g'], 'ts_g': load_file['ts_g']\n",
    "                    }\n",
    "        np.savez(data_path + file_name, save_dict)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding dynamics estimate for GROUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "from ssidid.icml_scripts import run_default\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import linalg as la\n",
    "import glob, os, psutil, time\n",
    "\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "from ssidid import ObservationScheme, progprint_xrange\n",
    "from ssidid.utility import get_subpop_stats, gen_data\n",
    "from subtracking import Grouse, calc_subspace_proj_error\n",
    "\n",
    "lag_range = np.arange(10)\n",
    "kl_ = np.max(lag_range) + 1\n",
    "sso = True\n",
    "\n",
    "run = '_e1'\n",
    "p,T_full,n,snr = 1000, 100030, 10, (9., 9.)\n",
    "nr = 0 # number of real eigenvalues\n",
    "snr = (9., 9.)\n",
    "whiten = True\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.9, 0.99, 0.9, 0.99\n",
    "mmap, verbose = True, True\n",
    "chunksize=np.min((p,100))\n",
    "\n",
    "rnd_seeds = range(10,20)\n",
    "Ts = np.array([1000, 3000, 10000, 30000, 100000]) + kl_\n",
    "Ts_g = Ts + 30 - kl_\n",
    "\n",
    "\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "\n",
    "\n",
    "for rnd_seed in rnd_seeds:\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    print('seed : ' + str(rnd_seed))\n",
    "    \n",
    "    data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e1/seed_' + str(int(rnd_seed)) + '/'\n",
    "\n",
    "    y_full = np.memmap(data_path+'y_full', dtype=np.float, mode='r', shape=(T_full,p))\n",
    "    \n",
    "    file_name = 'p' + str(p) + 'n' + str(n) + 'T' + str(T_full) + 'snr' + str(np.int(np.mean(snr)//1)) + 'e1_init'\n",
    "    load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "    pars_true = load_file['pars_true'].copy()\n",
    "    idx_a, idx_b = load_file['idx_a'].copy(), load_file['idx_b'].copy()\n",
    "    \n",
    "    for idxT in range(len(Ts)):\n",
    "        \n",
    "        T = Ts[idxT]\n",
    "        print('T = ' , str(T))\n",
    "\n",
    "        y_full = np.memmap(data_path+'y_full', dtype=np.float, mode='r', shape=(T_full,p))\n",
    "        y = np.memmap(data_path+'y', dtype=np.float, mode='w+', shape=(T,p))\n",
    "        y[:] = y_full[:T, :].copy()\n",
    "        del y_full\n",
    "        del y\n",
    "        chunksize = np.minimum(p, 100)\n",
    "        if mmap: \n",
    "            print('ensuring zero-mean data for given observation scheme')\n",
    "            for i in progprint_xrange(p//chunksize, perline=10):\n",
    "                y = np.memmap(data_path+'y', dtype=np.float, mode='r+', shape=(T,p))\n",
    "                y[:, i*chunksize:(i+1)*chunksize] = y[:, i*chunksize:(i+1)*chunksize] - y[:, i*chunksize:(i+1)*chunksize].mean(axis=0)\n",
    "                del y\n",
    "            if (p//chunksize)*chunksize < p:\n",
    "                y = np.memmap(data_path+'y', dtype=np.float, mode='r+', shape=(T,p))\n",
    "                y[:, (p//chunksize)*chunksize:] = y[:, (p//chunksize)*chunksize:] - y[:, (p//chunksize)*chunksize:].mean(axis=0)\n",
    "                del y        \n",
    "            y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "        else:\n",
    "            y -= y.mean(axis=0)\n",
    "\n",
    "\n",
    "        if T in [5010, 50010]:\n",
    "            file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+'snr'+str(np.int(np.mean(snr)//1))+'_run'+str(run)                \n",
    "            load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "            pars_est_g = load_file['pars_est_g']\n",
    "        else: \n",
    "            file_name = 'p'+str(p)+'n'+str(n)+'T'+str(Ts_g[idxT])+'snr'+str(np.int(np.mean(snr)//1))+'_run'+str(run)                \n",
    "            load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "            pars_est_g = load_file['pars_est_g']\n",
    "        \n",
    "        \n",
    "        print('re-computing observation scheme')    \n",
    "        obs_scheme = ObservationScheme(p=p, T=T, \n",
    "                                        sub_pops=(np.arange(p),), \n",
    "                                        obs_pops=(0,), \n",
    "                                        obs_time=(T,))\n",
    "        obs_scheme.comp_subpop_stats()    \n",
    "        sub_pops = obs_scheme.sub_pops\n",
    "\n",
    "\n",
    "        print('filtering data') \n",
    "        obs_scheme.gen_mask_from_scheme()\n",
    "        tracker = Grouse(p, n, 0. )\n",
    "        tracker.U = pars_est_g['C'].copy()\n",
    "        x_g = np.zeros((T,n))\n",
    "        for t in range (T):\n",
    "            x_g[t,:] = tracker._project(y[t,:].reshape(p,1), obs_scheme.mask[t,:].reshape(p,1)).reshape(-1)\n",
    "        obs_scheme.mask = None\n",
    "\n",
    "\n",
    "        lag_range_g = np.arange(20)\n",
    "        kl_ = np.max(lag_range_g) + 1\n",
    "        print('extracting dynamics parameters') \n",
    "        pars_est_g['X'] = np.vstack([np.cov(x_g[m:-(kl_+1)+m, :].T, x_g[:-(kl_+1), :].T)[:n,n:] for m in lag_range_g])\n",
    "        pars_est_g['A'] = np.linalg.lstsq(pars_est_g['X'][:(len(lag_range_g)-1)*n,:], pars_est_g['X'][n:len(lag_range_g)*n,:])[0]\n",
    "        pars_est_g['Pi'] = (pars_est_g['X'][:n,:] + pars_est_g['X'][:n,:].T)/2 \n",
    "        ev_est = np.linalg.eigvals(pars_est_g['A'])\n",
    "        del x_g\n",
    "\n",
    "        print('storing')\n",
    "        save_dict = {'p' : p,'n' : n,'T' : T,'snr' : load_file['snr'],'lag_range' : load_file['lag_range'],\n",
    "                     'obs_scheme' : load_file['obs_scheme'], 'mmap' : mmap,'y' : data_path if mmap else y,\n",
    "                     'pars_true' : load_file['pars_true'], 'pars_est' : load_file['pars_est'], \n",
    "                     'idx_a' : load_file['idx_a'],'idx_b' : load_file['idx_b'], 'W' : None,'Qs' : None,'Om' : None,\n",
    "                     'traces' : load_file['traces'], 'ts': load_file['ts'], \n",
    "                     'rnd_seed' : load_file['rnd_seed'], \n",
    "                     'pars_est_g' : pars_est_g, 'traces_g' :  load_file['traces_g'], 'ts_g': load_file['ts_g']\n",
    "                    }\n",
    "        np.savez(data_path + file_name, save_dict)        \n",
    "\n",
    "        \n",
    "    t = time.time() - t\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# safefile consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "from ssidid.icml_scripts import run_default\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import linalg as la\n",
    "import glob, os, psutil, time\n",
    "\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "from ssidid import ObservationScheme, progprint_xrange\n",
    "from ssidid.utility import get_subpop_stats, gen_data\n",
    "from subtracking import Grouse, calc_subspace_proj_error\n",
    "\n",
    "lag_range = np.arange(10)\n",
    "kl_ = np.max(lag_range) + 1\n",
    "sso = True\n",
    "\n",
    "run = '_e1'\n",
    "\n",
    "p,T_full,n,snr = 1000, 100030, 10, (9., 9.)\n",
    "nr = 0 # number of real eigenvalues\n",
    "snr = (9., 9.)\n",
    "mmap, verbose = True, True\n",
    "\n",
    "Ts = np.array([1000, 3000, 10000, 30000, 100000]) + kl_\n",
    "Ts_g = Ts + 30 - kl_\n",
    "rnd_seeds = range(10, 20)\n",
    "\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "\n",
    "for rnd_seed in rnd_seeds:\n",
    "    \n",
    "    print('seed : ' + str(rnd_seed))\n",
    "    \n",
    "    data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e1/seed_' + str(int(rnd_seed)) + '/'\n",
    "\n",
    "    y_full = np.memmap(data_path+'y_full', dtype=np.float, mode='r', shape=(T_full,p))\n",
    "    \n",
    "    file_name = 'p' + str(p) + 'n' + str(n) + 'T' + str(T_full) + 'snr' + str(np.int(np.mean(snr)//1)) + 'e1_init'\n",
    "    load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "    pars_true = load_file['pars_true'].copy()\n",
    "    idx_a, idx_b = load_file['idx_a'].copy(), load_file['idx_b'].copy()\n",
    "    \n",
    "    for idxT in range(len(Ts)):\n",
    "\n",
    "        T = Ts[idxT]\n",
    "        print('T = ' , str(T))\n",
    "\n",
    "        file_name_g = 'p'+str(p)+'n'+str(n)+'T'+str(Ts_g[idxT])+'snr'+str(np.int(np.mean(snr)//1))+'_run'+str(run)                \n",
    "        load_file_g = np.load(data_path + file_name_g + '.npz')['arr_0'].tolist()\n",
    "        pars_est_g = {'C' :  load_file_g['pars_est_g']['C'].copy(),\n",
    "                      'A' :  load_file_g['pars_est_g']['A'].copy(),\n",
    "                      'X' :  load_file_g['pars_est_g']['X'].copy(),\n",
    "                      'Pi' :  load_file_g['pars_est_g']['Pi'].copy()}\n",
    "        traces_g = load_file_g['traces_g']\n",
    "        ts_g = load_file_g['ts_g']\n",
    "        \n",
    "        del load_file\n",
    "        \n",
    "        file_name = 'p'+str(p)+'n'+str(n)+'T'+str(T)+'snr'+str(np.int(np.mean(snr)//1))+'_run'+str(run)                \n",
    "        load_file = np.load(data_path + file_name + '.npz')['arr_0'].tolist()\n",
    "\n",
    "        print('storing')\n",
    "        save_dict = {'p' : p,'n' : n,'T' : T,'snr' : snr,'lag_range' : load_file['lag_range'],\n",
    "                     'obs_scheme' : load_file['obs_scheme'], 'mmap' : mmap,'y' : data_path if mmap else y,\n",
    "                     'pars_true' : load_file['pars_true'], 'pars_est' : load_file['pars_est'], \n",
    "                     'idx_a' : load_file['idx_a'],'idx_b' : load_file['idx_b'], 'W' : None,'Qs' : None,'Om' : None,\n",
    "                     'traces' : load_file['traces'], 'ts': load_file['ts'], \n",
    "                     'rnd_seed' : load_file['rnd_seed'], \n",
    "                     'pars_est_g' : pars_est_g, 'traces_g' : traces_g, 'ts_g': ts_g\n",
    "                    }\n",
    "        \n",
    "        #print('file_name_g', file_name_g)\n",
    "        #print(pars_est_g.keys())\n",
    "        #print(traces_g)\n",
    "        #print(ts_g)\n",
    "        #print('file_name', file_name)\n",
    "        #print(load_file['pars_est_g'])\n",
    "        np.savez(data_path + file_name, save_dict)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generation (to be run once!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os, psutil, time\n",
    "\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "from ssidid.utility import get_subpop_stats, gen_data\n",
    "from ssidid import ObservationScheme\n",
    "from subtracking import Grouse, calc_subspace_proj_error\n",
    "from ssidid import progprint_xrange\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "\n",
    "# define problem size\n",
    "lag_range = np.arange(0,30)\n",
    "kl_ = np.max(lag_range)+1\n",
    "T_full = 100000 + kl_\n",
    "p, n, T = 1000, 10, T_full\n",
    "\n",
    "nr = 0 # number of real eigenvalues\n",
    "snr = (9., 9.)\n",
    "whiten = True\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.9, 0.99, 0.9, 0.99\n",
    "\n",
    "# I/O matter\n",
    "mmap, chunksize = True, np.min((p,100))\n",
    "verbose=True\n",
    "\n",
    "# create subpopulations\n",
    "sso = True\n",
    "sub_pops = (np.arange(p),)\n",
    "\n",
    "obs_pops = np.concatenate([ np.arange(len(sub_pops)) for r in range(reps) ])\n",
    "obs_time = np.linspace(0,T, len(obs_pops)+1)[1:].astype(int)\n",
    "obs_scheme = ObservationScheme(p=p, T=T, \n",
    "                                sub_pops=sub_pops, \n",
    "                                obs_pops=obs_pops, \n",
    "                                obs_time=obs_time)\n",
    "obs_scheme.comp_subpop_stats()\n",
    "    \n",
    "np.random.seed(rnd_seed)\n",
    "pars_true, x, y, _, _ = gen_data(p,n,lag_range,T, nr,\n",
    "                                 eig_m_r, eig_M_r, \n",
    "                                 eig_m_c, eig_M_c,\n",
    "                                 mmap, chunksize,\n",
    "                                 data_path,\n",
    "                                 snr=snr, whiten=whiten)    \n",
    "\n",
    "save_dict = {'p' : p,\n",
    "             'n' : n,\n",
    "             'T' : T,\n",
    "             'snr' : snr,\n",
    "             'obs_scheme' : obs_scheme,\n",
    "             'lag_range' : lag_range,\n",
    "             'x' : x,\n",
    "             'mmap' : mmap,\n",
    "             'y' : data_path if mmap else y,\n",
    "             'pars_true' : pars_true,\n",
    "             'pars_est' : pars_est,\n",
    "             'idx_a' : idx_a,\n",
    "             'idx_b' : idx_b,\n",
    "             'W' : W,\n",
    "             'Qs' : None,\n",
    "             'Om' : None,\n",
    "             'rnd_seed' : rnd_seed\n",
    "            }\n",
    "file_name = 'p' + str(p) + 'n' + str(n) + 'T' + str(T) + 'snr' + str(np.int(np.mean(snr)//1)) + 'e1_init'\n",
    "np.savez(data_path + file_name, save_dict)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl, f_l2_Hankel_comp_Q_Om\n",
    "from ssidid import progprint_xrange\n",
    "\n",
    "data_path =  '/home/mackelab/Desktop/Projects/Stitching/results/icml_e1/'\n",
    "\n",
    "\n",
    "if mmap: \n",
    "    print('ensuring zero-mean data for given observation scheme')\n",
    "    for i in progprint_xrange(p//chunksize, perline=10):\n",
    "        y = np.memmap(data_path+'y', dtype=np.float, mode='r+', shape=(T,p))\n",
    "        y[:, i*chunksize:(i+1)*chunksize] = y[:, i*chunksize:(i+1)*chunksize] - y[:, i*chunksize:(i+1)*chunksize].mean(axis=0)\n",
    "        del y\n",
    "    if (p//chunksize)*chunksize < p:\n",
    "        y = np.memmap(data_path+'y', dtype=np.float, mode='r+', shape=(T,p))\n",
    "        y[:, (p//chunksize)*chunksize:] = y[:, (p//chunksize)*chunksize:] - y[:, (p//chunksize)*chunksize:].mean(axis=0)\n",
    "        del y        \n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "else:\n",
    "    y -= y.mean(axis=0)\n",
    "\n",
    "idx_a = np.sort(np.random.choice(p, 1000, replace=False)) if p > 1000 else np.arange(p)\n",
    "idx_b = idx_a.copy()\n",
    "\n",
    "W = obs_scheme.comp_coocurrence_weights(lag_range, sso=True, idx_a=idx_a, idx_b=idx_b)\n",
    "print('computing time-lagged covariances')\n",
    "Qs, Om = f_l2_Hankel_comp_Q_Om(n=n,y=y,lag_range=lag_range,obs_scheme=obs_scheme,\n",
    "                      idx_a=idx_a,idx_b=idx_b,W=W,sso=sso,\n",
    "                      mmap=mmap,data_path=data_path,ts=None,ms=None)\n",
    "\n",
    "#pars_true['X'] = np.vstack([ np.linalg.matrix_power(pars_true['A'],m).dot(pars_true['Pi']) for m in lag_range])\n",
    "pars_true['X'] = np.vstack([ np.cov(x[m:T-kl_+m].T, x[:T-kl_].T)[:n,n:] for m in lag_range])\n",
    "print('true param. loss: ', f_l2_Hankel_nl(C=pars_true['C'],\n",
    "                               X=pars_true['X'],\n",
    "                               R=pars_true['R'],\n",
    "                               Qs=Qs,\n",
    "                               Om=Om,\n",
    "                               lag_range=lag_range,\n",
    "                               ms=range(len(lag_range)),\n",
    "                               idx_a=idx_a,\n",
    "                               idx_b=idx_b))\n",
    "print_slim(Qs,Om,lag_range,pars_true,idx_a,idx_b,_,False,data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_dict = {'p' : p,\n",
    "             'n' : n,\n",
    "             'T' : T,\n",
    "             'snr' : snr,\n",
    "             'obs_scheme' : obs_scheme,\n",
    "             'lag_range' : lag_range,\n",
    "             'x' : x,\n",
    "             'mmap' : mmap,\n",
    "             'y' : data_path if mmap else y,\n",
    "             'pars_true' : pars_true,\n",
    "             'pars_est' : pars_est,\n",
    "             'idx_a' : idx_a,\n",
    "             'idx_b' : idx_b,\n",
    "             'W' : W,\n",
    "             'Qs' : None,\n",
    "             'Om' : None,\n",
    "             'rnd_seed' : rnd_seed\n",
    "            }\n",
    "file_name = 'p' + str(p) + 'n' + str(n) + 'T' + str(T) + 'snr' + str(np.int(np.mean(snr)//1)) + 'e1_init'\n",
    "np.savez(data_path + file_name, save_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_full2 = np.memmap(data_path+'y_full', dtype=np.float, mode='r', shape=(T,p))\n",
    "y_full2.mean(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
