{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitz-Hugh-Nagumo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mackelab/anaconda3/lib/python3.5/site-packages/sklearn/utils/fixes.py:64: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if 'order' in inspect.getargspec(np.copy)[0]:\n",
      "/home/mackelab/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:46: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os, psutil, time\n",
    "\n",
    "p,n =  10000, 20\n",
    "k,l = 1,1\n",
    "T = 2000\n",
    "\n",
    "# fix emission model parameters\n",
    "pars = {}\n",
    "pars['C'] = np.random.normal(size=(p,n))/np.sqrt(n)\n",
    "pars['R'] = 1 * np.ones(p)\n",
    "tf = 1\n",
    "\n",
    "\n",
    "# diff. eq.\n",
    "I = 0\n",
    "def ddt_const(x):\n",
    "    v,w = x[0],x[1]\n",
    "    return np.array((v - v**3/3 -w + I, 0.08*(v +0.7-0.8*w)))\n",
    "\n",
    "# quiver plot\n",
    "\n",
    "N = 30\n",
    "V, W = np.meshgrid(np.linspace(-3,3,N), np.linspace(-3,3,N))\n",
    "dV, dW = np.zeros((N,N)), np.zeros((N,N))\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        tmp = ddt_const(np.array((V[i,j], W[i,j])))\n",
    "        dV[i,j], dW[i,j] = tmp[0], tmp[1]\n",
    "\n",
    "#plt.figure(figsize=(10,10))\n",
    "#plt.quiver(V, W, dV, dW, \n",
    "#           edgecolor='k', linewidth=.5)\n",
    "#plt.show()\n",
    "\n",
    "# generate latent trajectory\n",
    "\n",
    "I = [0]\n",
    "def ddt(x,t):\n",
    "    v,w = x[:n//2],x[n//2:]\n",
    "    return np.hstack((v - v**3/3 -w + I[t], 0.08*(v +0.7-0.8*w)))\n",
    "I0 = 0.3\n",
    "ts = np.arange(0,tf*2000,tf*2000/(2*tf*T))\n",
    "I = 0.01/0.2 * np.random.normal(size=(len(ts),n//2))*np.sqrt(0.1) + I0\n",
    "x0 = np.random.normal(size=n)\n",
    "x = sp.integrate.odeint(ddt, x0, ts)\n",
    "#plt.figure(figsize=(20,10))\n",
    "#plt.plot(ts, x[:,0:-1:2], 'k')\n",
    "#plt.hold(True)\n",
    "#plt.plot(ts, x[:,1:-1:2], 'b--')\n",
    "#plt.show()\n",
    "\n",
    "x = x[T:-1:tf] # downsample to 1s to reduce 1-time-lag correlation \n",
    "x = x[-T:]\n",
    "x = (x - np.mean(x,0))/np.sqrt(np.var(x,0))\n",
    "#T = T//tf      # (otherwise we'll need a lot of time-lags to add information)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mackelab/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:46: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((20,), (20,), (4000,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0.shape, ddt(x0, ts[0]).shape, ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate noisy observed data\n",
    "\n",
    "# I/O matter\n",
    "mmap, chunksize = False, np.min((T,100))\n",
    "#data_path, save_file = '/media/marcel/636f7b46-1fd1-4600-b69e-86d2ed82002c/stitching/hankel/', 'test'\n",
    "data_path, save_file = '../fits/', 'test'\n",
    "pa, pb = np.min((p, 1000)), np.min((p, 1000))\n",
    "idx_a, idx_b = np.sort(np.random.choice(p,pa,replace=False)), np.sort(np.random.choice(p,pb,replace=False))\n",
    "verbose=True\n",
    "\n",
    "T = x.shape[0]\n",
    "if mmap:\n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='w+', shape=(T,p))\n",
    "    eps = np.memmap(data_path+'eps', dtype=np.float, mode='w+', shape=(T,p))\n",
    "else:\n",
    "    y = np.empty(shape=(T,p))\n",
    "    eps = np.empty(shape=(T,p))\n",
    "    \n",
    "for i in range(T//chunksize):\n",
    "    idx = range(chunksize*i,chunksize*(i+1))\n",
    "    eps[idx] = np.atleast_2d(np.sqrt(pars['R'])) * np.random.normal(size=(chunksize,p)) \n",
    "    y[idx] = x[idx].dot(pars['C'].T) + eps[idx] \n",
    "    if mmap:\n",
    "        del y # releases RAM, forces flush to disk\n",
    "        y = np.memmap(data_path+'y', dtype=np.float, mode='r+', shape=(T,p))      \n",
    "        del eps # releases RAM, forces flush to disk\n",
    "        eps = np.memmap(data_path+'eps', dtype=np.float, mode='r+', shape=(T,p))      \n",
    "idx = (T//chunksize)*chunksize\n",
    "eps[idx:] = np.atleast_2d(np.sqrt(pars['R'])) * np.random.normal(size=(T-(T//chunksize)*chunksize,p))\n",
    "y[idx:] = x[(T//chunksize)*chunksize:].dot(pars['C'].T) + eps[idx:]\n",
    "if mmap:\n",
    "    del y # releases RAM, forces flush to disk\n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))   \n",
    "    del eps # releases RAM, forces flush to disk\n",
    "    eps = np.memmap(data_path+'eps', dtype=np.float, mode='r', shape=(T,p))      \n",
    "    \n",
    "Qs = []\n",
    "for m in range(k+l):\n",
    "    Qs.append(None)\n",
    "    print('computing time-lagged covariance for lag ', str(m))\n",
    "    if mmap:\n",
    "        Q = np.memmap(data_path+'Qs_'+str(m), dtype=np.float, \n",
    "                      mode='w+', shape=(pa,pb))\n",
    "    else:\n",
    "        Q = np.empty((pa,pb))\n",
    "    Q[:] = np.cov(y[m:m-(k+l),idx_a].T, y[:-(k+l),idx_b].T)[:pa,pa:]     \n",
    "    if mmap:\n",
    "        del Q\n",
    "        Qs[m] = np.memmap(data_path+'Qs_'+str(m), dtype=np.float, \n",
    "                          mode='r', shape=(pa,pb))\n",
    "    else:\n",
    "        Qs[m] = Q\n",
    "        \n",
    "    if mmap:\n",
    "        del y # releases RAM, forces flush to disk\n",
    "        y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))   \n",
    "        del eps # releases RAM, forces flush to disk\n",
    "        eps = np.memmap(data_path+'eps', dtype=np.float, mode='r', shape=(T,p))      \n",
    "        \n",
    "        \n",
    "key_pars = {'C' : pars['C'],\n",
    "            'R' : pars['R'],\n",
    "            'k' : k, 'l' : l,\n",
    "            'idx_a' : idx_a,\n",
    "            'idx_b' : idx_b\n",
    "           }\n",
    "np.savez(data_path+'pars', \n",
    "         pars=key_pars)\n",
    "np.savez(data_path+'x', x=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_b = idx_a.copy()\n",
    "plt.figure(figsize=(10*(k+l), 10))\n",
    "for m in range(k+l):\n",
    "    print('computing time-lagged covariance for lag ', str(m))\n",
    "    \n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.subplot(1,3,1)\n",
    "    #Qr[:] = (pars['C'][idx_a,:].dot(np.cov(x[m:m-(k+l),:].T, x[:-(k+l),:].T)[:n,n:]).dot(pars['C'][idx_b,:].T))\n",
    "    #Qr = np.cov(pars['C'][idx_a,:].dot(x[m:m-(k+l),:].T) + eps[m:m-(k+l),idx_a].T, pars['C'][idx_b,:].dot(x[0:-(k+l),:].T) + eps[0:0-(k+l),idx_b].T)[:pa,pa:]\n",
    "    Qr = np.cov(pars['C'][idx_a,:].dot(x[m:m-(k+l),:].T), pars['C'][idx_b,:].dot(x[0:-(k+l),:].T))[:pa,pa:]\n",
    "    plt.imshow(Qr, interpolation='None')    \n",
    "\n",
    "    plt.subplot(1,3,2)        \n",
    "    plt.imshow(Qs[m], interpolation='None')    \n",
    "    if mmap:\n",
    "        Q = Qs[m]\n",
    "        Qs[m] = None\n",
    "        del Q\n",
    "        Qs[m] = np.memmap(data_path+'Qs_'+str(m), dtype=np.float, \n",
    "                          mode='r', shape=(pa,pb))    \n",
    "\n",
    "    plt.subplot(1,3,3)    \n",
    "    plt.plot(Qs[m], Qr[:], 'b.')\n",
    "    plt.title(str(np.corrcoef(Qs[m].reshape(-1), Qr.reshape(-1))[0,1]))\n",
    "    if m == 0:\n",
    "        plt.xlabel('not adding R to reconstruction!')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data from disk (other default storage folder!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "if True:                                # make sure you want to execute this!\n",
    "    import numpy as np\n",
    "    import scipy as sp\n",
    "    from sklearn.decomposition import PCA\n",
    "    import matplotlib.pyplot as plt\n",
    "    import glob, os, psutil, time\n",
    "\n",
    "    data_path = '../fits/nonlinear_fitzhughnagumo/'\n",
    "\n",
    "    pars=np.load(data_path+'pars.npz')['pars'].tolist()\n",
    "    pars_est=np.load(data_path+'pars_est_full.npz')['arr_0'].tolist()['pars_est_full']\n",
    "    pars_pca=np.load(data_path+'pars_pca.npz')['pars'].tolist()\n",
    "    idx_a = pars['idx_a']\n",
    "    idx_b = pars['idx_b']\n",
    "    pa, pb = idx_a.size, idx_b.size\n",
    "    x=np.load(data_path+'x.npz')['x']\n",
    "\n",
    "    p,n = pars['C'].shape\n",
    "    T = x.shape[0]\n",
    "    k,l = pars['k'],pars['l']\n",
    "\n",
    "    mmap, chunksize = True, np.min((T,p))\n",
    "    Qs = []\n",
    "    for m in range(k+l):\n",
    "            Qs.append(np.memmap(data_path+'Qs_'+str(m), dtype=np.float, \n",
    "                          mode='r', shape=(pa,pb)))\n",
    "\n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:                                # make sure you want to execute this!\n",
    "\n",
    "    from scipy.io import savemat\n",
    "    savemat(data_path+'parameters', {'pars' : np.load(data_path+'pars.npz')['pars'].tolist(),\n",
    "                                     'pars_est_full':np.load(data_path+'pars_est_full.npz')['pars'].tolist(),\n",
    "                                     'pars_est_partial':np.load(data_path+'pars_est_partial.npz')['pars'].tolist(),\n",
    "                                     'pars_pca':pars_pca})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.subplot(3,1,1)\n",
    "    plt.plot(y[:, idx_a])\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel('y')\n",
    "    plt.subplot(3,1,2)\n",
    "    plt.plot(x)\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel('x')\n",
    "    plt.subplot(3,1,3)\n",
    "    plt.plot(T//2+np.arange(100,dtype=int), x[T//2+np.arange(100,dtype=int)])\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel('x')\n",
    "    plt.show()\n",
    "if mmap:\n",
    "    del y # releases RAM, forces flush to disk\n",
    "    y = np.memmap(data_path+'y', dtype=np.float, mode='r', shape=(T,p))\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "#if not mmap:\n",
    "if True:\n",
    "    pca = PCA()\n",
    "    pca.fit(y)\n",
    "    explained_variance_ratio_ = np.hstack((pca.explained_variance_ratio_, np.zeros(np.max((p-T,0)))))\n",
    "    plt.plot(range(1,p+1), np.cumsum(explained_variance_ratio_)/np.sum(explained_variance_ratio_))\n",
    "    plt.hold(True)\n",
    "    plt.plot(np.linspace(0,p+1,np.min((20,p))), \n",
    "             np.cumsum(pca.explained_variance_ratio_[:np.min((20,p))])/np.sum(pca.explained_variance_ratio_), \n",
    "             'r--')\n",
    "    plt.legend(('cum. var. expl.', 'first 20, x-axis rescaled'))\n",
    "\n",
    "    pars_pca = {}\n",
    "    pars_pca['C'] = pca.components_[:n].T\n",
    "    pars_pca['Pi'] = np.diag(pca.explained_variance_[:n])    \n",
    "    #np.savez(data_path+'pars_pca', \n",
    "    #     pars=pars_pca)\n",
    "    \n",
    "plt.xlabel('#eigvalue')\n",
    "plt.title('% explained variance of PCA (if p not too large)')\n",
    "plt.show()\n",
    "print('noise variance / total variance: \\n ', np.mean(pars['R']/np.var(y,axis=0)))\n",
    "\n",
    "if p < 1000:\n",
    "    L0 = np.cov(y.T)\n",
    "    L0[np.diag_indices(p)] *= 0\n",
    "    Lr = (pars['C']).dot(np.cov(x.T)).dot((pars['C']).T) + np.diag(pars['R'])\n",
    "    Lr[np.diag_indices(p)] *= 0\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(L0, interpolation='None')\n",
    "    \n",
    "    plt.title('emp. cov matrix')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(Lr, interpolation='None')\n",
    "    plt.title('est. cov matrix (C*cov(x)*C.T + cov(eps))')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.plot(L0[:], Lr[:], 'b.')\n",
    "    plt.xlabel('emp.')\n",
    "    plt.xlabel('est.')\n",
    "    plt.show()\n",
    "\n",
    "    print(np.var(y), pars['R'], \n",
    "          np.mean(np.abs(x.dot(pars['C'].T))), np.var(x.dot(pars['C'].T)))\n",
    "#print(np.var(y, axis=0), np.var(pars['sqR']*eps, axis=0), np.mean(np.abs(x.dot(pars['C'].T)), axis=0))\n",
    "\n",
    "#nonlinearity of latents\n",
    "xp = x[0:T-1]\n",
    "xf = x[1:T]\n",
    "A_ls = np.linalg.lstsq(xp, xf)[0].T\n",
    "xf_l = xp.dot(A_ls)\n",
    "plt.figure(figsize=(20,np.ceil(n/2)*10))\n",
    "for i in range(n):\n",
    "    plt.subplot(np.ceil(n/2),2,i+1)\n",
    "    plt.plot(xf_l[:,i], xf[:,i], 'k.')\n",
    "    plt.hold(True)\n",
    "    plt.plot(xf_l[:,i], xf_l[:,i], 'r.')\n",
    "    plt.xlabel('x_pred_lin')\n",
    "    plt.ylabel('x_emp')\n",
    "    plt.axis('equal')\n",
    "    mlim = np.max((np.max(np.abs(xf_l[:,i])),np.max(np.abs(xf[:,i]))))\n",
    "    #plt.axis(1.1*np.array([-mlim,mlim,-mlim,mlim]))\n",
    "    plt.title('non-linearity of x_'+str(i+1))\n",
    "plt.show()\n",
    "        \n",
    "print('\\n')\n",
    "print(psutil.virtual_memory())\n",
    "print(psutil.swap_memory())    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "for m in range(k+l):\n",
    "    plt.subplot(k+l,1,m)\n",
    "    Q = np.empty((n,n))\n",
    "    Q[:] = np.corrcoef(x[m:m-(k+l),:].T, x[:-(k+l),:].T)[:n,n:]\n",
    "    plt.imshow(Q, interpolation='None')    \n",
    "    plt.colorbar()\n",
    "    plt.title('m' + str(m))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os, psutil, time\n",
    "\n",
    "os.chdir('../core')\n",
    "import ssm_scripts, ssm_fit\n",
    "from utility import get_subpop_stats, gen_data\n",
    "from SSID_Hankel_loss import run_bad, plot_slim\n",
    "os.chdir('../dev')\n",
    "\n",
    "#np.random.seed(0)\n",
    "#y -= np.mean(y,axis=0)\n",
    "verbose=True\n",
    "\n",
    "# settings for fitting algorithm\n",
    "# settings for fitting algorithm\n",
    "batch_size, max_zip_size, max_iter = 10, 10, 10\n",
    "a, b1, b2, e = 0.0001, 0.9, 0.99, 1e-8\n",
    "a_R = a\n",
    "\n",
    "# create subpopulations\n",
    "sub_pops = (np.arange(0,p), np.arange(0,p))\n",
    "obs_pops = np.array([0,1])\n",
    "obs_time = np.array([T//2, T])\n",
    "\n",
    "obs_idx, idx_grp, co_obs, _, _, _, Om, _, _ = \\\n",
    "    get_subpop_stats(sub_pops=sub_pops, p=p, verbose=False)\n",
    "\n",
    "pars_init='default'        \n",
    "t = time.time()\n",
    "pars_init, pars_est, traces = run_bad(k=k,l=l,n=n,y=y, Qs=Qs,Om=Om,idx_a=idx_a, idx_b=idx_b,\n",
    "                                      sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                                      obs_pops=obs_pops,obs_time=obs_time,\n",
    "                                      linearity=linearity,stable=stable,init=pars_init,\n",
    "                                      alpha=a,alpha_R=a_R,b1=b1,b2=b2,e=e,max_iter=max_iter,batch_size=batch_size,\n",
    "                                      verbose=verbose, sym_psd=sym_psd, max_zip_size=max_zip_size)\n",
    "\n",
    "print('fitting time was ', time.time() - t, 's')\n",
    "print('\\n')\n",
    "print(psutil.virtual_memory())\n",
    "print(psutil.swap_memory())\n",
    "\n",
    "plot_slim(Qs,k,l,pars_est,idx_a,idx_b,traces,mmap,data_path)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# settings for fitting algorithm\n",
    "batch_size, max_zip_size, max_iter = 10, 100, 100\n",
    "a, b1, b2, e = 0.001, 0.9, 0.99, 1e-8\n",
    "a_R = 0.001\n",
    "\n",
    "t = time.time()\n",
    "_, pars_est, traces = run_bad(k=k,l=l,n=n,y=y, Qs=Qs,Om=Om,idx_a=idx_a, idx_b=idx_b,\n",
    "                                      sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                                      obs_pops=obs_pops,obs_time=obs_time,\n",
    "                                      linearity=linearity,stable=stable,init=pars_est,\n",
    "                                      alpha=a,alpha_R=a_R,b1=b1,b2=b2,e=e,max_iter=max_iter,batch_size=batch_size,\n",
    "                                      verbose=verbose, sym_psd=sym_psd, max_zip_size=max_zip_size)\n",
    "\n",
    "print('fitting time was ', time.time() - t, 's')\n",
    "print('\\n')\n",
    "\n",
    "plot_slim(Qs,k,l,pars_est,idx_a,idx_b,traces,mmap,data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# settings for fitting algorithm\n",
    "batch_size, max_zip_size, max_iter = 100, 3, 10\n",
    "a, b1, b2, e = 0.001, 0.9, 0.99, 1e-8\n",
    "a_R = 0.001\n",
    "\n",
    "t = time.time()\n",
    "_, pars_est, traces = run_bad(k=k,l=l,n=n,y=y, Qs=Qs,Om=Om,idx_a=idx_a, idx_b=idx_b,\n",
    "                                      sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                                      obs_pops=obs_pops,obs_time=obs_time,\n",
    "                                      linearity=linearity,stable=stable,init=pars_est,\n",
    "                                      alpha=a,alpha_R=a_R,b1=b1,b2=b2,e=e,max_iter=max_iter,batch_size=batch_size,\n",
    "                                      verbose=verbose, sym_psd=sym_psd, max_zip_size=max_zip_size)\n",
    "\n",
    "print('fitting time was ', time.time() - t, 's')\n",
    "print('\\n')\n",
    "\n",
    "plot_slim(Qs,k,l,pars_est,idx_a,idx_b,traces,mmap,data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# settings for fitting algorithm\n",
    "batch_size, max_zip_size, max_iter = 100, 10, 100\n",
    "a, b1, b2, e = 0.0001, 0.9, 0.99, 1e-8\n",
    "a_R = 0.0001\n",
    "\n",
    "t = time.time()\n",
    "_, pars_est, traces = run_bad(k=k,l=l,n=n,y=y, Qs=Qs,Om=Om,idx_a=idx_a, idx_b=idx_b,\n",
    "                                      sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                                      obs_pops=obs_pops,obs_time=obs_time,\n",
    "                                      linearity=linearity,stable=stable,init=pars_est,\n",
    "                                      alpha=a,alpha_R=a_R,b1=b1,b2=b2,e=e,max_iter=max_iter,batch_size=batch_size,\n",
    "                                      verbose=verbose, sym_psd=sym_psd, max_zip_size=max_zip_size)\n",
    "\n",
    "print('fitting time was ', time.time() - t, 's')\n",
    "print('\\n')\n",
    "\n",
    "plot_slim(Qs,k,l,pars_est,idx_a,idx_b,traces,mmap,data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for m in range(1):\n",
    "    print('computing time-lagged covariance for lag ', str(m))\n",
    "    \n",
    "    Qf = np.empty((pa,pb))\n",
    "    Qf[:] = np.cov(y[m:m-(k+l),idx_a].T, y[:-(k+l),idx_b].T)[:pa,pa:]    \n",
    "    \n",
    "    Q = np.empty((pa,pb))\n",
    "    Q[:] = (pars_est['C'][idx_a,:].dot(pars_est['X'][:n,:]).dot(pars_est['C'][idx_b,:].T))\n",
    "    plt.plot(Qf[:], Q[:], 'r.')\n",
    "    plt.hold(True)\n",
    "    plt.title('corr. est. us:' + str(np.corrcoef(Qf.reshape(-1), Q.reshape(-1))[0,1]))\n",
    "    \n",
    "    Q = np.empty((pa,pb))\n",
    "    Q[:] = (pars_pca['C'][idx_a,:].dot(pars_pca['Pi']).dot(pars_pca['C'][idx_b,:].T))\n",
    "    plt.plot(Qf[:], Q[:], 'b.')\n",
    "    \n",
    "    plt.xlabel('corr. est. PCA:' + str(np.corrcoef(Qf.reshape(-1), Q.reshape(-1))[0,1]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "savemat('../fits/'+'parameters', {'pars' : pars,\n",
    "                                 'pars_est_full':pars_est,\n",
    "                                 'pars_est_partial':{}, \n",
    "                                 'pars_pca':pars_pca})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.zeros(((k+l)*n,n))\n",
    "for m in range(k+l):\n",
    "    X[m*n:(m+1)*n,:] = np.cov(x[m:m-(k+l),:].T, x[:-(k+l),:].T)[:n,n:]\n",
    "\n",
    "pars_true= { 'C': pars['C'],\n",
    "             'X': X,\n",
    "             'R': pars['R']}\n",
    "# settings for fitting algorithm\n",
    "batch_size, max_zip_size, max_iter = 1, 100, 1000\n",
    "a, b1, b2, e = 0.0001, 0.9, 0.99, 1e-8\n",
    "a_R = 0.0001\n",
    "linearity, stable, sym_psd = 'False', False, False\n",
    "\n",
    "# create subpopulations\n",
    "sub_pops = (np.arange(0,p), np.arange(0,p))\n",
    "\n",
    "obs_idx, idx_grp, co_obs, _, _, _, Om, _, _ = \\\n",
    "    get_subpop_stats(sub_pops=sub_pops, p=p, verbose=False)\n",
    "\n",
    "pars_init='default'        \n",
    "t = time.time()\n",
    "_, pars_est, traces = run_bad(k=k,l=l,n=n,y=y, Qs=Qs,Om=Om,idx_a=idx_a, idx_b=idx_b,\n",
    "                                      sub_pops=sub_pops,idx_grp=idx_grp,co_obs=co_obs,obs_idx=obs_idx,\n",
    "                                      linearity=linearity,stable=stable,init=pars_true,\n",
    "                                      alpha=a,alpha_R=a_R,b1=b1,b2=b2,e=e,max_iter=max_iter,batch_size=batch_size,\n",
    "                                      verbose=verbose, sym_psd=sym_psd, max_zip_size=max_zip_size)\n",
    "\n",
    "print('fitting time was ', time.time() - t, 's')\n",
    "print('\\n')\n",
    "print(psutil.virtual_memory())\n",
    "print(psutil.swap_memory())\n",
    "\n",
    "plot_slim(Qs,k,l,pars_est,idx_a,idx_b,traces,mmap,data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Wong and Wang's dynamics\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{d s_i}{dt} = - \\frac{s_i}{\\tau_s} + (1 - s_i) \\gamma H_i \\\\\n",
    "H_i = \\frac{a x_i -b}{1 - \\exp(-d(a x_i -b))} \\\\\n",
    "x_1 = J_{N,11}s_1 - J_{N,12} s_2 + I_0 + I_1 \\\\\n",
    "x_2 = J_{N,22}s_2 - J_{N,21} s_1 + I_0 + I_2 \\\\\n",
    "I_i = J_{A,ext} \\mu_0 (1 \\pm c)\n",
    "\\end{align}\n",
    "Parameters: \n",
    "- $i \\in \\{1,2 \\}$, \n",
    "- $a = 270 (VnC)^{-1}$, \n",
    "- $b = 108 Hz$,\n",
    "- $d = 0.154s$, \n",
    "- $\\gamma = 0.641$, \n",
    "- $\\tau_s = 100ms$, \n",
    "- $J_{N,11} = J_{N,22} =  0.2608 nA$,\n",
    "- $J_{N,12} = J_{N,21} =  0.0497 nA$,\n",
    "- $J_{A,ext} = 0.00052 nA \\cdot{} Hz^{-1}$,\n",
    "- $\\mu_0 = 30 Hz$\n",
    "\n",
    "Remarks: marginally useful, as beset with strong attractors, preventing arbitrary simulation lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os, psutil, time\n",
    "\n",
    "p,n,m,T = 1000,2,2,1000\n",
    "k,l =  3,3\n",
    "pars = {}\n",
    "\n",
    "# I/O matter\n",
    "mmap, chunksize = True, np.min((2*T,10000))\n",
    "#data_path, save_file = '/media/marcel/636f7b46-1fd1-4600-b69e-86d2ed82002c/stitching/hankel/', 'test'\n",
    "data_path, save_file = '../fits/', 'test'\n",
    "pa, pb = np.min((p, 1000)), np.min((p, 1000))\n",
    "idx_a, idx_b = np.sort(np.random.choice(p,pa,replace=False)), np.sort(np.random.choice(p,pb,replace=False))\n",
    "verbose=True\n",
    "\n",
    "# experimental parameters\n",
    "I0 = 0\n",
    "c = 0\n",
    "\n",
    "# model parameters\n",
    "pars = {}\n",
    "pars['a'] = 270. * 10e9 # (VnC)^{-1} \n",
    "pars['b'] = 108. # Hz\n",
    "pars['d'] = 0.154 # s \n",
    "pars['gamma'] = 0.641\n",
    "pars['tau'] = 0.1 # s\n",
    "pars['J'] = np.array([[0.2608,-0.0497],[-0.0497,0.2608]]) * 10e-9 # nA\n",
    "pars['J_ext'] = 0.00052  * 10e-9 # nA Hz^{-1}\n",
    "pars['mu'] = 30. # Hz\n",
    "pars['I'] = pars['J_ext'] * pars['mu'] * (1 + np.array([1,-1]) * c)\n",
    "\n",
    "# functions\n",
    "def H(x):\n",
    "    return (pars['a']*x-pars['b']) / (1-np.exp(-pars['d']*(pars['a']*x-pars['b'])))\n",
    "def x(s):\n",
    "    return pars['J'].dot(s) + pars['I'] + I0\n",
    "    \n",
    "# diff. eq.\n",
    "def dsdt(s,t):\n",
    "    return -s/pars['tau'] + (1-s)*pars['gamma']*H(x(s))\n",
    "\n",
    "ts = np.linspace(0,10, 1000)\n",
    "s0 = np.zeros(2)\n",
    "N = 30\n",
    "S1, S2 = np.meshgrid(np.linspace(0,1,N), np.linspace(0,1,N))\n",
    "dS1, dS2 = np.zeros((N,N)), np.zeros((N,N))\n",
    "\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        tmp = dsdt(np.array((S1[i,j], S2[i,j])),0)\n",
    "        dS1[i,j], dS2[i,j] = tmp[0], tmp[1]\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.quiver(S1, S2, dS1, dS2, \n",
    "           edgecolor='k', linewidth=.5)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
