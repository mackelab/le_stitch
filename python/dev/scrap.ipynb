{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gen toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os, psutil, time\n",
    "\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl\n",
    "from ssidid.utility import get_subpop_stats, gen_data\n",
    "from ssidid import ObservationScheme\n",
    "from subtracking import Grouse, calc_subspace_proj_error\n",
    "\n",
    "# define problem size\n",
    "lag_range = np.arange(0,10)\n",
    "kl_ = np.max(lag_range)+1\n",
    "p, n, T = 100, 10, 1000 + kl_\n",
    "\n",
    "nr = 0 # number of real eigenvalues\n",
    "snr = (1.0, 1.0)\n",
    "whiten = True\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.9, 0.95, 0.90, 0.95\n",
    "\n",
    "print('(p,n,k+l,T) = ', (p,n,len(lag_range),T), '\\n')\n",
    "\n",
    "# I/O matter\n",
    "mmap, chunksize = False, np.min((p,2000))\n",
    "verbose=True\n",
    "\n",
    "# create subpopulations\n",
    "num_pops, reps = 3, 5\n",
    "sub_pops = [np.arange(i*p//num_pops, (i+1)*p//num_pops) for i in range(num_pops)]\n",
    "obs_pops = np.concatenate([ np.arange(len(sub_pops)) for r in range(reps) ])\n",
    "obs_time = np.linspace(0,T, len(obs_pops)+1)[1:].astype(int)\n",
    "\n",
    "obs_scheme = ObservationScheme(p=p, T=T, \n",
    "                                sub_pops=sub_pops, \n",
    "                                obs_pops=obs_pops, \n",
    "                                obs_time=obs_time)\n",
    "obs_scheme.comp_subpop_stats()\n",
    "\n",
    "missing_at_random, frac_obs = False, 0.5\n",
    "if missing_at_random:\n",
    "    n_obs = np.ceil(p * frac_obs)\n",
    "    mask = np.zeros((T,p))\n",
    "    for t in range(T):\n",
    "        for i in range(len(obs_time)):\n",
    "            if t < obs_time[i]:\n",
    "                mask[t, np.random.choice(p, n_obs, replace=False)] = 1\n",
    "                #mask[t,sub_pops[obs_pops[i]]] = 1\n",
    "                break                       \n",
    "    obs_scheme.mask = mask\n",
    "else:\n",
    "    obs_scheme.gen_mask_from_scheme()\n",
    "    obs_scheme.use_mask = False\n",
    "    \n",
    "get_observed = obs_scheme.gen_get_observed()\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(obs_scheme.mask.T, interpolation='None')\n",
    "plt.grid('off')\n",
    "plt.show()\n",
    "\n",
    "# draw system matrices / data\n",
    "data_path = '/home/mackelab/Desktop/Projects/Stitching/code/le_stitch/python/fits/compare_vs_grouse/'\n",
    "pars_true, x, y, Qs, idx_a, idx_b = gen_data(p,n,lag_range,T, nr,\n",
    "                                             eig_m_r, eig_M_r, \n",
    "                                             eig_m_c, eig_M_c,\n",
    "                                             mmap, chunksize,\n",
    "                                             data_path,\n",
    "                                             snr=snr, whiten=whiten)    \n",
    "pars_true['X'] = np.vstack([np.cov(x[m_:T-kl_+m_].T,x[:T-kl_].T)[:n,n:] for m_ in lag_range])\n",
    "\n",
    "y[obs_scheme.mask==0] = np.nan\n",
    "y -= np.nanmean(y, axis=0)\n",
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(x[:np.min((T,200)),:])\n",
    "plt.show()\n",
    "    \n",
    "pars_est = 'default'\n",
    "pars_true['X'] = np.vstack([np.cov(x[m_:T-kl_+m_].T,x[:T-kl_].T)[:n,n:] for m_ in lag_range])\n",
    "\n",
    "W = [np.zeros((p,p), dtype=int) for m in lag_range]\n",
    "for m in range(len(lag_range)):\n",
    "    m_ = lag_range[m]\n",
    "    for t in range(T-kl_):\n",
    "        a, b = get_observed(t+m_), get_observed(t)\n",
    "        W[m][np.ix_(a,b)] += 1\n",
    "    W[m] = 1./np.maximum(W[m]-1, 1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy import linalg as la\n",
    "\n",
    "parametrization='nl'\n",
    "\n",
    "# settings for quick initial SGD fitting phase for our model\n",
    "batch_size, max_zip_size, max_iter = 1, np.inf, 10\n",
    "a, b1, b2, e = 0.005, 0.9, 0.99, 1e-8\n",
    "a_R = 1 * a\n",
    "\n",
    "proj_errors = np.zeros((max_iter,n+1))\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "    \n",
    "\n",
    "def pars_track(pars,t): \n",
    "    C = pars[0]\n",
    "    proj_errors[t] = np.hstack((calc_subspace_proj_error(pars_true['C'], C), \n",
    "                                principal_angle(pars_true['C'], C)))\n",
    "        \n",
    "    \n",
    "t = time.time()\n",
    "_, pars_est, traces = run_bad(lag_range=lag_range,n=n,y=y, Qs=Qs,idx_a=idx_a, idx_b=idx_b,\n",
    "                                      obs_scheme=obs_scheme,init=pars_est,parametrization=parametrization,\n",
    "                                      alpha=a,b1=b1,b2=b2,e=e,max_iter=max_iter,\n",
    "                                      batch_size=batch_size,verbose=verbose, max_epoch_size=max_zip_size,\n",
    "                                      pars_track=pars_track, W=W)\n",
    "\n",
    "t = time.time() - t\n",
    "print_slim(Qs,lag_range,pars_est,idx_a,idx_b,traces,mmap,data_path)\n",
    "print('fitting time was ', t, 's')\n",
    "print('rank of final C_est: ', sp.linalg.orth(pars_est['C']).shape[1])\n",
    "print('ground-truth error: ', f_l2_Hankel_nl(C=pars_true['C'],\n",
    "               X=np.vstack([np.cov(x[k_:-(kl_+1)+k_, :].T, x[:-(kl_+1), :].T)[:n,n:] for k_ in lag_range]),\n",
    "               R=pars_true['R'],lag_range=lag_range,y=y,ts=np.arange(T-kl_), ms = range(len(lag_range)),\n",
    "               idx_a=idx_a,idx_b=idx_b,W=W,get_observed=get_observed))\n",
    "\n",
    "print('final error (est.): ', traces[0][-1])\n",
    "print('final proj. error (est.): ', str(calc_subspace_proj_error(pars_true['C'], pars_est['C'])))\n",
    "\n",
    "\n",
    "plt.plot(proj_errors[:,1:])\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import linalg as la\n",
    "\n",
    "parametrization='ln'\n",
    "\n",
    "# settings for quick initial SGD fitting phase for our model\n",
    "batch_size, max_zip_size, max_iter = 10, np.inf, 20\n",
    "a, b1, b2, e = 0.005, 0.9, 0.99, 1e-8\n",
    "a_R = 1 * a\n",
    "\n",
    "proj_errors = np.zeros((max_iter,n+1))\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "    \n",
    "\n",
    "def pars_track(pars,t): \n",
    "    C = pars[0]\n",
    "    proj_errors[t] = np.hstack((calc_subspace_proj_error(pars_true['C'], C), \n",
    "                                principal_angle(pars_true['C'], C)))\n",
    "        \n",
    "    \n",
    "t = time.time()\n",
    "_, pars_est, traces = run_bad(lag_range=lag_range,n=n,y=y, Qs=Qs,idx_a=idx_a, idx_b=idx_b,\n",
    "                                      obs_scheme=obs_scheme,init=pars_est,parametrization=parametrization,\n",
    "                                      alpha=a,b1=b1,b2=b2,e=e,max_iter=max_iter,\n",
    "                                      batch_size=batch_size,verbose=verbose, max_epoch_size=max_zip_size,\n",
    "                                      pars_track=pars_track, W=W)\n",
    "\n",
    "t = time.time() - t\n",
    "print_slim(Qs,lag_range,pars_est,idx_a,idx_b,traces,mmap,data_path)\n",
    "print('fitting time was ', t, 's')\n",
    "print('rank of final C_est: ', sp.linalg.orth(pars_est['C']).shape[1])\n",
    "print('ground-truth error: ', f_l2_Hankel_nl(C=pars_true['C'],\n",
    "               X=np.vstack([np.cov(x[k_:-(kl_+1)+k_, :].T, x[:-(kl_+1), :].T)[:n,n:] for k_ in lag_range]),\n",
    "               R=pars_true['R'],lag_range=lag_range,y=y,ts=np.arange(T-kl_), ms = range(len(lag_range)),\n",
    "               idx_a=idx_a,idx_b=idx_b,W=W,get_observed=get_observed))\n",
    "\n",
    "print('final error (est.): ', traces[0][-1])\n",
    "print('final proj. error (est.): ', str(calc_subspace_proj_error(pars_true['C'], pars_est['C'])))\n",
    "\n",
    "\n",
    "plt.plot(proj_errors[:,1:])\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import linalg as la\n",
    "\n",
    "parametrization='ln'\n",
    "\n",
    "# settings for quick initial SGD fitting phase for our model\n",
    "batch_size, max_zip_size, max_iter = 100, np.inf, 10\n",
    "a, b1, b2, e = 0.005, 0.9, 0.99, 1e-8\n",
    "a_R = 1 * a\n",
    "\n",
    "proj_errors = np.zeros((max_iter,n+1))\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "    \n",
    "\n",
    "def pars_track(pars,t): \n",
    "    C = pars[0]\n",
    "    proj_errors[t] = np.hstack((calc_subspace_proj_error(pars_true['C'], C), \n",
    "                                principal_angle(pars_true['C'], C)))\n",
    "        \n",
    "    \n",
    "t = time.time()\n",
    "_, pars_est, traces = run_bad(lag_range=lag_range,n=n,y=y, Qs=Qs,idx_a=idx_a, idx_b=idx_b,\n",
    "                                      obs_scheme=obs_scheme,init=pars_est,parametrization=parametrization,\n",
    "                                      alpha=a,b1=b1,b2=b2,e=e,max_iter=max_iter,\n",
    "                                      batch_size=batch_size,verbose=verbose, max_epoch_size=max_zip_size,\n",
    "                                      pars_track=pars_track, W=W)\n",
    "\n",
    "t = time.time() - t\n",
    "print_slim(Qs,lag_range,pars_est,idx_a,idx_b,traces,mmap,data_path)\n",
    "print('fitting time was ', t, 's')\n",
    "print('rank of final C_est: ', sp.linalg.orth(pars_est['C']).shape[1])\n",
    "print('ground-truth error: ', f_l2_Hankel_nl(C=pars_true['C'],\n",
    "               X=np.vstack([np.cov(x[k_:-(kl_+1)+k_, :].T, x[:-(kl_+1), :].T)[:n,n:] for k_ in lag_range]),\n",
    "               R=pars_true['R'],lag_range=lag_range,y=y,ts=np.arange(T-kl_), ms = range(len(lag_range)),\n",
    "               idx_a=idx_a,idx_b=idx_b,W=W,get_observed=get_observed))\n",
    "\n",
    "print('final error (est.): ', traces[0][-1])\n",
    "print('final proj. error (est.): ', str(calc_subspace_proj_error(pars_true['C'], pars_est['C'])))\n",
    "\n",
    "\n",
    "plt.plot(proj_errors[:,1:])\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import linalg as la\n",
    "\n",
    "parametrization='nl'\n",
    "\n",
    "# settings for quick initial SGD fitting phase for our model\n",
    "batch_size, max_zip_size, max_iter = 100, np.inf, 100\n",
    "a, b1, b2, e = 0.001, 0.9, 0.99, 1e-8\n",
    "a_R = 1 * a\n",
    "\n",
    "proj_errors = np.zeros((max_iter,n+1))\n",
    "def principal_angle(A, B):\n",
    "    \"A and B must be column-orthogonal.\"    \n",
    "    A = np.atleast_2d(A).T if (A.ndim<2) else A\n",
    "    B = np.atleast_2d(B).T if (B.ndim<2) else B\n",
    "    A = la.orth(A)\n",
    "    B = la.orth(B)\n",
    "    svd = la.svd(A.T.dot(B))\n",
    "    return np.arccos(np.minimum(svd[1], 1.0)) / (np.pi/2)\n",
    "    \n",
    "\n",
    "def pars_track(pars,t): \n",
    "    C = pars[0]\n",
    "    proj_errors[t] = np.hstack((calc_subspace_proj_error(pars_true['C'], C), \n",
    "                                principal_angle(pars_true['C'], C)))\n",
    "        \n",
    "    \n",
    "t = time.time()\n",
    "_, pars_est, traces = run_bad(lag_range=lag_range,n=n,y=y, Qs=Qs,idx_a=idx_a, idx_b=idx_b,\n",
    "                                      obs_scheme=obs_scheme,init=pars_est,parametrization=parametrization,\n",
    "                                      alpha=a,b1=b1,b2=b2,e=e,max_iter=max_iter,\n",
    "                                      batch_size=batch_size,verbose=verbose, max_epoch_size=max_zip_size,\n",
    "                                      pars_track=pars_track, W=W)\n",
    "\n",
    "t = time.time() - t\n",
    "print_slim(Qs,lag_range,pars_est,idx_a,idx_b,traces,mmap,data_path)\n",
    "print('fitting time was ', t, 's')\n",
    "print('rank of final C_est: ', sp.linalg.orth(pars_est['C']).shape[1])\n",
    "print('ground-truth error: ', f_l2_Hankel_nl(C=pars_true['C'],\n",
    "               X=np.vstack([np.cov(x[k_:-(kl_+1)+k_, :].T, x[:-(kl_+1), :].T)[:n,n:] for k_ in lag_range]),\n",
    "               R=pars_true['R'],lag_range=lag_range,y=y,ts=np.arange(T-kl_), ms = range(len(lag_range)),\n",
    "               idx_a=idx_a,idx_b=idx_b,W=W,get_observed=get_observed))\n",
    "\n",
    "print('final error (est.): ', traces[0][-1])\n",
    "print('final proj. error (est.): ', str(calc_subspace_proj_error(pars_true['C'], pars_est['C'])))\n",
    "\n",
    "\n",
    "plt.plot(proj_errors[:,1:])\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# settings for GROUSE\n",
    "a_grouse = 0.0001\n",
    "#tracker = Grouse(p, n, a_grouse )\n",
    "max_iter_grouse = 50\n",
    "\n",
    "# fit GROUSE\n",
    "t = time.time()\n",
    "print('\\n - GROUSE')\n",
    "tracker.step = a_grouse\n",
    "ct = 1.\n",
    "error = np.zeros((max_iter_grouse, n+1))\n",
    "for i in range(max_iter_grouse):\n",
    "    if verbose and np.mod(i,max_iter_grouse//10) == 0:\n",
    "        print('finished % ' + str((100*i)//max_iter_grouse))\n",
    "    idx = np.random.permutation(T-np.max(lag_range)-1)\n",
    "    for j in range(len(idx)):\n",
    "        tracker.consume(y[idx[j],:].reshape(p,1), mask[idx[j],:].reshape(p,1))\n",
    "    tracker.step = a_grouse / ct\n",
    "    ct += 1\n",
    "\n",
    "    error[i] = np.hstack((calc_subspace_proj_error(pars_true['C'], tracker.U), principal_angle(pars_true['C'], tracker.U)))\n",
    "pars_est_g = {'C' : tracker.U}\n",
    "\n",
    "print('final proj. error (est.): ', str(error[-1][0]))\n",
    "\n",
    "plt.plot(error[:,1:])\n",
    "plt.title('subspace proj. error (GROUSE)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cython in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "cdef int a = 0\n",
    "for i in range(10):\n",
    "    a += i\n",
    "print a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "from libc.math cimport log, sqrt\n",
    "from numpy.math cimport INFINITY, PI\n",
    "\n",
    "from scipy.linalg.cython_blas cimport dsymm, dcopy, dgemm, dgemv, daxpy, dsyrk, \\\n",
    "    dtrmv, dger, dnrm2, ddot\n",
    "from scipy.linalg.cython_lapack cimport dpotrf, dpotrs, dpotri, dtrtrs\n",
    "from cyutil cimport copy_transpose, copy_upper_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pars_est_uw = 'default'\n",
    "W_uw = [1/(T-1) * np.ones((p,p), dtype=int) for m in lag_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_rw = f_l2_Hankel_nl(C=pars_est_rw['C'],\n",
    "               X=pars_est_rw['X'],\n",
    "               R=pars_est_rw['R'],\n",
    "               lag_range=lag_range,y=y,ts=np.arange(T-kl_), ms = range(len(lag_range)),\n",
    "               idx_a=idx_a,idx_b=idx_b,W=W,get_observed=get_observed)\n",
    "f_uw = f_l2_Hankel_nl(C=pars_est_uw['C'],\n",
    "               X=pars_est_uw['X'],\n",
    "               R=pars_est_uw['R'],\n",
    "               lag_range=lag_range,y=y,ts=np.arange(T-kl_), ms = range(len(lag_range)),\n",
    "               idx_a=idx_a,idx_b=idx_b,W=W,get_observed=get_observed)\n",
    "f_gt =  f_l2_Hankel_nl(C=pars_true['C'],\n",
    "               X=pars_true['X'],\n",
    "               R=pars_true['R'],lag_range=lag_range,y=y,ts=np.arange(T-kl_), ms = range(len(lag_range)),\n",
    "               idx_a=idx_a,idx_b=idx_b,W=W,get_observed=get_observed)\n",
    "f_rw, f_uw, f_gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check fits / analytics / figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C = pars_true['C']\n",
    "\n",
    "plt.imshow(np.hstack(( C.dot(pars_true['X'][:n,:]).dot(C.T), C.dot(np.cov(x.T)).dot(C.T))), interpolation='None')\n",
    "plt.show()\n",
    "\n",
    "# fully observed, no noise\n",
    "ynn = x.dot(pars_true['C'].T)\n",
    "ynn -= ynn[:T-kl_,:].mean(axis=0).reshape(1,-1)\n",
    "\n",
    "def get_observed(t):\n",
    "    return np.arange(p)\n",
    "\n",
    "W = [np.zeros((p,p), dtype=int) for m in lag_range]\n",
    "S  = [np.zeros((p,p)) for m in range(len(lag_range))]\n",
    "for m in range(len(lag_range)):\n",
    "    m_ = lag_range[m]\n",
    "    for t in range(T-kl_):\n",
    "        a, b = get_observed(t+m_), get_observed(t)\n",
    "        W[m][np.ix_(a,b)] += 1\n",
    "        S[m][np.ix_(a,b)] += np.outer(ynn[t+m_,a], ynn[t,b])\n",
    "    W[m] = 1./np.maximum(W[m]-1, 1)\n",
    "    \n",
    "plt.plot(C.dot(np.cov(x[:T-kl_].T)).dot(C.T).reshape(-1), (S[0] * W[0]).reshape(-1), '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lag_range = [0]\n",
    "\n",
    "# fully observed, no noise\n",
    "ynn = x.dot(pars_true['C'].T)\n",
    "ynn -= ynn[:T-kl_,:].mean(axis=0).reshape(1,-1)\n",
    "\n",
    "def get_observed(t):\n",
    "    return np.arange(p)\n",
    "\n",
    "W = [np.zeros((p,p), dtype=int) for m in lag_range]\n",
    "S  = [np.zeros((p,p)) for m in range(len(lag_range))]\n",
    "for m in range(len(lag_range)):\n",
    "    m_ = lag_range[m]\n",
    "    for t in range(T-kl_):\n",
    "        a, b = get_observed(t+m_), get_observed(t)\n",
    "        W[m][np.ix_(a,b)] += 1\n",
    "        S[m][np.ix_(a,b)] += np.outer(ynn[t+m_,a], ynn[t,b])\n",
    "    W[m] = 1./np.maximum(W[m]-1, 1)\n",
    "\n",
    "for m in range(len(lag_range)):\n",
    "    \n",
    "    Q_pred = pars_true['C'].dot(pars_true['X'][m*n:(m+1)*n,:]).dot(pars_true['C'].T)\n",
    "    if lag_range[m] == 0:\n",
    "        Q_pred += np.diag( pars_true['R'] )\n",
    "    Q_emp  = S[m] * W[m]\n",
    "    \n",
    "    #plt.figure(figsize=(16,7))\n",
    "    #plt.subplot(1,2,1)\n",
    "    #plt.imshow(np.hstack((Q_pred, Q_emp)),\n",
    "    #           interpolation='None')\n",
    "    #plt.title('fully observed, no emission noise')\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(20,4))\n",
    "    \n",
    "    plt.subplot(1,5,1)\n",
    "    plt.imshow(S[m] * W[m], interpolation='None')\n",
    "    plt.title('model-predicted covariances')\n",
    "    \n",
    "    plt.subplot(1,5,2)\n",
    "    plt.plot(Q_pred.reshape(-1),Q_emp.reshape(-1),'.')\n",
    "    plt.xlabel('predicted covs.')\n",
    "    plt.ylabel('emp. covs.')\n",
    "    plt.title('fully obs., no emission noise')\n",
    "    \n",
    "    #plt.show()\n",
    "\n",
    "    Q_pred.reshape(-1)-Q_emp.reshape(-1)\n",
    "\n",
    "\n",
    "\n",
    "# fully observed + noise\n",
    "\n",
    "def get_observed(t):\n",
    "    return np.arange(p)\n",
    "\n",
    "W = [np.zeros((p,p), dtype=int) for m in lag_range]\n",
    "S  = [np.zeros((p,p)) for m in range(len(lag_range))]\n",
    "for m in range(len(lag_range)):\n",
    "    m_ = lag_range[m]\n",
    "    for t in range(T-kl_):\n",
    "        a, b = get_observed(t+m_), get_observed(t)\n",
    "        W[m][np.ix_(a,b)] += 1\n",
    "        S[m][np.ix_(a,b)] += np.outer(y[t+m_,a], y[t,b])\n",
    "    W[m] = 1./np.maximum(W[m]-1, 1)\n",
    "\n",
    "for m in range(len(lag_range)):\n",
    "    \n",
    "    Q_pred = pars_true['C'].dot(pars_true['X'][m*n:(m+1)*n,:]).dot(pars_true['C'].T)\n",
    "    if lag_range[m] == 0:\n",
    "        Q_pred += np.diag( pars_true['R'] )\n",
    "    Q_emp  = S[m] * W[m]\n",
    "    \n",
    "    #plt.figure(figsize=(16,7))\n",
    "    #plt.subplot(1,2,1)\n",
    "    #plt.imshow(np.hstack((Q_pred, Q_emp)),\n",
    "    #           interpolation='None')\n",
    "    #plt.title('fully observed, with (little) emission noise')\n",
    "\n",
    "    plt.subplot(1,5,3)\n",
    "    plt.plot(Q_pred.reshape(-1),Q_emp.reshape(-1),'.')\n",
    "    plt.xlabel('predicted covs.')\n",
    "    #plt.ylabel('emp. covs.')\n",
    "    plt.title('fully obs., with emission noise')\n",
    "    \n",
    "    #plt.show()\n",
    "\n",
    "    Q_pred.reshape(-1)-Q_emp.reshape(-1)\n",
    "    \n",
    "\n",
    "\n",
    "# partially observed, no noise    \n",
    "    \n",
    "def get_observed(t):\n",
    "    return np.where(obs_scheme.mask[t,:])[0]\n",
    "W = [np.zeros((p,p), dtype=int) for m in lag_range]\n",
    "S  = [np.zeros((p,p)) for m in range(len(lag_range))]\n",
    "for m in range(len(lag_range)):\n",
    "    m_ = lag_range[m]\n",
    "    for t in range(T-kl_):\n",
    "        a, b = get_observed(t+m_), get_observed(t)\n",
    "        W[m][np.ix_(a,b)] += 1\n",
    "        S[m][np.ix_(a,b)] += np.outer(ynn[t+m_,a], ynn[t,b])\n",
    "    W[m] = 1./np.maximum(W[m]-1, 1)\n",
    "    \n",
    "for m in range(len(lag_range)):\n",
    "    \n",
    "    Q_pred = pars_true['C'].dot(pars_true['X'][m*n:(m+1)*n,:]).dot(pars_true['C'].T)\n",
    "    if lag_range[m] == 0:\n",
    "        Q_pred += np.diag( pars_true['R'] )\n",
    "    Q_emp  = S[m] * W[m]\n",
    "    \n",
    "    #plt.figure(figsize=(16,7))\n",
    "    #plt.subplot(1,2,1)\n",
    "    #plt.imshow(np.hstack((Q_pred, Q_emp)),\n",
    "    #           interpolation='None')\n",
    "    #plt.title('50% missing data, no emission noise')\n",
    "\n",
    "    plt.subplot(1,5,4)\n",
    "    plt.plot(Q_pred.reshape(-1),Q_emp.reshape(-1),'.')\n",
    "    plt.xlabel('predicted covs.')\n",
    "    #plt.ylabel('emp. covs.')\n",
    "    plt.title('50% missing, no emission noise')\n",
    "\n",
    "    #plt.show()\n",
    "\n",
    "    Q_pred.reshape(-1)-Q_emp.reshape(-1)    \n",
    "    \n",
    "\n",
    "# partially observed + noise    \n",
    "    \n",
    "def get_observed(t):\n",
    "    return np.where(obs_scheme.mask[t,:])[0]\n",
    "W = [np.zeros((p,p), dtype=int) for m in lag_range]\n",
    "S  = [np.zeros((p,p)) for m in range(len(lag_range))]\n",
    "for m in range(len(lag_range)):\n",
    "    m_ = lag_range[m]\n",
    "    for t in range(T-kl_):\n",
    "        a, b = get_observed(t+m_), get_observed(t)\n",
    "        W[m][np.ix_(a,b)] += 1\n",
    "        S[m][np.ix_(a,b)] += np.outer(y[t+m_,a], y[t,b])\n",
    "    W[m] = 1./np.maximum(W[m]-1, 1)\n",
    "\n",
    "for m in range(len(lag_range)):\n",
    "    \n",
    "    Q_pred = pars_true['C'].dot(pars_true['X'][m*n:(m+1)*n,:]).dot(pars_true['C'].T)\n",
    "    if lag_range[m] == 0:\n",
    "        Q_pred += np.diag( pars_true['R'] )\n",
    "    Q_emp  = S[m] * W[m]\n",
    "    \n",
    "    #plt.figure(figsize=(16,7))\n",
    "    #plt.subplot(1,2,1)\n",
    "    #plt.imshow(np.hstack((Q_pred, Q_emp)),\n",
    "    #           interpolation='None')\n",
    "    #plt.title('50% missing data, with (little) emission noise')\n",
    "\n",
    "    plt.subplot(1,5,5)\n",
    "    plt.plot(Q_pred.reshape(-1),Q_emp.reshape(-1),'.')\n",
    "    plt.xlabel('predicted covs.')\n",
    "    #plt.ylabel('emp. covs.')\n",
    "    plt.title('50% missing, with emission noise')\n",
    "\n",
    "    plt.savefig(data_path + 'missing_data_adds_noise.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    Q_pred.reshape(-1)-Q_emp.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn\n",
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(mask[:p].T)\n",
    "plt.title('observation scheme (snippet)')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('# neuron')\n",
    "plt.subplot(1,4,1).grid(False)\n",
    "\n",
    "for m in range(len(lag_range)): \n",
    "    plt.subplot(1,4,m+2)\n",
    "    plt.imshow(1/W[m]+1, interpolation='None')\n",
    "    plt.colorbar()\n",
    "    plt.title('co-occurence counts, lag m = ' + str(m))\n",
    "    plt.subplot(1,4,m+2).grid(False)\n",
    "    plt.subplot(1,4,m+2).axis('off')\n",
    "plt.savefig(data_path + 'data_missing_at_random__reweighting.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(mask[:p].T)\n",
    "plt.title('observation scheme')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('# neuron')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(x[:p,:])\n",
    "plt.title('latent dynamics')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('latent variable x_i')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "corrs = np.array(\n",
    "[0.971037141558,0.96987352866\n",
    ",0.969459666115,0.971241432619\n",
    ",0.969665425978,0.969900486984\n",
    ",0.964496673231,0.967837463006\n",
    ",0.96541450383,0.964124749854\n",
    ",0.964842670427,0.964279922032\n",
    ",0.965162323115,0.962361938318\n",
    ",0.950802131672,0.959878055666\n",
    ",0.958265735453,0.947398139818\n",
    ",0.951527010565,0.940876843202])\n",
    "plt.plot(corrs)\n",
    "plt.xlabel('time lag')\n",
    "plt.ylabel('corr.: est. vs. ground-truth covs')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(proj_errors[-1,1:], 'b*', markersize=10)\n",
    "plt.hold(True)\n",
    "plt.plot(error[-1,1:], 'r*', markersize=10)\n",
    "plt.legend(['S^2ID^2', 'GROUSE'])\n",
    "plt.title('principal angles est. vs. true subspace')\n",
    "plt.xlabel('subspace dim. (sorted)')\n",
    "plt.ylabel('angle [radians]')\n",
    "plt.xlim([-0.5, len(error[-1,1:])-0.5])\n",
    "\n",
    "plt.savefig(data_path + 'data_missing_at_random.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = 0 \n",
    "plt.imshow(1 / W[m] + 1, interpolation='None')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yma = np.ma.masked_array(y, mask=np.invert(obs_scheme.mask))\n",
    "\n",
    "plt.imshow(np.ma.cov(yma[:T-kl_].T), interpolation='None')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(S[0] * W[0], interpolation='None')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.ma.cov(yma[:T-kl_].T).reshape(-1), (S[0] * W[0]).reshape(-1))\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(np.ma.cov(yma[:T-kl_].T) - (S[0] * W[0]), interpolation='None')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = '/home/mackelab/Desktop/Projects/Stitching/code/le_stitch/python/fits/'\n",
    "\n",
    "save_dict = {'p' : p,\n",
    "             'n' : n,\n",
    "             'T' : T,\n",
    "             'snr' : snr,\n",
    "             'obs_scheme' : obs_scheme,\n",
    "             'lag_range' : lag_range,\n",
    "             'x' : x,\n",
    "             'y' : y,\n",
    "             'pars_true' : pars_true,\n",
    "             'pars_est_m' : pars_est,\n",
    "             'traces_m' : traces\n",
    "            }\n",
    "file_name = 'p' + str(p) + 'n' + str(n) + 'T' + str(T) + 'snr' + str(np.int(np.mean(snr)//1)) + '_partial_dat'\n",
    "np.savez(data_path + file_name, save_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = [np.zeros((p,p), dtype=int) for m in lag_range]\n",
    "S  = [np.zeros((p,p)) for m in range(len(lag_range))]\n",
    "for m in range(len(lag_range)):\n",
    "    m_ = lag_range[m]\n",
    "    for t in range(T-kl_):\n",
    "        a, b = get_observed(t+m_), get_observed(t)\n",
    "        W[m][np.ix_(a,b)] += 1\n",
    "        S[m][np.ix_(a,b)] += np.outer(y[t+m_,a], y[t,b])\n",
    "    W[m] = 1./np.maximum(W[m], 1)\n",
    "    \n",
    "f, ft = 0., 0.\n",
    "for m in range(len(lag_range)):\n",
    "    plt.figure(figsize=(18,4))\n",
    "\n",
    "    pars = pars_est    \n",
    "    C, Xm, R = pars['C'],pars['X'][m*n:(m+1)*n,:],pars['R']\n",
    "    plt.subplot(1,4,1)\n",
    "    a,b = sub_pops[0], sub_pops[0]\n",
    "    plt.plot(C[a,:].dot(Xm).dot(C[b,:].T) + (m==0)*np.diag(R)[np.ix_(a,b)], S[m][np.ix_(a,b)]*W[m][np.ix_(a,b)], '.')\n",
    "    f += 0.5*np.sum((C[a,:].dot(Xm).dot(C[b,:].T) + (m==0)*np.diag(R)[np.ix_(a,b)] - S[m][np.ix_(a,b)]*W[m][np.ix_(a,b)])**2)\n",
    "    plt.subplot(1,4,2)\n",
    "    #a,b = sub_pops[1], sub_pops[1]\n",
    "    #plt.plot(C[a,:].dot(Xm).dot(C[b,:].T) + (m==0)*np.diag(R)[np.ix_(a,b)], S[m][np.ix_(a,b)]*W[m][np.ix_(a,b)], '.')\n",
    "    #f += 0.5*np.sum((C[a,:].dot(Xm).dot(C[b,:].T) + (m==0)*np.diag(R)[np.ix_(a,b)] - S[m][np.ix_(a,b)]*W[m][np.ix_(a,b)])**2)\n",
    "\n",
    "    pars = pars_true  \n",
    "    C, Xm, R = pars['C'],pars['X'][m*n:(m+1)*n,:],pars['R']\n",
    "    plt.subplot(1,4,3)\n",
    "    a,b = sub_pops[0], sub_pops[0]\n",
    "    plt.plot(C[a,:].dot(Xm).dot(C[b,:].T) + (m==0)*np.diag(R)[np.ix_(a,b)], S[m][np.ix_(a,b)]*W[m][np.ix_(a,b)], '.')\n",
    "    ft += 0.5*np.sum((C[a,:].dot(Xm).dot(C[b,:].T) + (m==0)*np.diag(R)[np.ix_(a,b)] - S[m][np.ix_(a,b)]*W[m][np.ix_(a,b)])**2)\n",
    "    plt.subplot(1,4,4)\n",
    "    #a,b = sub_pops[1], sub_pops[1]\n",
    "    #plt.plot(C[a,:].dot(Xm).dot(C[b,:].T) + (m==0)*np.diag(R)[np.ix_(a,b)], S[m][np.ix_(a,b)]*W[m][np.ix_(a,b)], '.')\n",
    "    #ft += 0.5*np.sum((C[a,:].dot(Xm).dot(C[b,:].T) + (m==0)*np.diag(R)[np.ix_(a,b)] - S[m][np.ix_(a,b)]*W[m][np.ix_(a,b)])**2)\n",
    "\n",
    "    plt.show()\n",
    "print(f, ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ssidid.SSID_Hankel_loss import f_l2_Hankel_nl, g_l2_Hankel_sgd\n",
    "\n",
    "ts1 = np.random.choice(T-kl_, T-kl_, replace=False)\n",
    "msu = np.random.choice(kl_, kl_, replace=False)\n",
    "\n",
    "ms = np.hstack([msu[i] * np.ones_like(ts1) for i in range(len(msu))])\n",
    "ts = np.hstack([ ts1 for i in range(len(msu))])\n",
    "\n",
    "# gen system pars\n",
    "nr = 0\n",
    "nc, nc_u = n - nr, (n - nr)//2\n",
    "Q, D = np.zeros((n,n), dtype=complex), np.zeros(n, dtype=complex)\n",
    "# draw real eigenvalues and eigenvectors\n",
    "D[:nr] = np.linspace(0.8, 0.99, nr)\n",
    "Q[:,:nr] = np.random.normal(size=(n,nr))\n",
    "Q[:,:nr] /= np.sqrt((Q[:,:nr]**2).sum(axis=0)).reshape(1,nr)\n",
    "# draw complex eigenvalues and eigenvectors\n",
    "circs = np.exp(2 * 1j * np.pi * np.random.vonmises(mu=0, kappa=1000, size=nc_u))\n",
    "scales = np.random.uniform(size=nc_u)\n",
    "ev_c_r, ev_c_c = scales * np.real(circs), scales * np.imag(circs)\n",
    "V = np.random.normal(size=(n,n))\n",
    "for i in range(nc_u):\n",
    "    Vi = V[:,i*2:(i+1)*2] / np.sqrt( np.sum(V[:,i*2:(i+1)*2]**2) )\n",
    "    Q[:,nr+i], Q[:,nr+nc_u+i] = Vi[:,0]+1j*Vi[:,1], Vi[:,0]-1j*Vi[:,1] \n",
    "    D[nr+i], D[nr+i+nc_u] = ev_c_r[i]+1j*ev_c_c[i], ev_c_r[i]-1j*ev_c_c[i]\n",
    "\n",
    "A = Q.dot(np.diag(D)).dot(np.linalg.inv(Q))\n",
    "assert np.allclose(A, np.real(A))\n",
    "A = np.real(A)\n",
    "B = np.random.normal(size=(n,n))\n",
    "X, R = np.random.normal(size=(len(lag_range)*n,n)), np.random.normal(size=(p))**2\n",
    "C = np.random.normal(size=(p,n))\n",
    "\n",
    "if not obs_scheme.mask is None:\n",
    "    def get_observed(t):\n",
    "        return np.where(obs_scheme.mask[t,:])[0]\n",
    "elif obs_time is None or obs_pops is None or sub_pops is None:\n",
    "    def get_observed(t):\n",
    "        return range(p) \n",
    "else:\n",
    "    def get_observed(t):\n",
    "        i = obs_pops[np.digitize(t, obs_time)]\n",
    "        return sub_pops[i]\n",
    "\n",
    "t_ij = [np.zeros((p,p), dtype=int) for m in range(len(lag_range))]\n",
    "for i in range(len(ts)):  \n",
    "    t,m = ts[i],ms[i]\n",
    "    m_ = lag_range[m]\n",
    "    a, b = get_observed(t+m_), get_observed(t)\n",
    "    t_ij[ms[i]][np.ix_(a, b)] += 1\n",
    "t_ij = [np.maximum(t_ij[m], 1) for m in range(len(lag_range))]\n",
    "\n",
    "#t_ij = [len(ts1)*np.ones((p,p)) for m in range(len(lag_range))]\n",
    "\n",
    "W = [1./t_ij[m] for m in range(len(lag_range))]\n",
    "\n",
    "# decorating\n",
    "def fC(C):\n",
    "    return f_sg(C,X,R,y, ts, ms, get_observed, W)\n",
    "def fC_ha(C):\n",
    "    return f_ha(C,X,R,y, ts, ms, get_observed, W)\n",
    "def fC_rw(C):\n",
    "    return f_rw(C,X,R,y, ts, ms, get_observed, W)\n",
    "def gC_rw(C):\n",
    "    return g_rw_C(C, X, R, y, ts,ms,get_observed,W)\n",
    "def gC(C):\n",
    "    C = C.reshape(p,n)\n",
    "    grad_C,_,_ = g_l2_Hankel_sgd(C,X,R,y,lag_range,ts1,ms=msu,get_observed=get_observed,linear=False, W=W)\n",
    "    return grad_C.reshape(-1)\n",
    "def fC_impl(C): \n",
    "    C = C.reshape(p,n)    \n",
    "    return f_l2_Hankel_nl(C,X,R, y, lag_range=lag_range, ms=msu, get_observed=get_observed, \n",
    "                          idx_a=np.arange(p), idx_b=np.arange(p), W=W, ts=ts1)\n",
    "\n",
    "def fX(X):\n",
    "    return f_sg(C,X,R, y, ts, ms, get_observed, W)\n",
    "def fX_ha(X):\n",
    "    return f_ha(C,X,R, y, ts, ms, get_observed, W)\n",
    "def fX_rw(X):\n",
    "    return f_rw(C,X,R, y, ts, ms, get_observed, W)\n",
    "def gX_rw(X):\n",
    "    return g_rw_X(C, X, R, y, ts, ms, get_observed, W)\n",
    "def gX(X):\n",
    "    X = X.reshape(len(lag_range)*n,n)\n",
    "    _,grad_X,_ = g_l2_Hankel_sgd(C,X,R,y,lag_range,ts1,msu,get_observed,linear=False, W=W)\n",
    "    return grad_X.reshape(-1)\n",
    "def fX_impl(X): \n",
    "    X = X.reshape(len(lag_range)*n,n)\n",
    "    return f_l2_Hankel_nl(C,X,R, y, lag_range=lag_range, ms=msu, get_observed=get_observed, \n",
    "                          idx_a=np.arange(p), idx_b=np.arange(p), W=W, ts=ts1)\n",
    "\n",
    "\n",
    "def fR(R):\n",
    "    return f_sg(C,X,R, y, ts, ms, get_observed, W)\n",
    "def fR_ha(R):\n",
    "    return f_ha(C,X,R, y, ts, ms, get_observed, W)\n",
    "def fR_rw(R):\n",
    "    return f_rw(C,X,R, y, ts, ms, get_observed, W)\n",
    "def gR_rw(R):\n",
    "    return g_rw_R(C, X, R, y, ts, ms, get_observed, W)\n",
    "def gR(R):\n",
    "    R = R.reshape(p)\n",
    "    _,_,grad_R = g_l2_Hankel_sgd(C,X,R,y,lag_range,ts1,msu,get_observed,linear=False, W=W)\n",
    "    return grad_R.reshape(-1)\n",
    "def fR_impl(R): \n",
    "    R = R.reshape(p)\n",
    "    return f_l2_Hankel_nl(C,X,R, y, lag_range=lag_range, ms=msu, get_observed=get_observed, \n",
    "                          idx_a=np.arange(p), idx_b=np.arange(p), W=W, ts=ts1)\n",
    "\n",
    "\n",
    "def fA(A):\n",
    "    A = A.reshape(n,n)\n",
    "    X = np.vstack([np.linalg.matrix_power(A,m).dot(B.dot(B.T)) for m in range(kl_)])\n",
    "    return f_sg(C,X,R,y, ts, ms, get_observed, W)\n",
    "def fA_ha(A):\n",
    "    A = A.reshape(n,n)\n",
    "    X = np.vstack([np.linalg.matrix_power(A,m).dot(B.dot(B.T)) for m in range(kl_)])\n",
    "    return f_ha(C,X,R,y, ts, ms, get_observed, W)\n",
    "def fA_rw(A):\n",
    "    A = A.reshape(n,n)\n",
    "    X = np.vstack([np.linalg.matrix_power(A,m).dot(B.dot(B.T)) for m in range(kl_)])\n",
    "    return f_rw(C,X,R, y, ts, ms, get_observed, W)\n",
    "def gA_rw(A):\n",
    "    A = A.reshape(n,n)\n",
    "    return g_rw_A(C, A, B.dot(B.T), R, y, ts1, msu, get_observed, W)\n",
    "def gA(A):\n",
    "    A = A.reshape(n,n)\n",
    "    return g_l2_Hankel_A(C, A, B.dot(B.T), R, y, lag_range, ts1, msu, get_observed, W)\n",
    "\n",
    "\n",
    "def fB(B):\n",
    "    B = B.reshape(n,n)\n",
    "    X = np.vstack([np.linalg.matrix_power(A,m).dot(B.dot(B.T)) for m in range(kl_)])\n",
    "    return f_sg(C,X,R,y, ts, ms, get_observed, W)\n",
    "\n",
    "def fB_ha(B):\n",
    "    B = B.reshape(n,n)\n",
    "    X = np.vstack([np.linalg.matrix_power(A,m).dot(B.dot(B.T)) for m in range(kl_)])\n",
    "    return f_ha(C,X,R,y, ts, ms, get_observed, W)\n",
    "\n",
    "def fB_rw(B):\n",
    "    B = B.reshape(n,n)\n",
    "    X = np.vstack([np.linalg.matrix_power(A,m).dot(B.dot(B.T)) for m in range(kl_)])\n",
    "    return f_rw(C,X,R, y, ts, ms, get_observed, W)\n",
    "\n",
    "def gB(B):\n",
    "    Aexpm = np.vstack([np.linalg.matrix_power(A,m) for m in range(kl_)])\n",
    "    B = B.reshape(n,n)\n",
    "    grad_B = g_l2_Hankel_sgd_B(C, B, Aexpm,R,y,lag_range,ts1,msu,get_observed,linear=False, W=W)\n",
    "    return grad_B.reshape(-1)\n",
    "\n",
    "\n",
    "print('m:', np.sort(msu))\n",
    "print('\\n')\n",
    "\n",
    "print('grad C (Pr. Er)', sp.optimize.check_grad(fC,    gC, C.reshape(-1)))\n",
    "print('grad C (Hankel)', sp.optimize.check_grad(fC_ha, gC, C.reshape(-1)))\n",
    "print('grad C (corr. )', sp.optimize.check_grad(fC_rw, gC, C.reshape(-1)))\n",
    "print('grad C (impl. )', sp.optimize.check_grad(fC_impl, gC, C.reshape(-1)))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('grad X (Pr. Er)', sp.optimize.check_grad(fX,    gX, X.reshape(-1)))\n",
    "print('grad X (Hankel)', sp.optimize.check_grad(fX_ha, gX, X.reshape(-1)))\n",
    "print('grad X (corr. )', sp.optimize.check_grad(fX_rw, gX, X.reshape(-1)))\n",
    "print('grad X (impl. )', sp.optimize.check_grad(fX_impl, gX, X.reshape(-1)))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('grad R (Pr. Er)', sp.optimize.check_grad(fR,    gR, R.reshape(-1)))\n",
    "print('grad R (Hankel)', sp.optimize.check_grad(fR_ha, gR, R.reshape(-1)))\n",
    "print('grad R (corr. )', sp.optimize.check_grad(fR_rw, gR, R.reshape(-1)))\n",
    "print('grad R (impl. )', sp.optimize.check_grad(fR_impl, gR, R.reshape(-1)))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('grad A (Pr. Er)', sp.optimize.check_grad(fA,    gA, A.reshape(-1)))\n",
    "print('grad A (Hankel)', sp.optimize.check_grad(fA_ha, gA, A.reshape(-1)))\n",
    "print('grad A (corr. )', sp.optimize.check_grad(fA_rw, gA, A.reshape(-1)))\n",
    "#print('grad A (impl. )', sp.optimize.check_grad(fA_impl, gA, A.reshape(-1)))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('grad B (Pr. Er)', sp.optimize.check_grad(fB,    gB, B.reshape(-1)))\n",
    "print('grad B (Hankel)', sp.optimize.check_grad(fB_ha, gB, B.reshape(-1)))\n",
    "print('grad B (corr. )', sp.optimize.check_grad(fB_rw, gB, B.reshape(-1)))\n",
    "#print('grad B (test)', sp.optimize.check_grad(fB, g_, np.random.normal(size=(n,n)).reshape(-1)))\n",
    "\n",
    "np.sort(ts1[ts1<=250]), np.sort(ts1[ts1>250]), np.min(np.diff(np.sort(ts1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g1 = g_l2_Hankel_sgd(C,X,R,y,lag_range,ts,(1,),get_observed,W=W)[0]\n",
    "g2 = g_l2_Hankel_sgd(C,X,R,y,lag_range,ts,(2,),get_observed,W=W)[0]\n",
    "g12 = g_l2_Hankel_sgd(C,X,R,y,lag_range,ts,(1,2),get_observed,W=W)[0]\n",
    "g1+g2, g12\n",
    "\n",
    "f1 = f_l2_Hankel_nl(C,X,R, y, lag_range=lag_range, ms=(1,), get_observed=get_observed, \n",
    "                          idx_a=np.arange(p), idx_b=np.arange(p), W=W, ts=ts1)\n",
    "f2 = f_l2_Hankel_nl(C,X,R, y, lag_range=lag_range, ms=(2,), get_observed=get_observed, \n",
    "                          idx_a=np.arange(p), idx_b=np.arange(p), W=W, ts=ts1)\n",
    "f12 = f_l2_Hankel_nl(C,X,R, y, lag_range=lag_range, ms=(1,2), get_observed=get_observed, \n",
    "                          idx_a=np.arange(p), idx_b=np.arange(p), W=W, ts=ts1)\n",
    "f1+f2, f12, g1+g2, g12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d/dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ssidid.SSID_Hankel_loss import f_l2_Hankel_nl, g_l2_Hankel_sgd\n",
    "\n",
    "ts1 = np.random.choice(T-kl_, T-kl_, replace=False)\n",
    "msu = np.random.choice(kl_, kl_, replace=False)\n",
    "\n",
    "T,p = y.shape\n",
    "n = x.shape[1]\n",
    "\n",
    "ms = np.hstack([msu[i] * np.ones_like(ts1) for i in range(len(msu))])\n",
    "ts = np.hstack([ ts1 for i in range(len(msu))])\n",
    "\n",
    "# gen system pars\n",
    "nr = 0\n",
    "nc, nc_u = n - nr, (n - nr)//2\n",
    "Q, D = np.zeros((n,n), dtype=complex), np.zeros(n, dtype=complex)\n",
    "# draw real eigenvalues and eigenvectors\n",
    "D[:nr] = np.linspace(0.8, 0.99, nr)\n",
    "Q[:,:nr] = np.random.normal(size=(n,nr))\n",
    "Q[:,:nr] /= np.sqrt((Q[:,:nr]**2).sum(axis=0)).reshape(1,nr)\n",
    "# draw complex eigenvalues and eigenvectors\n",
    "circs = np.exp(2 * 1j * np.pi * np.random.vonmises(mu=0, kappa=1000, size=nc_u))\n",
    "scales = np.random.uniform(size=nc_u)\n",
    "ev_c_r, ev_c_c = scales * np.real(circs), scales * np.imag(circs)\n",
    "V = np.random.normal(size=(n,n))\n",
    "for i in range(nc_u):\n",
    "    Vi = V[:,i*2:(i+1)*2] / np.sqrt( np.sum(V[:,i*2:(i+1)*2]**2) )\n",
    "    Q[:,nr+i], Q[:,nr+nc_u+i] = Vi[:,0]+1j*Vi[:,1], Vi[:,0]-1j*Vi[:,1] \n",
    "    D[nr+i], D[nr+i+nc_u] = ev_c_r[i]+1j*ev_c_c[i], ev_c_r[i]-1j*ev_c_c[i]\n",
    "\n",
    "A = Q.dot(np.diag(D)).dot(np.linalg.inv(Q))\n",
    "assert np.allclose(A, np.real(A))\n",
    "A = np.real(A)\n",
    "X0, R = np.random.normal(size=(n,n)), np.random.normal(size=(p))**2\n",
    "X0 = X0 + X0.T\n",
    "C = np.random.normal(size=(p,n))\n",
    "\n",
    "t_ij = [np.zeros((p,p), dtype=int) for m in range(len(lag_range))]\n",
    "for i in range(len(ts)):  \n",
    "    t,m = ts[i],ms[i]\n",
    "    m_ = lag_range[m]\n",
    "    a, b = get_observed(t+m_), get_observed(t)\n",
    "    t_ij[ms[i]][np.ix_(a, b)] += 1\n",
    "t_ij = [np.maximum(t_ij[m], 1) for m in range(len(lag_range))]\n",
    "W = [1./t_ij[m] for m in range(len(lag_range))]\n",
    "\n",
    "#W = [np.ones((p,p)) for m in lag_range]\n",
    "\n",
    "def get_observed(t):\n",
    "    return np.arange(p)\n",
    "\n",
    "def f_ha(C,X,R,y, ts, ms, get_observed, W):\n",
    "    C = C.reshape(p,n)\n",
    "    X = X.reshape(len(lag_range)*n,n)\n",
    "    R = R.reshape(p)\n",
    "    S  = [np.zeros((p,p)) for m in range(len(lag_range))]\n",
    "    Om = [np.zeros((p,p), dtype=bool) for m in range(len(lag_range))]\n",
    "    for i in range(len(ts)):        \n",
    "        t,m = ts[i],ms[i]\n",
    "        m_ = lag_range[m]\n",
    "        a, b = get_observed(t+m_), get_observed(t)\n",
    "        S[ m][np.ix_(a, b)] += np.outer(y[t+m_,a], y[t,b])\n",
    "        Om[m][np.ix_(a, b)] = True\n",
    "    return 0.5*np.sum([np.sum( (C.dot(X[m*n:(m+1)*n,:]).dot(C.T) + (lag_range[m]==0)*np.diag(R) - S[m]*W[m])[Om[m]]**2) for m in range(len(lag_range))])\n",
    "\n",
    "def fB(B):\n",
    "    B = B.reshape(n,n)\n",
    "    Pi = B.dot(B.T)\n",
    "    X = np.vstack([np.linalg.matrix_power(A,m).dot(Pi) for m in range(kl_)])\n",
    "    return f_ha(C,X,R,y, ts, ms, get_observed, W)\n",
    "\n",
    "def g_l2_Hankel_sgd_B(C, B, Aexpm,R,y,lag_range,ts,ms,get_observed,linear=False, W=None):\n",
    "    p,n = C.shape\n",
    "    grad_B  = np.zeros_like(B)\n",
    "    Pi = B.dot(B.T)\n",
    "    for m in ms:\n",
    "        grad_Bm  = np.zeros_like(B)\n",
    "        m_ = lag_range[m]\n",
    "        for t in ts:\n",
    "            a = get_observed(t+m_)\n",
    "            b = get_observed(t)\n",
    "            anb = np.intersect1d(a,b)\n",
    "            g_B_l2_vector_pair(grad_Bm, m_, C, Aexpm[m*n:(m+1)*n,:], Pi, R, a, b, anb, y[t], y[t+m_], W[m])\n",
    "        grad_B += (grad_Bm + grad_Bm.T)\n",
    "    grad_B = grad_B.dot(B)\n",
    "    return grad_B\n",
    "\n",
    "def g_B_l2_vector_pair(grad, m_, C, Am, Pi, R, a, b, anb, yp, yf, Wm):\n",
    "    for k in a:        \n",
    "        CAm_k = C[k,:].dot(Am)\n",
    "        S_k = C[b,:].T.dot(C[b,:] * Wm[k,b].reshape(-1,1))\n",
    "        grad += np.outer(CAm_k, CAm_k).dot(Pi).dot(S_k)\n",
    "        S_k = yp[b].dot(C[b,:] * Wm[k,b].reshape(-1,1))\n",
    "        grad -= np.outer(yf[k] * CAm_k, S_k)\n",
    "    if m_ == 0:\n",
    "        grad += C[anb,:].dot(Am).T.dot( (R[anb] * Wm[anb,anb]).reshape(-1,1)*C[anb,:]) \n",
    "\n",
    "Aexpm = np.vstack([np.linalg.matrix_power(A,m) for m in range(kl_)])\n",
    "\n",
    "def gB(B):\n",
    "    B = B.reshape(n,n)\n",
    "    grad_B = g_l2_Hankel_sgd_B(C, B, Aexpm,R,y,lag_range,ts1,msu,get_observed,linear=False, W=W)\n",
    "    return grad_B.reshape(-1)\n",
    "\n",
    "print('ms', msu)\n",
    "\n",
    "#print('grad B ', sp.optimize.check_grad(fA, gA, np.random.normal(size=(n,n)).reshape(-1)))\n",
    "\n",
    "print('grad B', sp.optimize.check_grad(fB, gB, np.random.normal(size=(n,n)).reshape(-1)))\n",
    "#print('grad B (test)', sp.optimize.check_grad(fB, g_, np.random.normal(size=(n,n)).reshape(-1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def g_l2_Hankel_sgd_B(C, B, Aexpm,R,y,lag_range,ts,ms,get_observed,linear=False, W=None):\n",
    "    p,n = C.shape\n",
    "    grad_B  = np.zeros_like(B)\n",
    "    Pi = B.dot(B.T)\n",
    "    for m in ms:\n",
    "        m_ = lag_range[m]\n",
    "        for t in ts:\n",
    "            a = get_observed(t+m_)\n",
    "            b = get_observed(t)\n",
    "            anb = np.intersect1d(a,b)\n",
    "            g_B_l2_vector_pair(grad_B, m_, C, Aexpm[m*n:(m+1)*n,:], Pi, R, a, b, anb, y[t], y[t+m_], W[m])\n",
    "        grad_B = (grad_B + grad_B.T).dot(B)  \n",
    "    return grad_B\n",
    "\n",
    "def g_B_l2_vector_pair(grad, m_, C, Am, Pi, R, a, b, anb, yp, yf, Wm):\n",
    "    for k in a:        \n",
    "        CAm_k = C[k,:].dot(Am)\n",
    "        S_k = C[b,:].T.dot(C[b,:] * Wm[k,b].reshape(-1,1))\n",
    "        grad += np.outer(CAm_k, CAm_k).dot(Pi).dot(S_k)\n",
    "        S_k = yp[b].dot(C[b,:] * Wm[k,b].reshape(-1,1))\n",
    "        grad -= np.outer(yf[k] * CAm_k, S_k)\n",
    "    if m_ == 0:\n",
    "        grad += C[anb,:].dot(Am).T.dot( (R[anb] * Wm[anb,anb]).reshape(-1,1)*C[anb,:]) \n",
    "\n",
    "Aexpm = np.vstack([np.linalg.matrix_power(A,m) for m in range(kl_)])\n",
    "\n",
    "def gB(B):\n",
    "    B = B.reshape(n,n)\n",
    "    grad_B = g_l2_Hankel_sgd_B(C, B, Aexpm,R,y,lag_range,ts1,msu,get_observed,linear=False, W=W)\n",
    "    return grad_B.reshape(-1)\n",
    "\n",
    "def g_(B):\n",
    "    B = B.reshape(n,n)\n",
    "    grad = np.zeros((n,n))\n",
    "    Pi = B.dot(B.T)\n",
    "    X = np.vstack([np.linalg.matrix_power(A,m).dot(Pi) for m in lag_range])\n",
    "    _,dXm,_ = g_l2_Hankel_sgd(C,X,R,y,lag_range,ts1,msu,get_observed,linear=False, W=W)\n",
    "    XT = np.vstack([np.linalg.matrix_power(A,m).dot(Pi).T for m in lag_range])\n",
    "    _,dXmT,_ = g_l2_Hankel_sgd(C,XT,R,y,lag_range,ts1,msu,get_observed,linear=False, W=W)\n",
    "    #dXm, dXmT = g_l2_Hankel_sgd_X(C,X,R,y,lag_range,ts,ms,get_observed,linear=False, W=W)\n",
    "    for m in msu:\n",
    "            Am = np.linalg.matrix_power(A,m)\n",
    "            grad += dXmT[m*n:(m+1)*n,:].dot(Am.dot(B)) + Am.T.dot(dXm[m*n:(m+1)*n,:]).dot(B)\n",
    "    return grad.reshape(-1)\n",
    "\n",
    "print('ms', msu)\n",
    "\n",
    "#print('grad B ', sp.optimize.check_grad(fA, gA, np.random.normal(size=(n,n)).reshape(-1)))\n",
    "print('grad B (test)', sp.optimize.check_grad(fB, gB, np.random.normal(size=(n,n)).reshape(-1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import optimize\n",
    "\n",
    "m = 1\n",
    "lag_range = np.arange(m+1)\n",
    "kl_ = len(lag_range) + 1\n",
    "T = 10 + kl_\n",
    "\n",
    "p,n = 5, 2\n",
    "A = np.random.normal(size=(n,n))\n",
    "C = np.random.normal(size=(p,n))\n",
    "\n",
    "def get_observed(t):\n",
    "    return np.arange(p)\n",
    "\n",
    "\n",
    "t_ij = [(T-kl_)*np.ones((p,p)) for m in range(len(lag_range))]\n",
    "W = [1/(t_ij[m]-1) for m in range(len(lag_range))]\n",
    "\n",
    "x = np.zeros((T, 2))\n",
    "x[0] = np.random.normal(size=n)\n",
    "for t in range(1,T):\n",
    "    x[t] = A.dot(x[t-1])\n",
    "y = x.dot(C.T)\n",
    "y -= y[:T-kl_].mean(axis=0)\n",
    "\n",
    "\n",
    "X0 = np.cov(x[:T-kl_].T)\n",
    "X = np.vstack([np.linalg.matrix_power(A,m).dot(X0) for m in range(kl_)])\n",
    "R = np.zeros(p)\n",
    "\n",
    "ts = np.arange(T-kl_)\n",
    "ms = m * np.ones_like(ts)\n",
    "\n",
    "S  = [np.zeros((p,p)) for m in range(len(lag_range))]\n",
    "Om = [np.zeros((p,p), dtype=bool) for m in range(len(lag_range))]\n",
    "ym = [ y[m:T-kl_+m].mean(axis=0) for m in range(len(lag_range))]\n",
    "for i in range(len(ts)):        \n",
    "    t,m = ts[i],ms[i]\n",
    "    m_ = lag_range[m]\n",
    "    a, b = get_observed(t+m_), get_observed(t)\n",
    "    S[ m][np.ix_(a, b)] += np.outer(y[t+m_,a] - ym[m], y[t,b])\n",
    "    Om[m][np.ix_(a, b)] = True\n",
    "    \n",
    "def f_ha(C,X,R, ts, ms, get_observed, t_ij):\n",
    "    C = C.reshape(p,n)\n",
    "    R = R.reshape(p)\n",
    "    return 0.5*np.sum([np.sum( (C.dot(X[m*n:(m+1)*n,:]).dot(C.T) + (lag_range[m]==0)*np.diag(R) - S[m]/t_ij[m])[Om[m]]**2) for m in range(len(lag_range))])\n",
    "\n",
    "# decorating\n",
    "def fA(A):\n",
    "    A = A.reshape(n,n)\n",
    "    X = np.vstack([np.linalg.matrix_power(A,m).dot(X0) for m in range(kl_)])\n",
    "    return f_ha(C,X,R, ts, ms, get_observed, t_ij)\n",
    "\n",
    "\n",
    "# unweighted stochastic gradients w.r.t. C \n",
    "def gA(A):    \n",
    "    A = A.reshape(n,n)\n",
    "    grad_A = np.zeros((n,n))    \n",
    "    CC = C.T.dot(C)\n",
    "    for q in range(m):\n",
    "        Am   = np.linalg.matrix_power(A, m)\n",
    "        Aq   = np.linalg.matrix_power(A, q)\n",
    "        Am1q = np.linalg.matrix_power(A, m-1-q)\n",
    "        grad_A += Aq.T.dot( CC.dot(Am.dot(X0)).dot(CC) - C.T.dot(S[m]*W[m]).dot(C)).dot(X0).dot(Am1q)\n",
    "    return grad_A.reshape(-1)\n",
    "\n",
    "print('f, g', (fA(A), gA(A)))\n",
    "\n",
    "print('grad A ', sp.optimize.check_grad(fA, gA, A.reshape(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# formula check\n",
    "\n",
    "- numerically comparing implemented gradients with non-vectorised analytic formula "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t, m = np.random.choice(p, 1), 0\n",
    "m_ = m\n",
    "\n",
    "C, Xm, R = pars_true['C'], pars_true['X'][m*n:(m+1)*n, :], pars_true['R']\n",
    "p,n = C.shape\n",
    "grad_C = np.zeros((p,n))\n",
    "grad_X = np.zeros(pars_true['X'].shape)\n",
    "grad_R = np.zeros(p)\n",
    "idx_ct = np.zeros((p,2),dtype=np.int32)\n",
    "\n",
    "C___ = C.dot(Xm)   # mad-\n",
    "C_tr = C.dot(Xm.T) # ness\n",
    "\n",
    "a,b = obs_scheme.mask[t+m,:], obs_scheme.mask[t,:]\n",
    "a,b = np.where(a)[1], np.where(b)[1]\n",
    "\n",
    "anb = np.intersect1d(a,b)\n",
    "a_ = np.setdiff1d(a,b)\n",
    "b_ = np.setdiff1d(b,a)\n",
    "\n",
    "yf = y[t+m_,a]\n",
    "yp = y[t,b]\n",
    "\n",
    "Om = np.outer(obs_scheme.mask[t+m,:], obs_scheme.mask[t,:]).astype(bool)\n",
    "L = np.outer(y[t+m,:], y[t,:])\n",
    "grad_C = np.zeros_like(C)\n",
    "for k in range(p):\n",
    "    for i in range(p):\n",
    "        for j in range(p):        \n",
    "\n",
    "            if Om[i,j]:\n",
    "                #print(i,j)\n",
    "                Ci, Cj = C[i,:], C[j,:]\n",
    "                if k==i and k!=j:\n",
    "                    #print('1')\n",
    "                    grad_C[k,:] += Ci.dot(Xm.dot(np.outer(Cj,Cj)).dot(Xm.T)) - L[i,j]*Cj.dot(Xm.T)\n",
    "                if k==j and k!=i:\n",
    "                    #print('2')\n",
    "                    grad_C[k,:] += Cj.dot(Xm.T.dot(np.outer(Ci,Ci)).dot(Xm)) - L[i,j]*Ci.dot(Xm)\n",
    "                if k==i and k==j:\n",
    "                    #print('3')\n",
    "                    grad_C[k,:] += Ci.dot(Xm.dot(np.outer(Cj,Cj)).dot(Xm.T)) - L[i,j]*Cj.dot(Xm.T)\n",
    "                    grad_C[k,:] += Cj.dot(Xm.T.dot(np.outer(Ci,Ci)).dot(Xm)) - L[i,j]*Ci.dot(Xm)\n",
    "                    if m ==0:\n",
    "                        grad_C[k,:] += R[i] * (Cj.dot(Xm.T)+Ci.dot(Xm))\n",
    "                    \n",
    "print('non-vectorised', grad_C)\n",
    "grad_C_blunt = grad_C.copy()\n",
    "#g_C_l2_Hankel_vector_pair(grad_C, m_, C, Xm, R, a, b, ab, CC_a, CC_b, yp, yf)    \n",
    "\n",
    "grad_C = np.zeros((p,n))\n",
    "\n",
    "C___ = C.dot(Xm)   # mad-\n",
    "C_tr = C.dot(Xm.T) # ness\n",
    "\n",
    "grad_C[a,:] += C[a,:].dot( C_tr[b,:].T.dot(C_tr[b,:]) ) - np.outer(yf,yp.dot(C_tr[b,:]))\n",
    "grad_C[b,:] += C[b,:].dot( C___[a,:].T.dot(C___[a,:]) ) - np.outer(yp,yf.dot(C___[a,:]))\n",
    "\n",
    "# correction for variables not observed both at t+m_ and t  \n",
    "#if a_.size > 0:\n",
    "#    grad_C[a_,:] -= (np.sum(C[a_,:]*C_tr[a_,:],axis=1) - y[t+m,a_]*y[t,a_]).reshape(-1,1) * C_tr[a_,:]\n",
    "#if b_.size > 0:\n",
    "#    grad_C[b_,:] -= (np.sum(C[b_,:]*C___[b_,:],axis=1) - y[t+m,b_]*y[t,b_]).reshape(-1,1) * C___[b_,:]\n",
    "\n",
    "if m_==0: \n",
    "    grad_C[anb,:] += R[anb].reshape(-1,1)*(C___[anb,:] + C_tr[anb,:])\n",
    "print('vectorised', grad_C)\n",
    "\n",
    "print('overlap', anb)\n",
    "\n",
    "assert np.allclose(grad_C_blunt, grad_C)\n",
    "\n",
    "plt.imshow(Om, interpolation='None')\n",
    "plt.title('observation scheme (\\Omega)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
