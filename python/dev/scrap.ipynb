{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gen toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob, os, psutil, time\n",
    "\n",
    "from ssidid.SSID_Hankel_loss import run_bad, plot_slim, print_slim, f_l2_Hankel_nl\n",
    "from ssidid.utility import get_subpop_stats, gen_data\n",
    "from ssidid import ObservationScheme\n",
    "from subtracking import Grouse, calc_subspace_proj_error\n",
    "\n",
    "# define problem size\n",
    "p, n, T = 10, 2, 200\n",
    "lag_range = np.arange(0,10)\n",
    "kl_ = np.max(lag_range)+1\n",
    "\n",
    "nr = 0 # number of real eigenvalues\n",
    "snr = (0.0, 0.0)\n",
    "whiten = True\n",
    "eig_m_r, eig_M_r, eig_m_c, eig_M_c = 0.90, 0.95, 0.90, 0.95\n",
    "\n",
    "print('(p,n,k+l,T) = ', (p,n,len(lag_range),T), '\\n')\n",
    "\n",
    "# I/O matter\n",
    "mmap, chunksize = False, np.min((p,2000))\n",
    "verbose=True\n",
    "\n",
    "# create subpopulations\n",
    "sub_pops = (np.arange(0,p), np.arange(0,p))\n",
    "obs_pops = np.array([0,1])\n",
    "obs_time = np.array([T//2,T])\n",
    "obs_idx, idx_grp, co_obs, _, _, _, Om, _, _ = \\\n",
    "    get_subpop_stats(sub_pops=sub_pops, p=p, verbose=False)\n",
    "obs_scheme = ObservationScheme(p=p, T=T, \n",
    "                               sub_pops=sub_pops, obs_pops=obs_pops, \n",
    "                               obs_time=obs_time, obs_idx=obs_time, \n",
    "                               idx_grp=idx_grp)\n",
    "\n",
    "n_obs = np.ceil(p * 0.5)\n",
    "mask = np.zeros((T,p))\n",
    "for t in range(T):\n",
    "    for i in range(len(obs_time)):\n",
    "        if t < obs_time[i]:\n",
    "            #mask[t, np.random.choice(p, n_obs, replace=False)] = 1\n",
    "            mask[t,sub_pops[obs_pops[i]]] = 1\n",
    "            break            \n",
    "            \n",
    "obs_scheme.mask = mask\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(mask.T)\n",
    "plt.show()\n",
    "\n",
    "# draw system matrices / data\n",
    "data_path = '/home/mackelab/Desktop/Projects/Stitching/code/le_stitch/python/fits/compare_vs_grouse/'\n",
    "pars_true, x, y, Qs, idx_a, idx_b = gen_data(p,n,lag_range,T, nr,\n",
    "                                             eig_m_r, eig_M_r, \n",
    "                                             eig_m_c, eig_M_c,\n",
    "                                             mmap, chunksize,\n",
    "                                             data_path,\n",
    "                                             snr=snr, whiten=whiten)    \n",
    "pars_true['X'] = np.vstack([np.linalg.matrix_power(pars_true['A'],k).dot(pars_true['Pi']) for k in lag_range])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# formula check\n",
    "\n",
    "- numerically comparing implemented gradients with non-vectorised analytic formula "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t, m = np.random.choice(p, 1), 0\n",
    "m_ = m\n",
    "\n",
    "C, Xm, R = pars_true['C'], pars_true['X'][m*n:(m+1)*n, :], pars_true['R']\n",
    "p,n = C.shape\n",
    "grad_C = np.zeros((p,n))\n",
    "grad_X = np.zeros(pars_true['X'].shape)\n",
    "grad_R = np.zeros(p)\n",
    "idx_ct = np.zeros((p,2),dtype=np.int32)\n",
    "\n",
    "C___ = C.dot(Xm)   # mad-\n",
    "C_tr = C.dot(Xm.T) # ness\n",
    "\n",
    "a,b = obs_scheme.mask[t+m,:], obs_scheme.mask[t,:]\n",
    "a,b = np.where(a)[1], np.where(b)[1]\n",
    "\n",
    "anb = np.intersect1d(a,b)\n",
    "a_ = np.setdiff1d(a,b)\n",
    "b_ = np.setdiff1d(b,a)\n",
    "\n",
    "yf = y[t+m_,a]\n",
    "yp = y[t,b]\n",
    "\n",
    "Om = np.outer(obs_scheme.mask[t+m,:], obs_scheme.mask[t,:]).astype(bool)\n",
    "L = np.outer(y[t+m,:], y[t,:])\n",
    "grad_C = np.zeros_like(C)\n",
    "for k in range(p):\n",
    "    for i in range(p):\n",
    "        for j in range(p):        \n",
    "\n",
    "            if Om[i,j]:\n",
    "                #print(i,j)\n",
    "                Ci, Cj = C[i,:], C[j,:]\n",
    "                if k==i and k!=j:\n",
    "                    #print('1')\n",
    "                    grad_C[k,:] += Ci.dot(Xm.dot(np.outer(Cj,Cj)).dot(Xm.T)) - L[i,j]*Cj.dot(Xm.T)\n",
    "                if k==j and k!=i:\n",
    "                    #print('2')\n",
    "                    grad_C[k,:] += Cj.dot(Xm.T.dot(np.outer(Ci,Ci)).dot(Xm)) - L[i,j]*Ci.dot(Xm)\n",
    "                if k==i and k==j:\n",
    "                    #print('3')\n",
    "                    grad_C[k,:] += Ci.dot(Xm.dot(np.outer(Cj,Cj)).dot(Xm.T)) - L[i,j]*Cj.dot(Xm.T)\n",
    "                    grad_C[k,:] += Cj.dot(Xm.T.dot(np.outer(Ci,Ci)).dot(Xm)) - L[i,j]*Ci.dot(Xm)\n",
    "                    if m ==0:\n",
    "                        grad_C[k,:] += R[i] * (Cj.dot(Xm.T)+Ci.dot(Xm))\n",
    "                    \n",
    "print('non-vectorised', grad_C)\n",
    "grad_C_blunt = grad_C.copy()\n",
    "#g_C_l2_Hankel_vector_pair(grad_C, m_, C, Xm, R, a, b, ab, CC_a, CC_b, yp, yf)    \n",
    "\n",
    "grad_C = np.zeros((p,n))\n",
    "\n",
    "C___ = C.dot(Xm)   # mad-\n",
    "C_tr = C.dot(Xm.T) # ness\n",
    "\n",
    "grad_C[a,:] += C[a,:].dot( C_tr[b,:].T.dot(C_tr[b,:]) ) - np.outer(yf,yp.dot(C_tr[b,:]))\n",
    "grad_C[b,:] += C[b,:].dot( C___[a,:].T.dot(C___[a,:]) ) - np.outer(yp,yf.dot(C___[a,:]))\n",
    "\n",
    "# correction for variables not observed both at t+m_ and t  \n",
    "#if a_.size > 0:\n",
    "#    grad_C[a_,:] -= (np.sum(C[a_,:]*C_tr[a_,:],axis=1) - y[t+m,a_]*y[t,a_]).reshape(-1,1) * C_tr[a_,:]\n",
    "#if b_.size > 0:\n",
    "#    grad_C[b_,:] -= (np.sum(C[b_,:]*C___[b_,:],axis=1) - y[t+m,b_]*y[t,b_]).reshape(-1,1) * C___[b_,:]\n",
    "\n",
    "if m_==0: \n",
    "    grad_C[anb,:] += R[anb].reshape(-1,1)*(C___[anb,:] + C_tr[anb,:])\n",
    "print('vectorised', grad_C)\n",
    "\n",
    "print('overlap', anb)\n",
    "\n",
    "assert np.allclose(grad_C_blunt, grad_C)\n",
    "\n",
    "plt.imshow(Om, interpolation='None')\n",
    "plt.title('observation scheme (\\Omega)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# errors per time-lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f_l2_block(C,AmPi,Q,idx_grp,co_obs,idx_a,idx_b,W=None):\n",
    "    \"Hankel reconstruction error on an individual Hankel block\"\n",
    "\n",
    "    err = 0.\n",
    "    for i in range(len(idx_grp)):\n",
    "        err_ab = 0.\n",
    "        a = np.intersect1d(idx_grp[i],idx_a)\n",
    "        b = np.intersect1d(co_obs[i], idx_b)\n",
    "        a_Q = np.in1d(idx_a, idx_grp[i])\n",
    "        b_Q = np.in1d(idx_b, co_obs[i])\n",
    "\n",
    "        v = (C[a,:].dot(AmPi).dot(C[b,:].T) - Q[np.ix_(a_Q,b_Q)])\n",
    "        v = v.reshape(-1,) if  W is None else W.reshape(-1,) * v.reshape(-1,)\n",
    "\n",
    "        err += v.dot(v)\n",
    "\n",
    "    return err\n",
    "\n",
    "def f_l2_inst(C,Pi,R,Q,idx_grp,co_obs,idx_a,idx_b,W=None):\n",
    "    \"reconstruction error on the instantaneous covariance\"\n",
    "\n",
    "    err = 0.\n",
    "    if not Q is None:\n",
    "        for i in range(len(idx_grp)):\n",
    "\n",
    "            a = np.intersect1d(idx_grp[i],idx_a)\n",
    "            b = np.intersect1d(co_obs[i], idx_b)\n",
    "            a_Q = np.in1d(idx_a, idx_grp[i])\n",
    "            b_Q = np.in1d(idx_b, co_obs[i])\n",
    "\n",
    "            v = (C[a,:].dot(Pi).dot(C[b,:].T) - Q[np.ix_(a_Q,b_Q)])\n",
    "            idx_R = np.where(np.in1d(b,a))[0]\n",
    "            v[np.arange(len(idx_R)), idx_R] += R[a]\n",
    "            v = v.reshape(-1,) if  W is None else W.reshape(-1,)*v.reshape(-1,)\n",
    "\n",
    "            err += v.dot(v)\n",
    "\n",
    "    return err\n",
    "\n",
    "def f_l2_Hankel_nl(C,X,Pi,R,lag_range,Qs,idx_grp,co_obs,\n",
    "                   idx_a=None,idx_b=None,W=None):\n",
    "    \"returns overall l2 Hankel reconstruction error\"\n",
    "\n",
    "    kl = len(lag_range)\n",
    "    p,n = C.shape\n",
    "    idx_a = np.arange(p) if idx_a is None else idx_a\n",
    "    idx_b = idx_a if idx_b is None else idx_b\n",
    "    assert (len(idx_a), len(idx_b)) == Qs[0].shape\n",
    "\n",
    "    err = np.zeros(kl)\n",
    "    err[0] = f_l2_inst(C,X[:n, :],R,Qs[0],idx_grp,co_obs,idx_a,idx_b)\n",
    "    for m in range(1,kl):\n",
    "        err[m]= f_l2_block(C,X[m*n:(m+1)*n, :],Qs[m],idx_grp,co_obs,idx_a,idx_b,W)\n",
    "            \n",
    "    return err\n",
    "pars_est = pars_est.copy()\n",
    "print('est. pars \\n', f_l2_Hankel_nl(pars_est['C'], pars_est['X'], pars_est['X'][:n,:], pars_est['R'], lag_range, Qs, idx_grp, co_obs))\n",
    "\n",
    "pars_est = pars_true.copy()\n",
    "print('ground-truth pars \\n', f_l2_Hankel_nl(pars_est['C'], np.vstack([np.cov(x[k_:-(kl_)+k_, :].T, x[:-(kl_), :].T)[:n,n:] for k_ in lag_range]), pars_est['X'][:n,:], pars_est['R'], lag_range, Qs, idx_grp, co_obs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_max = 4\n",
    "n_t = 10\n",
    "ts,ms = np.random.choice(T-m_max, n_t), np.random.choice(m_max, 1)[0] * np.ones(n_t,dtype=int)\n",
    "\n",
    "a = [np.where(obs_scheme.mask[t+m,:])[0] for (t,m) in zip(ts, ms)]\n",
    "b = [np.where(obs_scheme.mask[t,:])[0] for (t,m) in zip(ts, ms)]\n",
    "\n",
    "a = [np.random.choice(p,p//2,replace=False) for (t,m) in zip(ts, ms)]\n",
    "b = [a[i].copy() if ms[i] == 0 else np.random.choice(p,p//2,replace=False) for i in range(len(ts))]\n",
    "\n",
    "\n",
    "anb = [np.intersect1d(a[i],b[i]) for i in range(len(ts)) ]\n",
    "pars_est = pars_true.copy()\n",
    "\n",
    "#Xm, R = pars_est['X'][m*n:(m+1)*n,:], pars_est['R']\n",
    "X, R = np.random.normal(size=(m_max*n,n)), np.random.normal(size=(p))**2\n",
    "C = np.random.normal(size=(p,n))\n",
    "\n",
    "def fC(C):\n",
    "    C = C.reshape(p,n)\n",
    "    f = 0\n",
    "    for i in range(len(ts)):\n",
    "        Xm = X[ms[i]*n:(ms[i]+1)*n,:].copy()\n",
    "        f += ((C[a[i],:].dot(Xm).dot(C[b[i],:].T) + \\\n",
    "               (ms[i]==0)* np.diag(R)[np.ix_(a[i],b[i])] - \\\n",
    "               np.outer(y[ts[i]+ms[i],a[i]], y[ts[i],b[i]]))**2).sum()\n",
    "    \n",
    "    return 0.5*f / len(ts)\n",
    "\n",
    "def fC_rw(C):\n",
    "    C = C.reshape(p,n)\n",
    "    f = 0\n",
    "    \n",
    "    nC = [np.zeros((p,p), dtype=int) for m in range(m_max)]\n",
    "    for i in range(len(ts)):        \n",
    "        nC[ms[i]][np.ix_(a[i], b[i])] += 1\n",
    "    for i in range(len(ts)):\n",
    "        Xm = X[ms[i]*n:(ms[i]+1)*n,:].copy()\n",
    "        f += (((C[a[i],:].dot(Xm).dot(C[b[i],:].T) + \\\n",
    "                (ms[i]==0)* np.diag(R)[np.ix_(a[i],b[i])] - \\\n",
    "                np.outer(y[ts[i]+ms[i],a[i]], y[ts[i],b[i]]))**2)/nC[ms[i]][np.ix_(a[i],b[i])]).sum()\n",
    "    \n",
    "    return 0.5*f\n",
    "\n",
    "def fC_(C):\n",
    "    C = C.reshape(p,n)\n",
    "    S  = [np.zeros((p,p)) for m in range(m_max)]\n",
    "    cS = [np.zeros((p,p), dtype=int) for m in range(m_max)]\n",
    "    for i in range(len(ts)):        \n",
    "        S[ ms[i]][np.ix_(a[i], b[i])] += np.outer(y[ts[i]+ms[i],a[i]], y[ts[i],b[i]])\n",
    "        cS[ms[i]][np.ix_(a[i], b[i])] += 1\n",
    "    Om = [cS[m] > 0 for m in range(m_max)]\n",
    "    cS = [np.maximum(cS[m], 1) for m in range(m_max)]\n",
    "    #print(cS)\n",
    "    return 0.5*np.sum([np.sum( (C.dot(X[m*n:(m+1)*n,:]).dot(C.T) + (m==0)*np.diag(R) - S[m]/cS[m])[Om[m]]**2) for m in range(m_max)])\n",
    "\n",
    "\n",
    "def fX(X):\n",
    "    X = X.reshape(-1,n)\n",
    "    f = 0\n",
    "    for i in range(len(ts)):\n",
    "        Xm = X[ms[i]*n:(ms[i]+1)*n,:].copy()\n",
    "        \n",
    "        f += ((C[a[i],:].dot(Xm).dot(C[b[i],:].T) - np.outer(y[ts[i]+ms[i],a[i]], y[ts[i],b[i]]) + (ms[i]==0)* np.diag(R)[np.ix_(a[i],b[i])])**2).sum()\n",
    "    \n",
    "    return 0.5*f / len(ts)\n",
    "\n",
    "def fR(R):\n",
    "    S = np.zeros((p,p))\n",
    "    f = 0\n",
    "    for i in range(len(ts)):\n",
    "        Xm = X[ms[i]*n:(ms[i]+1)*n,:].copy()\n",
    "        \n",
    "        f += ((C[a[i],:].dot(Xm).dot(C[b[i],:].T) - np.outer(y[ts[i]+ms[i],a[i]], y[ts[i],b[i]]) + (ms[i]==0)* np.diag(R)[np.ix_(a[i],b[i])])**2).sum()\n",
    "    \n",
    "    return 0.5*f / len(ts)\n",
    "\n",
    "\n",
    "def gC(C): \n",
    "    C = C.reshape(p,n)\n",
    "    grad_C = np.zeros((p,n))\n",
    "\n",
    "    nC = [np.zeros((p,p), dtype=int) for m in range(m_max)]\n",
    "    for i in range(len(ts)):        \n",
    "        nC[ms[i]][np.ix_(a[i], b[i])] += 1    \n",
    "    \n",
    "    for i in range(len(ts)):\n",
    "        Xm = X[ms[i]*n:(ms[i]+1)*n,:].copy()\n",
    "        C___ = C.dot(Xm)   # mad-\n",
    "        C_tr = C.dot(Xm.T) # ness        \n",
    "        grad_C[a[i],:] += C[a[i],:].dot( C_tr[b[i],:].T.dot(C_tr[b[i],:]) ) - np.outer(y[ts[i]+ms[i],a[i]],y[ts[i],b[i]].dot(C_tr[b[i],:]))\n",
    "        grad_C[b[i],:] += C[b[i],:].dot( C___[a[i],:].T.dot(C___[a[i],:]) ) - np.outer(y[ts[i],b[i]],y[ts[i]+ms[i],a[i]].dot(C___[a[i],:]))\n",
    "        if ms[i] ==0:\n",
    "            grad_C[anb[i],:] += R[anb[i]].reshape(-1,1)*(C___[anb[i],:] + C_tr[anb[i],:])  \n",
    "    return grad_C.reshape(-1) / len(ts)\n",
    "\n",
    "def gX(X):\n",
    "    X = X.reshape(-1, n)\n",
    "    grad_X = np.zeros_like(X)\n",
    "    for i in range(len(ts)):\n",
    "        Xm = X[ms[i]*n:(ms[i]+1)*n,:].copy()\n",
    "        CC_a = C[a[i],:].T.dot(C[a[i],:])\n",
    "        CC_b = C[b[i],:].T.dot(C[b[i],:])\n",
    "        grad_X[ms[i]*n:(ms[i]+1)*n,:] += CC_a.dot(Xm).dot(CC_b) - np.outer(y[ts[i]+ms[i],a[i]].dot(C[a[i],:]), y[ts[i],b[i]].dot(C[b[i],:]))\n",
    "        if ms[i] == 0:\n",
    "            grad_X[:n,:] += C[anb[i],:].T.dot(R[anb[i]].reshape(-1,1) * C[anb[i],:])\n",
    "    return grad_X.reshape(-1) / len(ts)\n",
    "\n",
    "def gR(R): \n",
    "    grad_R = np.zeros(p)\n",
    "    for i in range(len(ts)):\n",
    "        if ms[i]==0:\n",
    "            grad_R[b[i]] += R[b[i]] + np.sum(C[b[i],:] * C[b[i],:].dot(X[:n,:].T),axis=1) - y[ts[i],b[i]]**2\n",
    "    return grad_R / len(ts)\n",
    "\n",
    "print(fC(C), fX(X), fR(R))\n",
    "#gC(pars_est['C'])\n",
    "\n",
    "#def fC(C):\n",
    "#    return 0.5*np.sum(C**2)\n",
    "#def gC(C):\n",
    "#    return C\n",
    "\n",
    "print('a, b, a \\cap b \\n', a,b,anb)\n",
    "\n",
    "print('ms \\n', ms)\n",
    "\n",
    "print('numerical gradient errors (sp.otimize.check_grad)')\n",
    "print('grad C (actual)', sp.optimize.check_grad(fC, gC, C.reshape(-1)))\n",
    "print('grad C (Hankel)', sp.optimize.check_grad(fC_, gC, C.reshape(-1)))\n",
    "print('grad C (corr. )', sp.optimize.check_grad(fC_rw, gC, C.reshape(-1)))\n",
    "\n",
    "print('grad X', sp.optimize.check_grad(fX, gX, X.reshape(-1)))\n",
    "print('grad R', sp.optimize.check_grad(fR, gR, R.reshape(-1)))\n",
    "\n",
    "print('function evaluation (actual f , Hankel f, corrected f )')\n",
    "print(fC(C), fC_(C), fC_rw(C))\n",
    "\n",
    "V = np.zeros((p,p))\n",
    "for i in range(p):\n",
    "    for j in range(p):\n",
    "        V[i,j] = np.var(y[ts+ms,i] * y[ts,i])\n",
    "\n",
    "fC(C), fC_(C) + 0.5 * V.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# corrected gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_max = 4\n",
    "n_t = 10\n",
    "ts,ms = np.random.choice(T-m_max, n_t), np.random.choice(m_max, 1)[0] * np.ones(n_t,dtype=int)\n",
    "\n",
    "a = [np.where(obs_scheme.mask[t+m,:])[0] for (t,m) in zip(ts, ms)]\n",
    "b = [np.where(obs_scheme.mask[t,:])[0] for (t,m) in zip(ts, ms)]\n",
    "\n",
    "ais = [np.random.choice(p,p//2,replace=False) for (t,m) in zip(ts, ms)]\n",
    "bis = [a[i].copy() if ms[i] == 0 else np.random.choice(p,p//2,replace=False) for i in range(len(ts))]\n",
    "\n",
    "anbis = anb\n",
    "\n",
    "\n",
    "def fC(C):\n",
    "    C = C.reshape(p,n)\n",
    "    f = 0\n",
    "    for i in range(len(ts)):\n",
    "        a, b = ais[i], bis[i]\n",
    "        t, m = ts[i], ms[i] \n",
    "        Xm = X[m*n:(m+1)*n,:].copy()\n",
    "        f += ((C[a,:].dot(Xm).dot(C[b,:].T) + \\\n",
    "               (ms[i]==0)* np.diag(R)[np.ix_(a,b)] - \\\n",
    "               np.outer(y[t+m,a], y[t,b]))**2).sum()\n",
    "    \n",
    "    return 0.5*f / len(ts)\n",
    "\n",
    "def fC_rw(C):\n",
    "    C = C.reshape(p,n)\n",
    "    f = 0\n",
    "    \n",
    "    nC = [np.zeros((p,p), dtype=int) for m in range(m_max)]\n",
    "    for i in range(len(ts)):  \n",
    "        a, b = ais[i], bis[i]\n",
    "        nC[ms[i]][np.ix_(a, b)] += 1\n",
    "    for i in range(len(ts)):\n",
    "        a, b = ais[i], bis[i]\n",
    "        t, m = ts[i], ms[i] \n",
    "        Xm = X[m*n:(m+1)*n,:].copy()\n",
    "        f += (((C[a,:].dot(Xm).dot(C[b,:].T) + \\\n",
    "                (ms[i]==0)* np.diag(R)[np.ix_(a,b)] - \\\n",
    "                np.outer(y[t+m,a], y[t,b]))**2)/nC[m][np.ix_(a,b)]).sum()\n",
    "    \n",
    "    return 0.5*f\n",
    "\n",
    "def fC_(C):\n",
    "    C = C.reshape(p,n)\n",
    "    S  = [np.zeros((p,p)) for m in range(m_max)]\n",
    "    cS = [np.zeros((p,p), dtype=int) for m in range(m_max)]\n",
    "    for i in range(len(ts)):        \n",
    "        a, b = ais[i], bis[i]\n",
    "        t, m = ts[i], ms[i] \n",
    "        S[ m][np.ix_(a, b)] += np.outer(y[t+m,a], y[t,b])\n",
    "        cS[m][np.ix_(a, b)] += 1\n",
    "    Om = [cS[m] > 0 for m in range(m_max)]\n",
    "    cS = [np.maximum(cS[m], 1) for m in range(m_max)]\n",
    "    #print(cS)\n",
    "    return 0.5*np.sum([np.sum( (C.dot(X[m*n:(m+1)*n,:]).dot(C.T) + (m==0)*np.diag(R) - S[m]/cS[m])[Om[m]]**2) for m in range(m_max)])\n",
    "\n",
    "\n",
    "\n",
    "def gC_rw(C): \n",
    "    C = C.reshape(p,n)\n",
    "    grad_C = np.zeros((p,n))\n",
    "\n",
    "    nC = [np.zeros((p,p), dtype=int) for m in range(m_max)]\n",
    "    for i in range(len(ts)):        \n",
    "        \n",
    "        a, b = ais[i], bis[i]\n",
    "        anb  = anbis[i]\n",
    "        \n",
    "        nC[ms[i]][np.ix_(a, b)] += 1    \n",
    "    \n",
    "    for i in range(len(ts)):\n",
    "        \n",
    "        a, b = ais[i], bis[i]\n",
    "        anb  = anbis[i]\n",
    "        t, m = ts[i], ms[i] \n",
    "        \n",
    "        Xm = X[ms[i]*n:(ms[i]+1)*n,:].copy()\n",
    "        C___ = C.dot(Xm)   # mad-\n",
    "        C_tr = C.dot(Xm.T) # ness        \n",
    "        for k in a:\n",
    "            #W = np.diag(1./np.maximum(nC[m][k,b],1))\n",
    "            WC = C_tr[b,:] / np.maximum(nC[m][k,b],1).reshape(-1,1)\n",
    "            grad_C[k,:] += C[k,:].dot( C_tr[b,:].T.dot(WC) ) \n",
    "            grad_C[k,:] -= y[t+m,k] * y[t,b].dot(WC)\n",
    "        for k in b:\n",
    "            WC = C___[a,:] / np.maximum(nC[m][a,k],1).reshape(-1,1)\n",
    "            grad_C[k,:] += C[k,:].dot( C___[a,:].T.dot(WC) ) \n",
    "            grad_C[k,:] -= y[t,k] * y[t+m,a].dot(WC)\n",
    "        if ms[i] ==0:\n",
    "            for k in anb:\n",
    "                grad_C[k,:] += R[k].reshape(-1,1)*(C___[k,:] + C_tr[k,:])\n",
    "    return grad_C.reshape(-1) \n",
    "\n",
    "\n",
    "print('grad C (actual)', sp.optimize.check_grad(fC, gC_rw, C.reshape(-1)))\n",
    "print('grad C (Hankel)', sp.optimize.check_grad(fC_, gC_rw, C.reshape(-1)))\n",
    "print('grad C (corr. )', sp.optimize.check_grad(fC_rw, gC_rw, C.reshape(-1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
