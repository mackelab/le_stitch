{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implementation of non-linear (locally (bi-)linear) models\n",
    "\n",
    "Zhao et al. (2016), \"Interpretable Nonlinear Dynamic Modeling\n",
    "of Neural Trajectories\"\n",
    "\n",
    "\\begin{align}\n",
    "y_t &= (1-\\exp(-\\tau^2)) y_t + C x_t + B_t u_t + \\epsilon_t \\\\\n",
    "\\mbox{vec}\\left(B_t\\right) &= W x_t \\nonumber \\\\\n",
    "x_{i,t} &= \\Phi_i(y_t) = \\frac{1}{Z} \\exp\\left(- \\frac{||x_t - z_i ||}{2\\sigma_i^2}\\right) \\nonumber \\\\\n",
    "\\epsilon_t &\\sim \\mathcal{N}(0, R) \\nonumber\n",
    "\\end{align}\n",
    "Parameters: \n",
    "- $C \\in \\mathbb{R}^{p \\times n}$, \n",
    "- $\\mbox{diag}(R) \\in \\mathbb{R}^p$, \n",
    "- $W \\in \\mathbb{R}^{p\\cdot{}m \\times n}$, \n",
    "- $\\tau \\in \\mathbb{R}$, \n",
    "- $\\forall i = 1, \\ldots,n: z_i \\in \\mathbb{R}^p, \\sigma_i^2 \\in \\mathbb{R}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "\n",
    "p,n,m,T = 2,2,2,50\n",
    "pars = {}\n",
    "\n",
    "# classic LDS pars\n",
    "#pars['C'] = np.random.normal(size=(p,n))\n",
    "pars['C'] = - np.array([[1,0],[0,1]])\n",
    "pars['d'] = np.ones(p)\n",
    "pars['R'] = 0 * np.ones(p) \n",
    "\n",
    "# auto-regression on observed variables\n",
    "pars['tau'] = np.sqrt(-np.log( 0.01 ))\n",
    "\n",
    "# fixed non-linear mapping from observed to latents\n",
    "#pars['Z'] = np.zeros((n,p))\n",
    "pars['Z'] = np.array([[1,0],[0,1]])\n",
    "pars['sig'] = np.ones(n)\n",
    "\n",
    "# bilinear dependence on inputs & latents\n",
    "pars['W'] = 0*np.random.normal(size=(p*m,n))\n",
    "pars['B'] = lambda x: np.reshape(pars['W'].dot(x), (p,m))\n",
    "\n",
    "# technical convenience parameters\n",
    "pars['e'] = 10e-7\n",
    "pars['sqR'] = np.sqrt(pars['R'])\n",
    "pars['alpha'] = 1 - np.exp(-pars['tau']**2)\n",
    "\n",
    "def condition_on(y):\n",
    "    phi = np.exp( - np.sum((y-pars['Z'])**2,1) / (2*pars['sig']) )\n",
    "    return phi / (pars['e'] + phi.sum())\n",
    "\n",
    "def predict(y, u, x,pars, eps):\n",
    "    return pars['alpha']*y + pars['C'].dot(x) + pars['B'](x).dot(u) + pars['d'] + pars['sqR'] * eps\n",
    "\n",
    "u = np.random.normal(size=(T,m))\n",
    "y,x = np.zeros((T,p)), np.zeros((T,n))\n",
    "for t in range(1,T):\n",
    "    x[t-1] = condition_on(y[t-1])\n",
    "    y[ t ] = predict(y[t-1], u[t-1], x[t-1], pars, np.random.normal(size=p))\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(y)\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(x)\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('x')\n",
    "plt.subplot(3,1,3)\n",
    "tmp = np.exp( - np.sum(y**2,1)/ 2 )\n",
    "plt.plot(tmp / (pars['e']+3*tmp))\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(x.sum(axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
